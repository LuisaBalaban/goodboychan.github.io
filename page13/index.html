<div class="home"><p>Currently Migrating into <a href="https://quarto.org/">Quarto</a> platform. See the progress on <a href="https://kcsgoodboy.github.io/">here</a> :)</p>

<h1 id="posts">Posts</h1>



  

  <!-- Hide posts if front matter flag hide:true -->
  
  

  <!-- Sort posts by rank, then date -->
  
  
  

 
  

   <!-- Assemble final sorted posts array -->
  
  <ul class="post-list"><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/mse.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/datacamp/machine_learning/2020/07/08/03-Feature-selection-II-selecting-for-model-accuracy.html">
            Feature selection II - selecting for model accuracy
          </a>
        </h3>
        <p class="post-meta-description">In this second chapter on feature selection, you'll learn how to let models help you find the most important features in a dataset for predicting a particular target feature. In the final lesson of this chapter, you'll combine the advice of multiple, different, models to decide on which features are worth keeping. This is the Summary of lecture "Dimensionality Reduction in Python", via datacamp.</p>
          <p class="post-meta">Jul 8, 2020</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/heatmap_lt.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/datacamp/machine_learning/2020/07/08/02-Feature-selection-I-selecting-for-feature-information.html">
            Feature selection I - selecting for feature information
          </a>
        </h3>
        <p class="post-meta-description">In this first out of two chapters on feature selection, you'll learn about the curse of dimensionality and how dimensionality reduction can help you overcome it. You'll be introduced to a number of techniques to detect and remove features that bring little added value to the dataset. Either because they have little variance, too many missing values, or because they are strongly correlated to other features. This is the Summary of lecture "Dimensionality Reduction in Python", via datacamp.</p>
          <p class="post-meta">Jul 8, 2020</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/tsne_gender.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/datacamp/machine_learning/2020/07/08/01-Exploring-high-dimensional-data.html">
            Exploring high dimensional data
          </a>
        </h3>
        <p class="post-meta-description">You'll be introduced to the concept of dimensionality reduction and will learn when an why this is important. You'll learn the difference between feature selection and feature extraction and will apply both techniques for data exploration. The chapter ends with a lesson on t-SNE, a powerful feature extraction technique that will allow you to visualize a high-dimensional dataset. This is the Summary of lecture "Dimensionality Reduction in Python", via datacamp.</p>
          <p class="post-meta">Jul 8, 2020</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/datacamp/machine_learning/2020/07/07/03-Using-XGBoost-in-pipelines.html">
            Using XGBoost in pipelines
          </a>
        </h3>
        <p class="post-meta-description">Take your XGBoost skills to the next level by incorporating your models into two end-to-end machine learning pipelines. You'll learn how to tune the most important XGBoost hyperparameters efficiently within a pipeline, and get an introduction to some more advanced preprocessing techniques. This is the Summary of lecture "Extreme Gradient Boosting with XGBoost", via datacamp.</p>
          <p class="post-meta">Jul 7, 2020</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/datacamp/machine_learning/2020/07/07/02-Fine-tuning-your-XGBoost-model.html">
            Fine-tuning your XGBoost model
          </a>
        </h3>
        <p class="post-meta-description">This chapter will teach you how to make your XGBoost models as performant as possible. You'll learn about the variety of parameters that can be adjusted to alter the behavior of XGBoost and how to tune them efficiently so that you can supercharge the performance of your models. This is the Summary of lecture "Extreme Gradient Boosting with XGBoost", via datacamp.</p>
          <p class="post-meta">Jul 7, 2020</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/xgb_feature_importance.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/datacamp/machine_learning/2020/07/07/01-Regression-with-XGBoost.html">
            Regression with XGBoost
          </a>
        </h3>
        <p class="post-meta-description">After a brief review of supervised regression, you'll apply XGBoost to the regression task of predicting house prices in Ames, Iowa. You'll learn about the two kinds of base learners that XGboost can use as its weak learners, and review how to evaluate the quality of your regression models. This is the Summary of lecture "Extreme Gradient Boosting with XGBoost", via datacamp.</p>
          <p class="post-meta">Jul 7, 2020</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/svm_classification2.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/datacamp/machine_learning/2020/07/06/02-Support-Vector-Machines.html">
            Support Vector Machines
          </a>
        </h3>
        <p class="post-meta-description">In this chapter you will learn all about the details of support vector machines. You'll learn about tuning hyperparameters for these models and using kernels to fit non-linear decision boundaries. This is the Summary of lecture "Linear Classifiers in Python", via datacamp.</p>
          <p class="post-meta">Jul 6, 2020</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/svm_classification.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/datacamp/machine_learning/2020/07/06/01-Logistic-regression.html">
            Logistic regression
          </a>
        </h3>
        <p class="post-meta-description">In this chapter you will delve into the details of logistic regression. You'll learn all about regularization and how to interpret model output. This is the Summary of lecture "Linear Classifiers in Python", via datacamp.</p>
          <p class="post-meta">Jul 6, 2020</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/datacamp/machine_learning/2020/07/06/03-Classification-with-XGBoost.html">
            Classification with XGBoost
          </a>
        </h3>
        <p class="post-meta-description">This chapter will introduce you to the fundamental idea behind XGBoostâ€”boosted learners. Once you understand how XGBoost works, you'll apply it to solve a common classification problem found in industry - predicting whether a customer will stop being a customer at some point in the future. This is the Summary of lecture "Extreme Gradient Boosting with XGBoost", via datacamp.</p>
          <p class="post-meta">Jul 6, 2020</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/plot_4_classifiers.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/datacamp/machine_learning/2020/07/05/01-Applying-logistic-regression-and-SVM.html">
            Applying logistic regression and SVM
          </a>
        </h3>
        <p class="post-meta-description">In this chapter you will learn the basics of applying logistic regression and support vector machines (SVMs) to classification problems. You'll use the scikit-learn library to fit classification models to real data. This is the Summary of lecture "Linear Classifiers in Python", via datacamp.</p>
          <p class="post-meta">Jul 5, 2020</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/log_hinge.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/datacamp/machine_learning/2020/07/05/02-Loss-functions.html">
            Loss functions
          </a>
        </h3>
        <p class="post-meta-description">In this chapter you will discover the conceptual framework behind logistic regression and SVMs. This will let you delve deeper into the inner workings of these models. This is the Summary of lecture "Linear Classifiers in Python", via datacamp.</p>
          <p class="post-meta">Jul 5, 2020</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/geopandas_choropleth.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/datacamp/visualization/2020/07/03/01-Creating-a-choropleth-building-permit-density-in-Nashville.html">
            Creating a choropleth building permit density in Nashville
          </a>
        </h3>
        <p class="post-meta-description">In this chapter, you will learn about a special map called a choropleth. Then you will learn and practice building choropleths using two different packages - geopandas and folium. This is the Summary of lecture "Visualizing Geospatial Data in Python", via datacamp.</p>
          <p class="post-meta">Jul 3, 2020</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/downtown_map.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/datacamp/visualization/2020/07/02/01-GeoSeries-and-folium.html">
            GeoSeries and folium
          </a>
        </h3>
        <p class="post-meta-description">First you will learn to get information about the geometries in your data with three different GeoSeries attributes and methods. Then you will learn to create a street map layer using folium. This is the Summary of lecture "Visualizing Geospatial Data in Python", via datacamp.</p>
          <p class="post-meta">Jul 2, 2020</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/urban_art.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/datacamp/visualization/2020/07/01/02-Creating-and-joining-GeoDataFrames.html">
            Creating and joining GeoDataFrames
          </a>
        </h3>
        <p class="post-meta-description">You'll work with GeoJSON to create polygonal plots, learn about projections and coordinate reference systems, and get practice spatially joining data in this chapter. This is the Summary of lecture "Visualizing Geospatial Data in Python", via datacamp.</p>
          <p class="post-meta">Jul 1, 2020</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/nashville_chicken_permits.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/datacamp/visualization/2020/07/01/01-Building-2-layer-maps-combining-polygons-and-scatterplots.html">
            Building 2-layer maps - combining polygons and scatterplots
          </a>
        </h3>
        <p class="post-meta-description">In this chapter, you will learn how to create a two-layer map by first plotting regions from a shapefile and then plotting location points as a scatterplot. This is the Summary of lecture "Visualizing Geospatial Data in Python", via datacamp.</p>
          <p class="post-meta">Jul 1, 2020</p>
      </div>
  </div></li></ul>

    
      <div class="pager">
        <ul class="pagination">
          <li><a href="/page12/" class="previous-page">12</a></li>
          <li><div class="current-page">13</div></li>
          <li><a href="/page14/" class="next-page">14</a></li>
        </ul>
      </div></div>