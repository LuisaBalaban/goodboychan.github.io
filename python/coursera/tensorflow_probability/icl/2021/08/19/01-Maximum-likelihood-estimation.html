<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Maximum Likelihood Estimation - how neural networks learn | Chan`s Jupyter</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Maximum Likelihood Estimation - how neural networks learn" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="In this post, we will review a Maximum Likelihood Estimation (MLE for short), an important learning principle used in neural network training. This is the copy of lecture “Probabilistic Deep Learning with Tensorflow 2” from Imperial College London." />
<meta property="og:description" content="In this post, we will review a Maximum Likelihood Estimation (MLE for short), an important learning principle used in neural network training. This is the copy of lecture “Probabilistic Deep Learning with Tensorflow 2” from Imperial College London." />
<link rel="canonical" href="https://goodboychan.github.io/python/coursera/tensorflow_probability/icl/2021/08/19/01-Maximum-likelihood-estimation.html" />
<meta property="og:url" content="https://goodboychan.github.io/python/coursera/tensorflow_probability/icl/2021/08/19/01-Maximum-likelihood-estimation.html" />
<meta property="og:site_name" content="Chan`s Jupyter" />
<meta property="og:image" content="https://goodboychan.github.io/images/gaussian_likelihood.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-08-19T00:00:00-05:00" />
<script type="application/ld+json">
{"headline":"Maximum Likelihood Estimation - how neural networks learn","dateModified":"2021-08-19T00:00:00-05:00","url":"https://goodboychan.github.io/python/coursera/tensorflow_probability/icl/2021/08/19/01-Maximum-likelihood-estimation.html","datePublished":"2021-08-19T00:00:00-05:00","@type":"BlogPosting","image":"https://goodboychan.github.io/images/gaussian_likelihood.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://goodboychan.github.io/python/coursera/tensorflow_probability/icl/2021/08/19/01-Maximum-likelihood-estimation.html"},"description":"In this post, we will review a Maximum Likelihood Estimation (MLE for short), an important learning principle used in neural network training. This is the copy of lecture “Probabilistic Deep Learning with Tensorflow 2” from Imperial College London.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://goodboychan.github.io/feed.xml" title="Chan`s Jupyter" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-33905785-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-33905785-1');
</script>


<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>

<script data-ad-client="ca-pub-6747875619665490" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Chan`s Jupyter</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/book/">Book</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Maximum Likelihood Estimation - how neural networks learn</h1><p class="page-description">In this post, we will review a Maximum Likelihood Estimation (MLE for short), an important learning principle used in neural network training. This is the copy of lecture "Probabilistic Deep Learning with Tensorflow 2" from Imperial College London.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-08-19T00:00:00-05:00" itemprop="datePublished">
        Aug 19, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      12 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#Python">Python</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#Coursera">Coursera</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#Tensorflow_probability">Tensorflow_probability</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#ICL">ICL</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/goodboychan/goodboychan.github.io/tree/main/_notebooks/2021-08-19-01-Maximum-likelihood-estimation.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/goodboychan/goodboychan.github.io/main?filepath=_notebooks%2F2021-08-19-01-Maximum-likelihood-estimation.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/goodboychan/goodboychan.github.io/blob/main/_notebooks/2021-08-19-01-Maximum-likelihood-estimation.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Fgoodboychan%2Fgoodboychan.github.io%2Fblob%2Fmain%2F_notebooks%2F2021-08-19-01-Maximum-likelihood-estimation.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Introduction">Introduction </a></li>
<li class="toc-entry toc-h2"><a href="#Probability-mass-and-probability-density-functions">Probability mass and probability density functions </a></li>
<li class="toc-entry toc-h2"><a href="#The-likelihood-function">The likelihood function </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Bernoulli-distribution">Bernoulli distribution </a></li>
<li class="toc-entry toc-h4"><a href="#Normal-(Gaussian)-distribution">Normal (Gaussian) distribution </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Maximum-likelihood-estimation">Maximum likelihood estimation </a></li>
<li class="toc-entry toc-h2"><a href="#The-negative-log-likelihood">The negative log-likelihood </a></li>
<li class="toc-entry toc-h2"><a href="#Training-neural-networks">Training neural networks </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Bernoulli-distribution:-binary-classifiers">Bernoulli distribution: binary classifiers </a></li>
<li class="toc-entry toc-h4"><a href="#Normal-distribution:-least-squares-regression">Normal distribution: least squares regression </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Conclusion">Conclusion </a></li>
<li class="toc-entry toc-h2"><a href="#Further-reading-and-resources">Further reading and resources </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-08-19-01-Maximum-likelihood-estimation.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>This is the reading session on coursera, so it doesn’t contain any working tutorial.
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introduction">
<a class="anchor" href="#Introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction<a class="anchor-link" href="#Introduction"> </a>
</h2>
<p>Why are neural networks trained the way they are? For example, why do you use a mean squared error loss function for a regression task, but a sparse categorical crossentropy loss for classification? The answer lies in the <em>likelihood</em> function, with a long history in statistics. In this notebook, we'll look at what this function is and how it leads to the loss functions used to train deep learning models.</p>
<p>Since you're taking a course in Tensorflow Probability, I'll assume you already have some understanding of probability distributions, both discrete and continous. If you don't, there are countless resources to help you understand them. I find the <a href="https://en.wikipedia.org/wiki/Probability_distribution">Wikipedia page</a> works well for an intuitive introduction. For a more solid mathematical description, see an introductory statistics course.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Probability-mass-and-probability-density-functions">
<a class="anchor" href="#Probability-mass-and-probability-density-functions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Probability mass and probability density functions<a class="anchor-link" href="#Probability-mass-and-probability-density-functions"> </a>
</h2>
<p>Every probability distribution has either a probability mass function (if the distribution is discrete) or a probability density function (if the distribution is continuous). This function roughly indicates the probability of a sample taking a particular value. We will denote this function $P(y | \theta)$ where $y$ is the value of the sample and $\theta$ is the parameter describing the probability distribution. Written out mathematically, we have:</p>
$$
P(y | \theta) = \text{Prob} (\text{sampling value $y$ from a distribution with parameter $\theta$}).
$$<p>When more than one sample is drawn <em>independently</em> from the same distribution (which we usually assume), the probability mass/density function of the sample values $y_1, \ldots, y_n$ is the product of the probability mass/density functions for each individual $y_i$. Written formally:</p>
$$
P(y_1, \ldots, y_n | \theta) = \prod_{i=1}^n P(y_i | \theta).
$$<p>This all sounds more complicated than it is: see the examples below for a more concrete illustration.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-likelihood-function">
<a class="anchor" href="#The-likelihood-function" aria-hidden="true"><span class="octicon octicon-link"></span></a>The likelihood function<a class="anchor-link" href="#The-likelihood-function"> </a>
</h2>
<p>Probability mass/density functions are usually considered functions of $y_1, \ldots, y_n$, with the parameter $\theta$ considered fixed. They are used when you know the parameter $\theta$ and want to know the probability of a sample taking some values $y_1, \ldots, y_n$. You use this function in <em>probability</em>, where you know the distribution and want to make deductions about possible values sampled from it.</p>
<p>The <em>likelihood</em> function is the same, but with the $y_1, \ldots, y_n$ considered fixed and with $\theta$ considered the independent variable. You usually use this function when you know the sample values $y_1, \ldots, y_n$ (because you've observed them by collecting data), but don't know the parameter $\theta$. You use this function in <em>statistics</em>, where you know the data and want to make inferences about the distribution they came from.</p>
<p>This is an important point, so I'll repeat it: $P(y_1, \ldots, y_n | \theta)$ is called the <em>probability mass/density function</em> when considered as a function of $y_1, \ldots, y_n$ with $\theta$ fixed. It's called the <em>likelihood</em> when considered as a function of $\theta$ with $y_1, \ldots, y_n$ fixed. For the likelihood, the convention is using the letter $L$, so that</p>
$$
\underbrace{L(y_1, \ldots, y_n | \theta)}_{\text{ likelihood,} \\ \text{function of $\theta$}} = \underbrace{P(y_1, \ldots, y_n | \theta)}_{\text{probabiliy mass/density,} \\ \text{ function of $y_1, \ldots, y_n$}}
$$<p>Let's see some examples of this below.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Bernoulli-distribution">
<a class="anchor" href="#Bernoulli-distribution" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bernoulli distribution<a class="anchor-link" href="#Bernoulli-distribution"> </a>
</h4>
<p>We'll start by looking at the <a href="https://en.wikipedia.org/wiki/Bernoulli_distribution">Bernoulli distribution</a> with parameter $\theta$. It's the distribution of a random variable that takes value 1 with probability $\theta$ and 0 with probability $1-\theta$. Let $P(y | \theta)$ be the probability that the event returns value $y$ given parameter $\theta$. Then</p>
$$
\begin{aligned}
L(y | \theta) = P(y | \theta) &amp;= \begin{cases}
1 - \theta \quad \text{if} \, y = 0 \\
\theta \quad \quad \, \, \, \text{if} \, y = 1 \\
\end{cases} \\
&amp;= (1 - \theta)^{1 - y} \theta^y \quad y \in \{0, 1\}
\end{aligned}
$$<p>If we assume samples are independent, we also have
$$
L(y_1, \ldots, y_n | \theta) = \prod_{i=1}^n (1 - \theta)^{1 - y_i} \theta^{y_i}.
$$</p>
<p>For example, the probability of observing $0, 0, 0, 1, 0$ is</p>
$$
L(0, 0, 0, 1, 0 | \theta) = (1 - \theta)(1 - \theta)(1 - \theta)\theta(1 - \theta) = \theta(1 - \theta)^4.
$$<p>Note that, in this case, we have fixed the data, and are left with a function just of $\theta$. This is called the <em>likelihood</em> function. Let's plot the likelihood as a function of $\theta$ below.</p>
<p><img src="/images/copied_from_nb/image/bernoulli_likelihood.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Normal-(Gaussian)-distribution">
<a class="anchor" href="#Normal-(Gaussian)-distribution" aria-hidden="true"><span class="octicon octicon-link"></span></a>Normal (Gaussian) distribution<a class="anchor-link" href="#Normal-(Gaussian)-distribution"> </a>
</h4>
<p>This idea also generalises naturally to the <a href="https://en.wikipedia.org/wiki/Normal_distribution">Normal distribution</a> (also called the <em>Gaussian</em> distribution). This distribution has two parameters: a mean $\mu$ and a standard deviation $\sigma$. We hence let $\theta = (\mu, \sigma)$. The probability density function (the analogue of the probability mass function for continuous distributions) is:</p>
$$
L(y | \theta) = P(y | \theta) = P(y | \mu, \sigma) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp \Big( - \frac{1}{2 \sigma^2} (y - \mu)^2 \Big).
$$<p>For a sequence of independent observations $y_1, \ldots, y_n$, the likelihood is</p>
$$
L(y_1, \ldots, y_n | \mu, \sigma) = \prod_{i=1}^n \frac{1}{\sqrt{2 \pi \sigma^2}} \exp \Big( - \frac{1}{2 \sigma^2} (y_i - \mu)^2 \Big).
$$<p>The <em>likelihood</em> is hence the same, but viewed as a function of $\mu$ and $\sigma$, with $y_1, \ldots, y_n$ viewed as constants. For example, if the observed data is -1, 0, 1, the likelihood becomes</p>
$$
L(-1, 0, 1 | \mu, \sigma) = (2 \pi \sigma^2)^{-3/2} \exp \Big( - \frac{1}{2 \sigma^2} (\mu-1)^2 + (\mu)^2 + (\mu+1)^2 \Big).
$$<p>which we can plot as a function of $\mu$ an $\sigma$ below.</p>
<p><img src="/images/copied_from_nb/image/gaussian_likelihood.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Maximum-likelihood-estimation">
<a class="anchor" href="#Maximum-likelihood-estimation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Maximum likelihood estimation<a class="anchor-link" href="#Maximum-likelihood-estimation"> </a>
</h2>
<p>The likelihood function is commonly used in statistical inference when we are trying to fit a distribution to some data. This is usually done as follows. Suppose we have observed data $y_1, \ldots, y_n$, assumed to be from some distribution with unknown parameter $\theta$, which we want to estimate. The likelihood is</p>
$$
L(y_1, \ldots, y_n | \theta).
$$<p>The <em>maximum likelihood estimate</em> $\theta_{\text{MLE}}$ of the parameter $\theta$ is then the value that maximises the likelihood $L(y_1, \ldots, y_n | \theta)$. For the example of the Bernoulli distribution with observed data 0, 0, 0, 1, 0 (as in the plot above), this gives us $p=\frac{1}{5}$, which is where the plot takes its maximum. For the normal distribution with data -1, 0, 1, this is the region where the plot is brightest (indicating the highest value), and this occurs at $\mu=0, \sigma=\sqrt{\frac{2}{3}}$. In this way, we <em>pick the values of the parameter that make the data we have observed the most likely</em>. Written in mathematical notation, this is</p>
$$
\theta_{\text{MLE}} = \arg \max_{\theta} L(y_1, \ldots, y_n | \theta).
$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-negative-log-likelihood">
<a class="anchor" href="#The-negative-log-likelihood" aria-hidden="true"><span class="octicon octicon-link"></span></a>The negative log-likelihood<a class="anchor-link" href="#The-negative-log-likelihood"> </a>
</h2>
<p>Recall that, for independent observations, the likelihood becomes a product:</p>
$$
L(y_1, \ldots, y_n | \theta) = \prod_{i=1}^n P(y_i | \theta).
$$<p>Furthermore, since the $\log$ function increases with its argument, maximizing the likelihood is equivalent to maximizing the log-likelihood $\log L(y_1, \ldots, y_n | \theta)$. This changes the product into a sum:</p>
$$
\begin{aligned}
\theta_{\text{MLE}} &amp;= \arg \max_{\theta} L(y_1, \ldots, y_n | \theta) \\
&amp;= \arg \max_{\theta} \log L(y_1, \ldots, y_n | \theta) \\
&amp;= \arg \max_{\theta} \log \prod_{i=1}^n L(y_i | \theta) \\
&amp;= \arg \max_{\theta} \sum_{i=1}^n \log L(y_i | \theta).
\end{aligned}
$$<p>Furthermore, convention in optimization is that we always <em>minimize</em> a function instead of maximizing it. Hence, maximizing the likelihood is equivalent to <em>minimizing</em> the <em>negative log-likelihood</em>:</p>
$$
\theta_{\text{MLE}} = \arg \min_{\theta} \text{NLL}(y_1, \ldots, y_n | \theta)
$$<p>where the <em>negative log-likelihood</em> NLL is defined as</p>
$$
\text{NLL}(y_1, \ldots, y_n | \theta) = - \sum_{i=1}^n \log L(y_i | \theta).
$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Training-neural-networks">
<a class="anchor" href="#Training-neural-networks" aria-hidden="true"><span class="octicon octicon-link"></span></a>Training neural networks<a class="anchor-link" href="#Training-neural-networks"> </a>
</h2>
<p>How is all this used to train neural networks? We do this, given some training data, by picking the weights of the neural network that maximise the likelihood (or, equivalently, minimise the negative loglikelihood) of having observed that data. More specifically, the neural network is a function that maps a data point $x_i$ to the parameter $\theta$ of some distribution. This parameter indicates the probability of seeing each possible label. We then use our true labels and the likelihood to find the best weights of the neural network.</p>
<p>Let's be a bit more precise about this. Suppose we have a neural network $\text{NN}$ with weights $\mathbf{w}$. Furthemore, suppose $x_i$ is some data point, e.g. an image to be classified, or an $x$ value for which we want to predict the $y$ value. The neural network prediction (the feedforward value) $\hat{y}_i$ is</p>
$$
\hat{y}_i = \text{NN}(x_i | \mathbf{w}).
$$<p>We can use this to train the neural network (determine its weights $\mathbf{w}$) as follows. We assume that the neural network prediction $\hat{y}_i$ forms part of a distribution that the true label is drawn from. Suppose we have some training data consisting of inputs and the associated labels. Let the data be $x_i$ and the labels $y_i$ for $i=1, \ldots, n$, where $n$ is the number of training samples. The training data is hence</p>
$$
\text{training data} = \{(x_1, y_1), \ldots, (x_n, y_n)\}
$$<p>For each point $x_i$, we have the neural network prediction $\hat{y}_i = \text{NN}(x_i | \mathbf{w})$, which we assume specifies a distribution. We also have the true label $y_i$. The weights of the trained neural network are then those that minimise the negative log-likelihood:</p>
$$
\begin{aligned}
\mathbf{w}^* &amp;= \arg \min_{\mathbf{w}} \big( - \sum_{i=1}^n \log L(y_i | \hat{y}_i) \big) \\
&amp;= \arg \min_{\mathbf{w}} \big( - \sum_{i=1}^n \log L(y_i | \text{NN}(x_i | \mathbf{w})) \big)
\end{aligned}
$$<p>In practice, determining the true optimum $\mathbf{w}^*$ is not always possible. Instead, an approximate value is sought using stochastic gradient descent, usually via a <em>backpropagation</em> of derivatives and some optimization algorithm such as <code>RMSprop</code> or <code>Adam</code>.</p>
<p>Let's see some examples to make this idea more concrete.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Bernoulli-distribution:-binary-classifiers">
<a class="anchor" href="#Bernoulli-distribution:-binary-classifiers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bernoulli distribution: binary classifiers<a class="anchor-link" href="#Bernoulli-distribution:-binary-classifiers"> </a>
</h4>
<p>Suppose we want a neural network NN that classifies images into either cats or dogs. Here, $x_i$ is an image of either a cat or a dog, and $\hat{y}_i$ is the probability that this image is either a cat (value 0) or a dog (value 1):</p>
$$
\hat{y}_i = \text{NN}(x_i | \mathbf{w}) = \text{Prob}(\text{image is dog}).
$$<p>Note that this is just a Bernoulli distribution with values 0 and 1 corresponding to cat and dog respectively, of which we discussed the likelihood function above. Given training data $\{(x_1, y_1), \ldots, (x_n, y_n)\}$, with $y_i \in \{0, 1\}$, we have the negative log-likelihood</p>
$$
\begin{aligned}
\text{NLL}((x_1, y_1), \ldots, (x_n, y_n) | \mathbf{w}) &amp;= - \sum_{i=1}^n \log L(y_i | \hat{y}_i) \\
&amp;= - \sum_{i=1}^n \log \big( (1 - \hat{y}_i)^{1 - y_i} \hat{y}_i^{y_i} \big) \\
&amp;= - \sum_{i=1}^n \big( (1 - y_i) \log(1 - \hat{y}_i) + y_i \log \hat{y}_i \big) \\
&amp;= - \sum_{i=1}^n \big( (1 - y_i) \log(1 - \text{NN}(x_i | \mathbf{w})) + y_i \log \text{NN}(x_i | \mathbf{w}) \big). \\
\end{aligned}
$$<p>This is exactly the sparse categorical cross-entropy loss function used when training a classification neural network. Hence, the reason why we typically use categorical cross-entropy loss functions when training classification data is exactly because this is the negative log-likelihood under a Bernoulli (or, when there are more than 2 classes, a categorical) distribution.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Normal-distribution:-least-squares-regression">
<a class="anchor" href="#Normal-distribution:-least-squares-regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Normal distribution: least squares regression<a class="anchor-link" href="#Normal-distribution:-least-squares-regression"> </a>
</h4>
<p>The idea works the same way in a regression task. Here, we have an $x$-value $x_i$ and want to predict the associated $y$-value $y_i$. We can use a neural network to do this, giving a prediction $\hat{y}_i$:</p>
$$
\hat{y}_i = \text{NN}(x_i | \mathbf{w}).
$$<p>For example, suppose we were doing linear regression with the following data.</p>
<p><img src="/images/copied_from_nb/image/linear_regression.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It's not possible to put a straight line through every data point. Furthermore, even points with the same $x$ value might not have the same $y$ value. We can interpret this as $y$ being linearly related to $x$ with some noise. More precisely, we may assume that</p>
$$
y_i = f(x_i) + \epsilon_i \quad \quad  \epsilon_i \sim N(0, \sigma^2)
$$<p>where $f$ is some function we want to determine (the regression) and $\epsilon_i$ is some Gaussian noise with mean 0 and constant variance $\sigma^2$. In deep learning, we might approximate $f(x_i)$ by a neural network $\text{NN}(x_i | \mathbf{w})$ with weights $\mathbf{w}$ and output $\hat{y}_i$.</p>
$$
\hat{y}_i = \text{NN}(x_i | \mathbf{w}) = f(x_i)
$$<p>Under this assumption, we have</p>
$$
\epsilon_i = y_i - \hat{y}_i \sim N(0, \sigma^2)
$$<p>and hence, given training data $\{(x_1, y_1), \ldots, (x_n, y_n)\}$, we have the negative log-likelihood (assuming the noise terms are independent):</p>
$$
\begin{aligned}
\text{NLL}((x_1, y_1), \ldots, (x_n, y_n) | \mathbf{w}) &amp;= - \sum_{i=1}^n \log L(y_i | \hat{y}_i) \\
&amp;= - \sum_{i=1}^n \log \Big( \frac{1}{\sqrt{2\pi\sigma^2}} \exp \Big( - \frac{1}{2\sigma^2} (\hat{y}_i - y_i)^2 \Big) \Big) \\
&amp;= \frac{n}{2} \log (2\pi\sigma^2) + \frac{1}{2\sigma^2} \sum_{i=1}^n (\hat{y}_i - y_i)^2 \\
&amp;= \frac{n}{2} \log (2\pi\sigma^2) + \frac{1}{2\sigma^2} \sum_{i=1}^n (\text{NN}(x_i | \mathbf{w}) - y_i)^2.
\end{aligned}
$$<p>Note that only the last term includes the weights. Hence, minimising the negative log-likelihood is equivalent to minimising</p>
$$
\sum_{i=1}^n (\text{NN}(x_i | \mathbf{w}) - y_i)^2
$$<p>which is exactly the sum of squared errors. Hence, least squares regression (or training a neural network using the mean squared error) is equivalent to training a neural network to match the expected value of an output by minimising the negative log-likelihood assuming a Gaussian error term with constant variance.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Conclusion">
<a class="anchor" href="#Conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion<a class="anchor-link" href="#Conclusion"> </a>
</h2>
<p>This was a very short introduction to maximum likelihood estimation, which is essential for deep learning, especially of the probabilistic variety that we'll be doing in this course. The method of maximum likelihood estimation is key to training neural networks, and typically informs the choice of loss function. In fact, you have probably trained neural networks using maximum likelihood estimation without even knowing it!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Further-reading-and-resources">
<a class="anchor" href="#Further-reading-and-resources" aria-hidden="true"><span class="octicon octicon-link"></span></a>Further reading and resources<a class="anchor-link" href="#Further-reading-and-resources"> </a>
</h2>
<p>I find that the Wikipedia pages for many statistical concepts offer excellent intuition. If you'd like to read up on these ideas in more detail, I'd recommend these:</p>
<ul>
<li>The Wikipedia page for Probability Distribution: <a href="https://en.wikipedia.org/wiki/Probability_distribution">https://en.wikipedia.org/wiki/Probability_distribution</a>
</li>
<li>The Wikipedia page for Maximum Likelihood Estimation: <a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation">https://en.wikipedia.org/wiki/Maximum_likelihood_estimation</a>
</li>
</ul>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="goodboychan/goodboychan.github.io"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/python/coursera/tensorflow_probability/icl/2021/08/19/01-Maximum-likelihood-estimation.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="https://goodboychan.github.io/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
  <a rel="me" href="https://github.com/goodboychan" target="_blank" title="github">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#github"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://www.linkedin.com/in/chanseokk/" target="_blank" title="linkedin">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#linkedin"></use>
    </svg>
  </a>
</li>
</ul>
</div>

  </div>

</footer>
</body>

</html>
