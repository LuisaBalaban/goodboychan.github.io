<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Modeling | Chan`s Jupyter</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Modeling" />
<meta name="author" content="Chanseok Kang" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Time to bring everything together and build some models! In this last chapter, you will build a base model before tuning some hyperparameters and improving your results with ensembles. You will then get some final tips and tricks to help you compete more efficiently. This is the Summary of lecture “Winning a Kaggle Competition in Python”, via datacamp." />
<meta property="og:description" content="Time to bring everything together and build some models! In this last chapter, you will build a base model before tuning some hyperparameters and improving your results with ensembles. You will then get some final tips and tricks to help you compete more efficiently. This is the Summary of lecture “Winning a Kaggle Competition in Python”, via datacamp." />
<link rel="canonical" href="https://goodboychan.github.io/python/datacamp/kaggle/machine_learning/2020/08/12/04-Modeling-used-in-Kaggle.html" />
<meta property="og:url" content="https://goodboychan.github.io/python/datacamp/kaggle/machine_learning/2020/08/12/04-Modeling-used-in-Kaggle.html" />
<meta property="og:site_name" content="Chan`s Jupyter" />
<meta property="og:image" content="https://goodboychan.github.io/images/modeling_stage.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-08-12T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://goodboychan.github.io/python/datacamp/kaggle/machine_learning/2020/08/12/04-Modeling-used-in-Kaggle.html","headline":"Modeling","dateModified":"2020-08-12T00:00:00-05:00","datePublished":"2020-08-12T00:00:00-05:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://goodboychan.github.io/python/datacamp/kaggle/machine_learning/2020/08/12/04-Modeling-used-in-Kaggle.html"},"image":"https://goodboychan.github.io/images/modeling_stage.png","author":{"@type":"Person","name":"Chanseok Kang"},"description":"Time to bring everything together and build some models! In this last chapter, you will build a base model before tuning some hyperparameters and improving your results with ensembles. You will then get some final tips and tricks to help you compete more efficiently. This is the Summary of lecture “Winning a Kaggle Competition in Python”, via datacamp.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://goodboychan.github.io/feed.xml" title="Chan`s Jupyter" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-33905785-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-33905785-1');
</script>


<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>

<script data-ad-client="ca-pub-6747875619665490" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Chan`s Jupyter</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/book/">Book</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Modeling</h1><p class="page-description">Time to bring everything together and build some models! In this last chapter, you will build a base model before tuning some hyperparameters and improving your results with ensembles. You will then get some final tips and tricks to help you compete more efficiently. This is the Summary of lecture "Winning a Kaggle Competition in Python", via datacamp.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-08-12T00:00:00-05:00" itemprop="datePublished">
        Aug 12, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Chanseok Kang</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      9 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#Python">Python</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#Datacamp">Datacamp</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#Kaggle">Kaggle</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#Machine_Learning">Machine_Learning</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/goodboychan/goodboychan.github.io/tree/main/_notebooks/2020-08-12-04-Modeling-used-in-Kaggle.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/goodboychan/goodboychan.github.io/main?filepath=_notebooks%2F2020-08-12-04-Modeling-used-in-Kaggle.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/goodboychan/goodboychan.github.io/blob/main/_notebooks/2020-08-12-04-Modeling-used-in-Kaggle.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Fgoodboychan%2Fgoodboychan.github.io%2Fblob%2Fmain%2F_notebooks%2F2020-08-12-04-Modeling-used-in-Kaggle.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Baseline-model">Baseline model </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Replicate-validation-score">Replicate validation score </a></li>
<li class="toc-entry toc-h3"><a href="#Baseline-based-on-the-date">Baseline based on the date </a></li>
<li class="toc-entry toc-h3"><a href="#Baseline-based-on-the-gradient-boosting">Baseline based on the gradient boosting </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Hyperparameter-tuning">Hyperparameter tuning </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Grid-search">Grid search </a></li>
<li class="toc-entry toc-h3"><a href="#2D-grid-search">2D grid search </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Model-ensembling">Model ensembling </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Model-blending">Model blending </a></li>
<li class="toc-entry toc-h3"><a href="#Model-stacking-I">Model stacking I </a></li>
<li class="toc-entry toc-h3"><a href="#Model-stacking-II">Model stacking II </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Final-tips">Final tips </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Testing-Kaggle-forum-ideas">Testing Kaggle forum ideas </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-08-12-04-Modeling-used-in-Kaggle.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">'ggplot'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">'figure.figsize'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Baseline-model">
<a class="anchor" href="#Baseline-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Baseline model<a class="anchor-link" href="#Baseline-model"> </a>
</h2>
<ul>
<li>Modeling stage
<img src="/images/copied_from_nb/image/modeling_stage.png" alt="modeling">
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Replicate-validation-score">
<a class="anchor" href="#Replicate-validation-score" aria-hidden="true"><span class="octicon octicon-link"></span></a>Replicate validation score<a class="anchor-link" href="#Replicate-validation-score"> </a>
</h3>
<p>Throughout this chapter, you will work with New York City Taxi competition data. The problem is to predict the fare amount for a taxi ride in New York City. The competition metric is the root mean squared error.</p>
<p>The first goal is to evaluate the Baseline model on the validation data. You will replicate the simplest Baseline based on the mean of <code>"fare_amount"</code>. Recall that as a validation strategy we used a 30% holdout split with <code>validation_train</code> as train and <code>validation_test</code> as holdout DataFrames.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'./dataset/taxi_train_chapter_4.csv'</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'./dataset/taxi_test_chapter_4.csv'</span><span class="p">)</span>

<span class="n">validation_train</span><span class="p">,</span> <span class="n">validation_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>

<span class="c1"># Calculate the mean fare_amount on the validation_train data</span>
<span class="n">naive_prediction</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">validation_train</span><span class="p">[</span><span class="s1">'fare_amount'</span><span class="p">])</span>

<span class="c1"># Assign naive prediction to all the holdout observations</span>
<span class="n">validation_test</span> <span class="o">=</span> <span class="n">validation_test</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">validation_test</span><span class="p">[</span><span class="s1">'pred'</span><span class="p">]</span> <span class="o">=</span> <span class="n">naive_prediction</span>

<span class="c1"># Measure the local RMSE</span>
<span class="n">rmse</span> <span class="o">=</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">validation_test</span><span class="p">[</span><span class="s1">'fare_amount'</span><span class="p">],</span> <span class="n">validation_test</span><span class="p">[</span><span class="s1">'pred'</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Validation RMSE for Baseline I model: </span><span class="si">{:.3f}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rmse</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Validation RMSE for Baseline I model: 9.431
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Baseline-based-on-the-date">
<a class="anchor" href="#Baseline-based-on-the-date" aria-hidden="true"><span class="octicon octicon-link"></span></a>Baseline based on the date<a class="anchor-link" href="#Baseline-based-on-the-date"> </a>
</h3>
<p>We've already built 3 different baseline models. To get more practice, let's build a couple more. The first model is based on the grouping variables. It's clear that the ride fare could depend on the part of the day. For example, prices could be higher during the rush hours.</p>
<p>Your goal is to build a baseline model that will assign the average <code>"fare_amount"</code> for the corresponding hour. For now, you will create the model for the whole train data and make predictions for the test dataset.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train</span><span class="p">[</span><span class="s1">'pickup_datetime'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s1">'pickup_datetime'</span><span class="p">])</span>
<span class="n">test</span><span class="p">[</span><span class="s1">'pickup_datetime'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s1">'pickup_datetime'</span><span class="p">])</span>

<span class="c1"># Get pickup hour from the pickup_datetime column</span>
<span class="n">train</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s1">'pickup_datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">hour</span>
<span class="n">test</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="s1">'pickup_datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">hour</span>

<span class="c1"># Calculate average fare_amount grouped by pickup hour</span>
<span class="n">hour_groups</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">'hour'</span><span class="p">)[</span><span class="s1">'fare_amount'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="c1"># Make predictions on the test set</span>
<span class="n">test</span><span class="p">[</span><span class="s1">'fare_amount'</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">hour</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">hour_groups</span><span class="p">)</span>

<span class="c1"># Write predictions</span>
<span class="n">test</span><span class="p">[[</span><span class="s1">'id'</span><span class="p">,</span> <span class="s1">'fare_amount'</span><span class="p">]]</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">'hour_mean_sub.csv'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>head hour_mean_sub.csv
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>id,fare_amount
0,11.199879638916757
1,11.199879638916757
2,11.241585365853654
3,10.964889086069206
4,10.964889086069206
5,10.964889086069206
6,11.094688755020092
7,11.094688755020092
8,11.094688755020092
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Baseline-based-on-the-gradient-boosting">
<a class="anchor" href="#Baseline-based-on-the-gradient-boosting" aria-hidden="true"><span class="octicon octicon-link"></span></a>Baseline based on the gradient boosting<a class="anchor-link" href="#Baseline-based-on-the-gradient-boosting"> </a>
</h3>
<p>Let's build a final baseline based on the Random Forest. You've seen a huge score improvement moving from the grouping baseline to the Gradient Boosting in the video. Now, you will use <code>sklearn</code>'s Random Forest to further improve this score.</p>
<p>The goal of this exercise is to take numeric features and train a Random Forest model without any tuning. After that, you could make test predictions and validate the result on the Public Leaderboard.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="c1"># Select only numeric features</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'pickup_longitude'</span><span class="p">,</span> <span class="s1">'pickup_latitude'</span><span class="p">,</span> <span class="s1">'dropoff_longitude'</span><span class="p">,</span>
            <span class="s1">'dropoff_latitude'</span><span class="p">,</span> <span class="s1">'passenger_count'</span><span class="p">,</span> <span class="s1">'hour'</span><span class="p">]</span>

<span class="c1"># Train a Random Forest model</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">()</span>
<span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">train</span><span class="o">.</span><span class="n">fare_amount</span><span class="p">)</span>

<span class="c1"># Make predictions on the test data</span>
<span class="n">test</span><span class="p">[</span><span class="s1">'fare_amount'</span><span class="p">]</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>

<span class="c1"># Write predictions</span>
<span class="n">test</span><span class="p">[[</span><span class="s1">'id'</span><span class="p">,</span> <span class="s1">'fare_amount'</span><span class="p">]]</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">'rf_sub.csv'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>head rf_sub.csv
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>id,fare_amount
0,8.658000000000001
1,8.472000000000003
2,5.587
3,9.402000000000001
4,13.478000000000002
5,8.375000000000007
6,5.745999999999999
7,54.50429999999999
8,11.93
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Hyperparameter-tuning">
<a class="anchor" href="#Hyperparameter-tuning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hyperparameter tuning<a class="anchor-link" href="#Hyperparameter-tuning"> </a>
</h2>
<ul>
<li>Ridge Regression<ul>
<li>Least squares linear regression

$$ \text{Loss} = \sum_{i=1}^N (y_i - \hat{y_i})^2 \rightarrow \text{min} $$
</li>
<li>Ridge Regression

$$ \text{Loss} = \sum_{i=1}^N (y_i - \hat{y_i})^2 + \alpha \sum_{j=1}^K w_j^2 \rightarrow \text{min} $$
</li>
<li>$\alpha$ is hyperparameter</li>
</ul>
</li>
<li>Hyperparameter optimization strategies<ul>
<li>Grid Search - Choose the predefined grid of hyperparamter values
<img src="/images/copied_from_nb/image/grid_search.png" alt="gs">
</li>
<li>Random Search - Choose the search space of hyperparamter values
<img src="/images/copied_from_nb/image/random_search.png" alt="rs">
</li>
<li>Bayesian optimization - Choose the search space of hyperparameter values</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Grid-search">
<a class="anchor" href="#Grid-search" aria-hidden="true"><span class="octicon octicon-link"></span></a>Grid search<a class="anchor-link" href="#Grid-search"> </a>
</h3>
<p>Recall that we've created a baseline Gradient Boosting model in the previous lesson. Your goal now is to find the best <code>max_depth</code> hyperparameter value for this Gradient Boosting model. This hyperparameter limits the number of nodes in each individual tree. You will be using K-fold cross-validation to measure the local performance of the model for each hyperparameter value.</p>
<p>You're given a function <code>get_cv_score()</code>, which takes the train dataset and dictionary of the model parameters as arguments and returns the overall validation RMSE score over 3-fold cross-validation.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingRegressor</span>

<span class="k">def</span> <span class="nf">get_cv_score</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="c1"># Create KFold object</span>
    <span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>

    <span class="n">rmse_scores</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c1"># Loop through each split</span>
    <span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">train</span><span class="p">):</span>
        <span class="n">cv_train</span><span class="p">,</span> <span class="n">cv_test</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
    
        <span class="c1"># Train a Gradient Boosting model</span>
        <span class="n">gb</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cv_train</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">cv_train</span><span class="o">.</span><span class="n">fare_amount</span><span class="p">)</span>
    
        <span class="c1"># Make predictions on the test data</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">gb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">cv_test</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>
    
        <span class="n">fold_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">cv_test</span><span class="p">[</span><span class="s1">'fare_amount'</span><span class="p">],</span> <span class="n">pred</span><span class="p">))</span>
        <span class="n">rmse_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fold_score</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rmse_scores</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">rmse_scores</span><span class="p">),</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">max_depth_grid</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">15</span><span class="p">]</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c1"># For each value in the grid</span>
<span class="k">for</span> <span class="n">max_depth_candidate</span> <span class="ow">in</span> <span class="n">max_depth_grid</span><span class="p">:</span>
    <span class="c1"># Specify parameters for the model</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'max_depth'</span><span class="p">:</span> <span class="n">max_depth_candidate</span><span class="p">}</span>
    
    <span class="c1"># Calculate validation score for a particular hyperparameter</span>
    <span class="n">validation_score</span> <span class="o">=</span> <span class="n">get_cv_score</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
    
    <span class="c1"># Save the results for each max depth value</span>
    <span class="n">results</span><span class="p">[</span><span class="n">max_depth_candidate</span><span class="p">]</span> <span class="o">=</span> <span class="n">validation_score</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>{3: 5.67086, 6: 5.36931, 9: 5.35615, 12: 5.49952, 15: 5.70183}
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="2D-grid-search">
<a class="anchor" href="#2D-grid-search" aria-hidden="true"><span class="octicon octicon-link"></span></a>2D grid search<a class="anchor-link" href="#2D-grid-search"> </a>
</h3>
<p>The drawback of tuning each hyperparameter independently is a potential dependency between different hyperparameters. The better approach is to try all the possible hyperparameter combinations. However, in such cases, the grid search space is rapidly expanding. For example, if we have 2 parameters with 10 possible values, it will yield 100 experiment runs.</p>
<p>Your goal is to find the best hyperparameter couple of <code>max_depth</code> and <code>subsample</code> for the Gradient Boosting model. <code>subsample</code> is a fraction of observations to be used for fitting the individual trees.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">itertools</span>

<span class="c1"># Hyperparameter grids</span>
<span class="n">max_depth_grid</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="n">subsample_grid</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c1"># For each couple in the grid</span>
<span class="k">for</span> <span class="n">max_depth_candidate</span><span class="p">,</span> <span class="n">subsample_candidate</span> <span class="ow">in</span> <span class="n">itertools</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="n">max_depth_grid</span><span class="p">,</span> <span class="n">subsample_grid</span><span class="p">):</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'max_depth'</span><span class="p">:</span> <span class="n">max_depth_candidate</span><span class="p">,</span>
              <span class="s1">'subsample'</span><span class="p">:</span> <span class="n">subsample_candidate</span><span class="p">}</span>
    <span class="n">validation_score</span> <span class="o">=</span> <span class="n">get_cv_score</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
    <span class="c1"># Save the results fro each couple</span>
    <span class="n">results</span><span class="p">[(</span><span class="n">max_depth_candidate</span><span class="p">,</span> <span class="n">subsample_candidate</span><span class="p">)]</span> <span class="o">=</span> <span class="n">validation_score</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>{(3, 0.8): 5.65813, (3, 0.9): 5.65228, (3, 1.0): 5.67086, (5, 0.8): 5.34925, (5, 0.9): 5.44507, (5, 1.0): 5.3132, (7, 0.8): 5.39073, (7, 0.9): 5.40612, (7, 1.0): 5.35909}
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Model-ensembling">
<a class="anchor" href="#Model-ensembling" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model ensembling<a class="anchor-link" href="#Model-ensembling"> </a>
</h2>
<ul>
<li>Model blending</li>
<li>Model stacking<ol>
<li>Split train data into two parts</li>
<li>Train multiple models on Part 1</li>
<li>Make predictions on Part 2</li>
<li>Make predictions on the test data</li>
<li>Train a new model on Part 2 using predictions as features</li>
<li>Make predictions on the test data using the 2nd level model</li>
</ol>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Model-blending">
<a class="anchor" href="#Model-blending" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model blending<a class="anchor-link" href="#Model-blending"> </a>
</h3>
<p>You will start creating model ensembles with a blending technique.</p>
<p>Your goal is to train 2 different models on the New York City Taxi competition data. Make predictions on the test data and then blend them using a simple arithmetic mean.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'./dataset/taxi_train_distance.csv'</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'./dataset/taxi_test_distance.csv'</span><span class="p">)</span>

<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'pickup_longitude'</span><span class="p">,</span> <span class="s1">'pickup_latitude'</span><span class="p">,</span> <span class="s1">'dropoff_longitude'</span><span class="p">,</span> <span class="s1">'dropoff_latitude'</span><span class="p">,</span> 
            <span class="s1">'passenger_count'</span><span class="p">,</span> <span class="s1">'distance_km'</span><span class="p">,</span> <span class="s1">'hour'</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">gb</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">train</span><span class="o">.</span><span class="n">fare_amount</span><span class="p">)</span>

<span class="c1"># Train a Random Forest model</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">train</span><span class="o">.</span><span class="n">fare_amount</span><span class="p">)</span>

<span class="c1"># Make predictions on the test data</span>
<span class="n">test</span><span class="p">[</span><span class="s1">'gb_pred'</span><span class="p">]</span> <span class="o">=</span> <span class="n">gb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>
<span class="n">test</span><span class="p">[</span><span class="s1">'rf_pred'</span><span class="p">]</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>

<span class="c1"># Find mean of model predictions</span>
<span class="n">test</span><span class="p">[</span><span class="s1">'blend'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s1">'gb_pred'</span><span class="p">]</span> <span class="o">+</span> <span class="n">test</span><span class="p">[</span><span class="s1">'rf_pred'</span><span class="p">])</span> <span class="o">/</span> <span class="mi">2</span>
<span class="n">test</span><span class="p">[[</span><span class="s1">'gb_pred'</span><span class="p">,</span> <span class="s1">'rf_pred'</span><span class="p">,</span> <span class="s1">'blend'</span><span class="p">]]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>gb_pred</th>
      <th>rf_pred</th>
      <th>blend</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>9.661374</td>
      <td>9.057</td>
      <td>9.359187</td>
    </tr>
    <tr>
      <th>1</th>
      <td>9.304288</td>
      <td>8.269</td>
      <td>8.786644</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5.795140</td>
      <td>4.936</td>
      <td>5.365570</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Model-stacking-I">
<a class="anchor" href="#Model-stacking-I" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model stacking I<a class="anchor-link" href="#Model-stacking-I"> </a>
</h3>
<p>Now it's time for stacking. To implement the stacking approach, you will follow the 6 steps:</p>
<ol>
<li>Split train data into two parts</li>
<li>Train multiple models on Part 1</li>
<li>Make predictions on Part 2</li>
<li>Make predictions on the test data</li>
<li>Train a new model on Part 2 using predictions as features</li>
<li>Make predictions on the test data using the 2nd level model</li>
</ol>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">part_1</span><span class="p">,</span> <span class="n">part_2</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>

<span class="c1"># Train a Gradient Boosting model on Part 1</span>
<span class="n">gb</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">part_1</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">part_1</span><span class="o">.</span><span class="n">fare_amount</span><span class="p">)</span>

<span class="c1"># Train a Random Forest model on Part 1</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">part_1</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">part_1</span><span class="o">.</span><span class="n">fare_amount</span><span class="p">)</span>

<span class="c1"># Make predictions on the Part 2 data</span>
<span class="n">part_2</span> <span class="o">=</span> <span class="n">part_2</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">part_2</span><span class="p">[</span><span class="s1">'gb_pred'</span><span class="p">]</span> <span class="o">=</span> <span class="n">gb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">part_2</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>
<span class="n">part_2</span><span class="p">[</span><span class="s1">'rf_pred'</span><span class="p">]</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">part_2</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>

<span class="c1"># Make predictions on the test data</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">test</span><span class="p">[</span><span class="s1">'gb_pred'</span><span class="p">]</span> <span class="o">=</span> <span class="n">gb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>
<span class="n">test</span><span class="p">[</span><span class="s1">'rf_pred'</span><span class="p">]</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Model-stacking-II">
<a class="anchor" href="#Model-stacking-II" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model stacking II<a class="anchor-link" href="#Model-stacking-II"> </a>
</h3>
<p>what you've done so far in the stacking implementation:</p>
<ol>
<li>Split train data into two parts</li>
<li>Train multiple models on Part 1</li>
<li>Make predictions on Part 2</li>
<li>Make predictions on the test data</li>
</ol>
<p>Now, your goal is to create a second level model using predictions from steps 3 and 4 as features. So, this model is trained on Part 2 data and then you can make stacking predictions on the test data.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="c1"># Create linear regression model without the intercept</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">(</span><span class="n">fit_intercept</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Train 2nd level model on the Part 2 data</span>
<span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">part_2</span><span class="p">[[</span><span class="s1">'gb_pred'</span><span class="p">,</span> <span class="s1">'rf_pred'</span><span class="p">]],</span> <span class="n">part_2</span><span class="o">.</span><span class="n">fare_amount</span><span class="p">)</span>

<span class="c1"># Make stacking predictions on the test data</span>
<span class="n">test</span><span class="p">[</span><span class="s1">'stacking'</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">[[</span><span class="s1">'gb_pred'</span><span class="p">,</span> <span class="s1">'rf_pred'</span><span class="p">]])</span>

<span class="c1"># Look at the model coefficients</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[0.27882028 0.72809648]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Usually, the 2nd level model is some simple model like Linear or Logistic Regressions. Also, note that you were not using intercept in the Linear Regression just to combine pure model predictions. Looking at the coefficients, it's clear that 2nd level model has more trust to the Random Forest: 0.7 versus 0.3 for the Gradient Boosting.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Final-tips">
<a class="anchor" href="#Final-tips" aria-hidden="true"><span class="octicon octicon-link"></span></a>Final tips<a class="anchor-link" href="#Final-tips"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Testing-Kaggle-forum-ideas">
<a class="anchor" href="#Testing-Kaggle-forum-ideas" aria-hidden="true"><span class="octicon octicon-link"></span></a>Testing Kaggle forum ideas<a class="anchor-link" href="#Testing-Kaggle-forum-ideas"> </a>
</h3>
<p>Unfortunately, not all the Forum posts and Kernels are necessarily useful for your model. So instead of blindly incorporating ideas into your pipeline, you should test them first.</p>
<p>You're given a function <code>get_cv_score()</code>, which takes a train dataset as an argument and returns the overall validation root mean squared error over 3-fold cross-validation.</p>
<p>You should try different suggestions from the Kaggle Forum and check whether they improve your validation score.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_cv_score</span><span class="p">(</span><span class="n">train</span><span class="p">):</span>
    <span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'pickup_longitude'</span><span class="p">,</span> <span class="s1">'pickup_latitude'</span><span class="p">,</span>
            <span class="s1">'dropoff_longitude'</span><span class="p">,</span> <span class="s1">'dropoff_latitude'</span><span class="p">,</span>
            <span class="s1">'passenger_count'</span><span class="p">,</span> <span class="s1">'distance_km'</span><span class="p">,</span> <span class="s1">'hour'</span><span class="p">,</span> <span class="s1">'weird_feature'</span><span class="p">]</span>
    
    <span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">features</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">train</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
    
    <span class="c1"># Create KFold object</span>
    <span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>

    <span class="n">rmse_scores</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c1"># Loop through each split</span>
    <span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">train</span><span class="p">):</span>
        <span class="n">cv_train</span><span class="p">,</span> <span class="n">cv_test</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
    
        <span class="c1"># Train a Gradient Boosting model</span>
        <span class="n">gb</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cv_train</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">cv_train</span><span class="o">.</span><span class="n">fare_amount</span><span class="p">)</span>
    
        <span class="c1"># Make predictions on the test data</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">gb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">cv_test</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>
    
        <span class="n">fold_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">cv_test</span><span class="p">[</span><span class="s1">'fare_amount'</span><span class="p">],</span> <span class="n">pred</span><span class="p">))</span>
        <span class="n">rmse_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fold_score</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rmse_scores</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">rmse_scores</span><span class="p">),</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">new_train_1</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">'passenger_count'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Compare validation scores</span>
<span class="n">initial_score</span> <span class="o">=</span> <span class="n">get_cv_score</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="n">new_score</span> <span class="o">=</span> <span class="n">get_cv_score</span><span class="p">(</span><span class="n">new_train_1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Initial score is </span><span class="si">{}</span><span class="s1"> and the new score is </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">initial_score</span><span class="p">,</span> <span class="n">new_score</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Initial score is 6.49932 and the new score is 6.42315
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">new_train_2</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># Find sum of pickup latitude and ride distance</span>
<span class="n">new_train_2</span><span class="p">[</span><span class="s1">'weird_feature'</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_train_2</span><span class="p">[</span><span class="s1">'pickup_latitude'</span><span class="p">]</span> <span class="o">+</span> <span class="n">new_train_2</span><span class="p">[</span><span class="s1">'distance_km'</span><span class="p">]</span>

<span class="c1"># Compare validation scores</span>
<span class="n">initial_score</span> <span class="o">=</span> <span class="n">get_cv_score</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="n">new_score</span> <span class="o">=</span> <span class="n">get_cv_score</span><span class="p">(</span><span class="n">new_train_2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Initial score is </span><span class="si">{}</span><span class="s1"> and the new score is </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">initial_score</span><span class="p">,</span> <span class="n">new_score</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Initial score is 6.49932 and the new score is 6.50495
</pre>
</div>
</div>

</div>
</div>

</div>
    

</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="goodboychan/goodboychan.github.io"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/python/datacamp/kaggle/machine_learning/2020/08/12/04-Modeling-used-in-Kaggle.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="https://goodboychan.github.io/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
  <a rel="me" href="https://github.com/goodboychan" target="_blank" title="github">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#github"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://www.linkedin.com/in/chanseokk/" target="_blank" title="linkedin">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#linkedin"></use>
    </svg>
  </a>
</li>
</ul>
</div>

  </div>

</footer>
</body>

</html>
