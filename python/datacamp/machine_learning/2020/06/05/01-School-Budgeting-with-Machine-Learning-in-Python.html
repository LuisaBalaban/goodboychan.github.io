<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>School Budgeting with Machine Learning in Python | Chan`s Jupyter</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="School Budgeting with Machine Learning in Python" />
<meta name="author" content="Chanseok Kang" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A Summary of lecture “Case Study- School Budgeting with Machine Learning in Python”, via datacamp" />
<meta property="og:description" content="A Summary of lecture “Case Study- School Budgeting with Machine Learning in Python”, via datacamp" />
<link rel="canonical" href="https://goodboychan.github.io/python/datacamp/machine_learning/2020/06/05/01-School-Budgeting-with-Machine-Learning-in-Python.html" />
<meta property="og:url" content="https://goodboychan.github.io/python/datacamp/machine_learning/2020/06/05/01-School-Budgeting-with-Machine-Learning-in-Python.html" />
<meta property="og:site_name" content="Chan`s Jupyter" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-06-05T00:00:00-05:00" />
<script type="application/ld+json">
{"headline":"School Budgeting with Machine Learning in Python","url":"https://goodboychan.github.io/python/datacamp/machine_learning/2020/06/05/01-School-Budgeting-with-Machine-Learning-in-Python.html","dateModified":"2020-06-05T00:00:00-05:00","datePublished":"2020-06-05T00:00:00-05:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://goodboychan.github.io/python/datacamp/machine_learning/2020/06/05/01-School-Budgeting-with-Machine-Learning-in-Python.html"},"author":{"@type":"Person","name":"Chanseok Kang"},"description":"A Summary of lecture “Case Study- School Budgeting with Machine Learning in Python”, via datacamp","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://goodboychan.github.io/feed.xml" title="Chan`s Jupyter" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-33905785-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-33905785-1');
</script>


<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>

<script data-ad-client="ca-pub-6747875619665490" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Chan`s Jupyter</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/book/">Book</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">School Budgeting with Machine Learning in Python</h1><p class="page-description">A Summary of lecture "Case Study- School Budgeting with Machine Learning in Python", via datacamp</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-06-05T00:00:00-05:00" itemprop="datePublished">
        Jun 5, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Chanseok Kang</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      37 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#Python">Python</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#Datacamp">Datacamp</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#Machine_Learning">Machine_Learning</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/goodboychan/goodboychan.github.io/tree/main/_notebooks/2020-06-05-01-School-Budgeting-with-Machine-Learning-in-Python.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/goodboychan/goodboychan.github.io/main?filepath=_notebooks%2F2020-06-05-01-School-Budgeting-with-Machine-Learning-in-Python.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/goodboychan/goodboychan.github.io/blob/main/_notebooks/2020-06-05-01-School-Budgeting-with-Machine-Learning-in-Python.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Fgoodboychan%2Fgoodboychan.github.io%2Fblob%2Fmain%2F_notebooks%2F2020-06-05-01-School-Budgeting-with-Machine-Learning-in-Python.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Introducing-the-challenge">Introducing the challenge </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Loading-the-data">Loading the data </a></li>
<li class="toc-entry toc-h3"><a href="#Summarizing-the-data">Summarizing the data </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Looking-at-the-datatypes">Looking at the datatypes </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Exploring-datatypes-in-pandas">Exploring datatypes in pandas </a></li>
<li class="toc-entry toc-h3"><a href="#Encode-the-labels-as-categorical-variables">Encode the labels as categorical variables </a></li>
<li class="toc-entry toc-h3"><a href="#Counting-unique-labels">Counting unique labels </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#How-do-we-measure-success?">How do we measure success? </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Computing-log-loss-with-NumPy">Computing log loss with NumPy </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Time-to-build-model">Time to build model </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Setting-up-a-train-test-split-in-scikit-learn">Setting up a train-test split in scikit-learn </a></li>
<li class="toc-entry toc-h3"><a href="#Training-a-model">Training a model </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Making-predictions">Making predictions </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Use-your-model-to-predict-values-on-holdout-data">Use your model to predict values on holdout data </a></li>
<li class="toc-entry toc-h3"><a href="#Writing-out-your-results-to-a-csv-for-submission">Writing out your results to a csv for submission </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#A-very-brief-introduction-to-NLP">A very brief introduction to NLP </a></li>
<li class="toc-entry toc-h2"><a href="#Representing-text-numerically">Representing text numerically </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Creating-a-bag-of-words-in-scikit-learn">Creating a bag-of-words in scikit-learn </a></li>
<li class="toc-entry toc-h3"><a href="#Combining-text-columns-for-tokenization">Combining text columns for tokenization </a></li>
<li class="toc-entry toc-h3"><a href="#What's-in-a-token?">What&#39;s in a token? </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Pipelines,-feature-&-text-preprocessing">Pipelines, feature &amp; text preprocessing </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Instantiate-pipeline">Instantiate pipeline </a></li>
<li class="toc-entry toc-h3"><a href="#Preprocessing-numeric-features">Preprocessing numeric features </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Text-features-and-feature-unions">Text features and feature unions </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Preprocessing-text-features">Preprocessing text features </a></li>
<li class="toc-entry toc-h3"><a href="#Multiple-types-of-processing:-FunctionTransformer">Multiple types of processing: FunctionTransformer </a></li>
<li class="toc-entry toc-h3"><a href="#Multiple-types-of-processing:-FeatureUnion">Multiple types of processing: FeatureUnion </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Choosing-a-classification-model">Choosing a classification model </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Using-FunctionTransformer-on-the-main-dataset">Using FunctionTransformer on the main dataset </a></li>
<li class="toc-entry toc-h3"><a href="#Add-a-model-to-the-pipeline">Add a model to the pipeline </a></li>
<li class="toc-entry toc-h3"><a href="#Try-a-different-class-of-model">Try a different class of model </a></li>
<li class="toc-entry toc-h3"><a href="#Can-you-adjust-the-model-or-parameters-to-improve-accuracy?">Can you adjust the model or parameters to improve accuracy? </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Learning-from-the-expert:-processing">Learning from the expert: processing </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Deciding-what's-a-word">Deciding what&#39;s a word </a></li>
<li class="toc-entry toc-h3"><a href="#N-gram-range-in-scikit-learn">N-gram range in scikit-learn </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Learning-from-the-expert:-a-stats-trick">Learning from the expert: a stats trick </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Implement-interaction-modeling-in-scikit-learn">Implement interaction modeling in scikit-learn </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Learning-from-the-expert-the-winning-model">Learning from the expert the winning model </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Why-is-hashing-a-useful-trick?">Why is hashing a useful trick? </a></li>
<li class="toc-entry toc-h3"><a href="#Implementing-the-hashing-trick-in-scikit-learn">Implementing the hashing trick in scikit-learn </a></li>
<li class="toc-entry toc-h3"><a href="#Build-the-winning-model">Build the winning model </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-06-05-01-School-Budgeting-with-Machine-Learning-in-Python.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introducing-the-challenge">
<a class="anchor" href="#Introducing-the-challenge" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introducing the challenge<a class="anchor-link" href="#Introducing-the-challenge"> </a>
</h2>
<ul>
<li>Budgets for schools are huge, complex, and not standardize.<ul>
<li>Hundreds of hours each year are spent manually labelling</li>
</ul>
</li>
<li>Goal: Build a machine learning algorithm that can automate the process</li>
<li>Supervised Learning problem</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>Due to the size of dataset, it is not included in this repository, however, you can download it through <a href="https://www.kaggle.com/jeromeblanchet/drivendatas-boxplots-for-education-dataset">kaggle repo</a>
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Loading-the-data">
<a class="anchor" href="#Loading-the-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Loading the data<a class="anchor-link" href="#Loading-the-data"> </a>
</h3>
<p>Now it's time to check out the dataset! You'll use pandas (which has been pre-imported as pd) to load your data into a DataFrame and then do some Exploratory Data Analysis (EDA) of it.</p>
<p>Some of the column names correspond to <strong>features</strong> - descriptions of the budget items - such as the <code>Job_Title_Description</code> column. The values in this column tell us if a budget item is for a teacher, custodian, or other employee.</p>
<p>Some columns correspond to the budget item <strong>labels</strong> you will be trying to predict with your model. For example, the <code>Object_Type</code> column describes whether the budget item is related classroom supplies, salary, travel expenses, etc.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'./dataset/TrainingData.csv'</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Function</th>
      <th>Use</th>
      <th>Sharing</th>
      <th>Reporting</th>
      <th>Student_Type</th>
      <th>Position_Type</th>
      <th>Object_Type</th>
      <th>Pre_K</th>
      <th>Operating_Status</th>
      <th>Object_Description</th>
      <th>...</th>
      <th>Sub_Object_Description</th>
      <th>Location_Description</th>
      <th>FTE</th>
      <th>Function_Description</th>
      <th>Facility_or_Department</th>
      <th>Position_Extra</th>
      <th>Total</th>
      <th>Program_Description</th>
      <th>Fund_Description</th>
      <th>Text_1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>134338</th>
      <td>Teacher Compensation</td>
      <td>Instruction</td>
      <td>School Reported</td>
      <td>School</td>
      <td>NO_LABEL</td>
      <td>Teacher</td>
      <td>NO_LABEL</td>
      <td>NO_LABEL</td>
      <td>PreK-12 Operating</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>KINDERGARTEN</td>
      <td>50471.810</td>
      <td>KINDERGARTEN</td>
      <td>General Fund</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>206341</th>
      <td>NO_LABEL</td>
      <td>NO_LABEL</td>
      <td>NO_LABEL</td>
      <td>NO_LABEL</td>
      <td>NO_LABEL</td>
      <td>NO_LABEL</td>
      <td>NO_LABEL</td>
      <td>NO_LABEL</td>
      <td>Non-Operating</td>
      <td>CONTRACTOR SERVICES</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>RGN  GOB</td>
      <td>NaN</td>
      <td>UNDESIGNATED</td>
      <td>3477.860</td>
      <td>BUILDING IMPROVEMENT SERVICES</td>
      <td>NaN</td>
      <td>BUILDING IMPROVEMENT SERVICES</td>
    </tr>
    <tr>
      <th>326408</th>
      <td>Teacher Compensation</td>
      <td>Instruction</td>
      <td>School Reported</td>
      <td>School</td>
      <td>Unspecified</td>
      <td>Teacher</td>
      <td>Base Salary/Compensation</td>
      <td>Non PreK</td>
      <td>PreK-12 Operating</td>
      <td>Personal Services - Teachers</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>TEACHER</td>
      <td>62237.130</td>
      <td>Instruction - Regular</td>
      <td>General Purpose School</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>364634</th>
      <td>Substitute Compensation</td>
      <td>Instruction</td>
      <td>School Reported</td>
      <td>School</td>
      <td>Unspecified</td>
      <td>Substitute</td>
      <td>Benefits</td>
      <td>NO_LABEL</td>
      <td>PreK-12 Operating</td>
      <td>EMPLOYEE BENEFITS</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>UNALLOC BUDGETS/SCHOOLS</td>
      <td>NaN</td>
      <td>PROFESSIONAL-INSTRUCTIONAL</td>
      <td>22.300</td>
      <td>GENERAL MIDDLE/JUNIOR HIGH SCH</td>
      <td>NaN</td>
      <td>REGULAR INSTRUCTION</td>
    </tr>
    <tr>
      <th>47683</th>
      <td>Substitute Compensation</td>
      <td>Instruction</td>
      <td>School Reported</td>
      <td>School</td>
      <td>Unspecified</td>
      <td>Teacher</td>
      <td>Substitute Compensation</td>
      <td>NO_LABEL</td>
      <td>PreK-12 Operating</td>
      <td>TEACHER COVERAGE FOR TEACHER</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NON-PROJECT</td>
      <td>NaN</td>
      <td>PROFESSIONAL-INSTRUCTIONAL</td>
      <td>54.166</td>
      <td>GENERAL HIGH SCHOOL EDUCATION</td>
      <td>NaN</td>
      <td>REGULAR INSTRUCTION</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 25 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Function</th>
      <th>Use</th>
      <th>Sharing</th>
      <th>Reporting</th>
      <th>Student_Type</th>
      <th>Position_Type</th>
      <th>Object_Type</th>
      <th>Pre_K</th>
      <th>Operating_Status</th>
      <th>Object_Description</th>
      <th>...</th>
      <th>Sub_Object_Description</th>
      <th>Location_Description</th>
      <th>FTE</th>
      <th>Function_Description</th>
      <th>Facility_or_Department</th>
      <th>Position_Extra</th>
      <th>Total</th>
      <th>Program_Description</th>
      <th>Fund_Description</th>
      <th>Text_1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>109283</th>
      <td>Professional Development</td>
      <td>ISPD</td>
      <td>Shared Services</td>
      <td>Non-School</td>
      <td>Unspecified</td>
      <td>Instructional Coach</td>
      <td>Other Compensation/Stipend</td>
      <td>NO_LABEL</td>
      <td>PreK-12 Operating</td>
      <td>WORKSHOP PARTICIPANT</td>
      <td>...</td>
      <td>NaN</td>
      <td>STAFF DEV AND INSTR MEDIA</td>
      <td>NaN</td>
      <td>INST STAFF TRAINING SVCS</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>48.620000</td>
      <td>NaN</td>
      <td>GENERAL FUND</td>
      <td>STAFF DEV AND INSTR MEDIA</td>
    </tr>
    <tr>
      <th>102430</th>
      <td>Substitute Compensation</td>
      <td>Instruction</td>
      <td>School Reported</td>
      <td>School</td>
      <td>Unspecified</td>
      <td>Substitute</td>
      <td>Base Salary/Compensation</td>
      <td>NO_LABEL</td>
      <td>PreK-12 Operating</td>
      <td>SALARIES OF PART TIME EMPLOYEE</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.00431</td>
      <td>TITLE II,D</td>
      <td>NaN</td>
      <td>PROFESSIONAL-INSTRUCTIONAL</td>
      <td>128.824985</td>
      <td>INSTRUCTIONAL STAFF TRAINING</td>
      <td>NaN</td>
      <td>INSTRUCTIONAL STAFF</td>
    </tr>
    <tr>
      <th>413949</th>
      <td>Parent &amp; Community Relations</td>
      <td>NO_LABEL</td>
      <td>School Reported</td>
      <td>School</td>
      <td>NO_LABEL</td>
      <td>Other</td>
      <td>NO_LABEL</td>
      <td>NO_LABEL</td>
      <td>PreK-12 Operating</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.00000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>PARENT/TITLE I</td>
      <td>4902.290000</td>
      <td>Misc</td>
      <td>Schoolwide Schools</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>433672</th>
      <td>Library &amp; Media</td>
      <td>Instruction</td>
      <td>School on Central Budgets</td>
      <td>Non-School</td>
      <td>Unspecified</td>
      <td>Librarian</td>
      <td>Benefits</td>
      <td>NO_LABEL</td>
      <td>PreK-12 Operating</td>
      <td>EMPLOYEE BENEFITS</td>
      <td>...</td>
      <td>NaN</td>
      <td>ED RESOURCE SERVICES</td>
      <td>NaN</td>
      <td>NON-PROJECT</td>
      <td>NaN</td>
      <td>OFFICE/ADMINISTRATIVE SUPPORT</td>
      <td>4020.290000</td>
      <td>MEDIA SUPPORT SERVICES</td>
      <td>NaN</td>
      <td>INSTRUCTIONAL STAFF</td>
    </tr>
    <tr>
      <th>415831</th>
      <td>Substitute Compensation</td>
      <td>Instruction</td>
      <td>School Reported</td>
      <td>School</td>
      <td>Poverty</td>
      <td>Substitute</td>
      <td>Substitute Compensation</td>
      <td>Non PreK</td>
      <td>PreK-12 Operating</td>
      <td>Salaries And Wages For Substitute Professionals</td>
      <td>...</td>
      <td>Inservice Substitute Teachers Grant Funded</td>
      <td>School</td>
      <td>NaN</td>
      <td>Instruction</td>
      <td>Instruction And Curriculum</td>
      <td>CERTIFIED SUBSTITUTE</td>
      <td>46.530000</td>
      <td>Accelerated Education</td>
      <td>"Title  Part A Improving Basic Programs"</td>
      <td>MISCELLANEOUS</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 25 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;class 'pandas.core.frame.DataFrame'&gt;
Int64Index: 400277 entries, 134338 to 415831
Data columns (total 25 columns):
 #   Column                  Non-Null Count   Dtype  
---  ------                  --------------   -----  
 0   Function                400277 non-null  object 
 1   Use                     400277 non-null  object 
 2   Sharing                 400277 non-null  object 
 3   Reporting               400277 non-null  object 
 4   Student_Type            400277 non-null  object 
 5   Position_Type           400277 non-null  object 
 6   Object_Type             400277 non-null  object 
 7   Pre_K                   400277 non-null  object 
 8   Operating_Status        400277 non-null  object 
 9   Object_Description      375493 non-null  object 
 10  Text_2                  88217 non-null   object 
 11  SubFund_Description     306855 non-null  object 
 12  Job_Title_Description   292743 non-null  object 
 13  Text_3                  109152 non-null  object 
 14  Text_4                  53746 non-null   object 
 15  Sub_Object_Description  91603 non-null   object 
 16  Location_Description    162054 non-null  object 
 17  FTE                     126071 non-null  float64
 18  Function_Description    342195 non-null  object 
 19  Facility_or_Department  53886 non-null   object 
 20  Position_Extra          264764 non-null  object 
 21  Total                   395722 non-null  float64
 22  Program_Description     304660 non-null  object 
 23  Fund_Description        202877 non-null  object 
 24  Text_1                  292285 non-null  object 
dtypes: float64(2), object(23)
memory usage: 79.4+ MB
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Summarizing-the-data">
<a class="anchor" href="#Summarizing-the-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Summarizing the data<a class="anchor-link" href="#Summarizing-the-data"> </a>
</h3>
<p>You'll continue your EDA in this exercise by computing summary statistics for the numeric data in the dataset.</p>
<p>You can use df.info() in the IPython Shell to determine which columns of the data are numeric, specifically type float64. You'll notice that there are two numeric columns, called FTE and Total.</p>
<ul>
<li>FTE: Stands for "full-time equivalent". If the budget item is associated to an employee, this number tells us the percentage of full-time that the employee works. A value of 1 means the associated employee works for the school full-time. A value close to 0 means the item is associated to a part-time or contracted employee.</li>
<li>Total: Stands for the total cost of the expenditure. This number tells us how much the budget item cost.</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>FTE</th>
      <th>Total</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>126071.000000</td>
      <td>3.957220e+05</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.426794</td>
      <td>1.310586e+04</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.573576</td>
      <td>3.682254e+05</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-0.087551</td>
      <td>-8.746631e+07</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.000792</td>
      <td>7.379770e+01</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.130927</td>
      <td>4.612300e+02</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.000000</td>
      <td>3.652662e+03</td>
    </tr>
    <tr>
      <th>max</th>
      <td>46.800000</td>
      <td>1.297000e+08</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'FTE'</span><span class="p">]</span><span class="o">.</span><span class="n">dropna</span><span class="p">(),</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Add title and labels</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Distribution of </span><span class="si">%f</span><span class="s1">ull-time </span><span class="se">\n</span><span class="s1"> employee works'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'</span><span class="si">% o</span><span class="s1">f full-time'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'num employee'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Text(0, 0.5, 'num employee')</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAZcAAAElCAYAAAAoZK9zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZwdVZ338c/XhB3ZAwMJEpCoBAZRI+I2IjgQFg2jrA9LQJyIg9uIg0EdUYRncBRBH0WHMZGArIM6BAUxsig6soRFICASA5IQBgIhEBCBwPf5o07LTed253a67m26+/t+ve6rb/3q1Klzq5P763Oq6pRsExERUadXDHQDIiJi6ElyiYiI2iW5RERE7ZJcIiKidkkuERFRuySXiIioXZJLvCxJ+q6kf62prldJekrSiLJ8raQP1VF3qe8KSZPrqq8P+z1Z0qOS/reGul4r6VZJSyV9vIXylrRteX+2pJP7sK/lfh8xNCW5RMdJul/SM+WLbImk/5F0jKS//nu0fYztL7dY13t6K2P7Advr2n6hhrZ/UdIPutW/l+0Z/a27j+3YEjgOGG/7b5qtl3S9pMWSTuu27meSJnTb5HjgWtuvtP3Nmtu63O+ozt9HvHwlucRAea/tVwJbAacCnwGm1b0TSSPrrvNlYivgMduP9LD+BGAGsDWwX1cykXQQMM/27Cb1zWlXY2P4SXKJAWX7CdszgYOAyZJ2gOWHWiRtIuknpZezWNJ1kl4h6VzgVcBlZZjleEljy5DN0ZIeAK5uiDUmmldLulHSE5IulbRR2deukhY0trHrL29JE4HPAgeV/f2urP/rMFtp1+cl/UnSI5LOkbR+WdfVjsmSHihDWp/r6dhIWr9sv6jU9/lS/3uAWcAWpR1nN9l8a+Bq208ANwHbSFoPmFo+Q+N+rgbeDXyr1Pea7kOHko6U9OtefpU9fYbefkcjG47fyaUH+5SkyyRtLOk8SU9KuknS2IY6XydpVvm3cI+kA/varmi/JJd4WbB9I7AAeGeT1ceVdaOAzai+HG37cOABql7Qurb/vWGbdwHbAXv2sMsjgA8CWwDLgJUOBdn+GfB/gYvK/l7fpNiR5fVuYBtgXeBb3cq8A3gtsDvwBUnb9bDL/wesX+p5V2nzUbZ/AewFLCztOLLJtncCfy9pA2ACcBfwZeAM20u6fa7dgOuAj5b6/tDjQeijlfyOGh0MHA6MBl4N/Bb4PrARcDdwIoCkdagS6/nApsAhwJmStq+rzVGPJJd4OVlI9WXS3fPA5sBWtp+3fZ1XPineF20/bfuZHtafa/tO208D/wocWNMJ5kOBr9ueZ/spquGpg7v1mr5k+xnbvwN+B6yQpEpbDgJOsL3U9v3AaVRfwK34N6pE/Uvg28BqwI5UPYjzJf1K0kdX7SO2xfdt/7H0tK4A/mj7F7aXAf8FvKGU2xe43/b3bS+zfQvwQ2D/gWl29CTJJV5ORgOLm8S/CswFfi5pnqSpLdQ1vw/r/0T15btJS63s3Ralvsa6R1L1uLo0Xt31Z6reTXebAKs3qWt0K42wvdj2QaV39Q2qXtDHqIbF7gTeAxwjaXwr9bVK1ZVzT5XXoX3Y9OGG9880We46RlsBbylDpEskLaFK6Ctc1BADa6ie7IxBRtKbqb44VxjXt72UamjsuDL8cY2km2xfBfTUg1lZz2bLhvevouodPQo8Dazd0K4RVMNxrda7kOoLsLHuZVRflmNWsm2jR0ubtqIa0uqq68E+1NFlCnC97Tsl/S1wuu3nJN0B7NBQf6PljgMtfnnb3qtZuK8N7sV84Je2/77GOqMN0nOJASVpPUn7AhcCP7B9R5My+0raVpKAJ4EXyguqL+1tVmHXh0kaL2lt4CTgknJp7B+ANSXtI2k14PPAGg3bPQyMVcNl091cAPyzpK0lrctL52iW9aVxpS0XA6dIeqWkrYBPAT/ofcvlSdoUOBb4YgndB7y7tG0CMK+HTW8D3i9pbVX3sxzdl/12s6q/o2Z+ArxG0uGSViuvN/dy3ioGSJJLDJTLJC2l+kv0c8DXgaN6KDsO+AXwFNWJ3jNtX1vW/Rvw+TJE8uk+7P9c4GyqIao1gY9DdfUa8E/A96h6CU9TXUzQ5b/Kz8ck3dKk3uml7l9RfZH/hWo4alV8rOx/HlWP7vxSf198DTipnP+B6njtRnXcZza5JLnL6cBzVIlhBnBeH/fbaFV/Rysovdg9qC4AWEj1+/sKy/8BEC8DysPCIiKibum5RERE7ZJcIiKidkkuERFRuySXiIioXZJLRM2azU82VHWfgyyiS5JLRETULnfoR0SflRtaNdDtiJev9Fxi2OhtqnZVU/yf2TA31m8k/Y2kMyQ9Lun3kt7QUP5+SSdIuqus/76kNXvY73Zl+GiJpDmS3lfib5b0cOOklpI+IOm28v4VkqZK+qOkxyRdrPJogLJ+lzJN/RJJv5O0aw/7P0rSZQ3LcyVd3LA8X9JO5f3byhT3T5Sfb2sod62kUyT9hmpOtG267WdzSbd33Sipapr+eaoeCndfH+cai8HOdl55DfkXsA7VXelHUfXY30g1f9f2Zf3ZZflNVHfsX011h/0RwAjgZOCahvrup5oAckuqmZx/A5xc1u0KLCjvV6OadPOzVBNR7gYsBV5b1t8F7NVQ74+B48r7TwLXU81JtgbwH8AFZd1o4DFgb6o/Ev++LI9q8tm3AZaUcptTTYD5YMO6x8u6jcr7w8sxOqQsb1zKXks1ff72Zf1qJfYhYCzV1DlTGo73kw2fc/OuY53X8Hil5xLDRStTtf/Y9s22/0L1Jf8X2+e4mufrIl6a9r3Lt2zPt70YOIXqy7i7Xahm9D3V9nO2r6aaH6ur7AzgMIDSK9mTapoXgA8Dn7O9wPazVPOD7V96OocBl9u+3PaLtmcBs6mSzXJsz6NKaDtRPRfmSuBBSa8ry9fZfhHYB7jX9rnlGF0A/B54b0N1Z9ueU9Y/X2LjqZLMibbPaij7IrCDpLVsP2Q7T7ocRnLOJYaLv07V3hAbSTUPWJdWp33v0n3a/i2a7HcLYH758m4s2zV1/g+Au8tEkgdSfdE/1NDmH0tq3PYFqun7twIOkNT4xb8acE2TNkD1XJddgW3L+yVUieWtZbmrrX/qtl33af6bPcrgUKre2SVdAdtPq3qk8qeBaWUo7Tjbv++hfTHEpOcSw0XXVO0bNLzWtf2RftTZfdr+hU3KLAS27DaL8l+nzrf9INVknP9ANRzVmOzmUw2ZNbZ5zbLNfKoHnjWuW8f2qT20tSu5dD1A7JdUyeVdvJRcuj8uYLm2Fs0mI/wi1ZDi+Wp44JrtK11Njb85VQ/oP3toWwxBSS4xXLRjqvZjJY0pw1mfpRo66+4GqpmNjy/73JVqmOnChjLnAMcDf0s1HNflu1RT7m8FIGmUpEll3Q+A90raU9IISWuW+2t6embML6kevbyW7QVUjzWeCGwM3FrKXE51jP6PpJGl5zGe6tj15nngAKrzLOeWCxE2k/Q+VY8lfpZqRusXeqskhpYklxgW3J6p2s8Hfk41Jf48qpP+3ff7HPA+qmfePwqcCRzRbXjox5QhMFePXe7yDWAm1RM4l1Kd3H9LqXc+MIkqqS2i6sn8Cz38n7b9B6ov+OvK8pOlzb8p55Sw/RjVuanjqC4OOB7Y1/ajKzsQ5XO+n+q59tOphhyPozrWi6l6SP+0snpi6MiU+xGrQNL9wIds/6Km+v4IfLiu+iIGWnouEQNM0geozmVcPdBtiahLrhaLGECSrqU6r3F4tyvKIga1DItFRETtMiwWERG1y7BYsckmm3js2LED3YyIiEHl5ptvftT2qO7xJJdi7NixzJ49e6CbERExqEjqPqsDkGGxiIhogySXiIioXZJLRETULsklIiJql+QSERG1S3KJiIjaJblERETtklwiIqJ2SS4REVG73KFfg7FTfzpg+77/1H0GbN8RET1JzyUiImqX5BIREbVLcomIiNoluURERO2SXCIionZtSy6Spkt6RNKdDbGvSvq9pNsl/VjSBg3rTpA0V9I9kvZsiE8ssbmSpjbEt5Z0g6R7JV0kafUSX6Mszy3rx7brM0ZERHPt7LmcDUzsFpsF7GB7R+APwAkAksYDBwPbl23OlDRC0gjg28BewHjgkFIW4CvA6bbHAY8DR5f40cDjtrcFTi/lIiKig9qWXGz/CljcLfZz28vK4vXAmPJ+EnCh7Wdt3wfMBXYur7m259l+DrgQmCRJwG7AJWX7GcB+DXXNKO8vAXYv5SMiokMG8pzLB4EryvvRwPyGdQtKrKf4xsCShkTVFV+urrL+iVI+IiI6ZECSi6TPAcuA87pCTYp5FeK91dWsHVMkzZY0e9GiRb03OiIiWtbx5CJpMrAvcKjtri/9BcCWDcXGAAt7iT8KbCBpZLf4cnWV9evTbXiui+2zbE+wPWHUqFH9/WgREVF0NLlImgh8Bnif7T83rJoJHFyu9NoaGAfcCNwEjCtXhq1OddJ/ZklK1wD7l+0nA5c21DW5vN8fuLohiUVERAe0beJKSRcAuwKbSFoAnEh1ddgawKxyjv1628fYniPpYuAuquGyY22/UOr5KHAlMAKYbntO2cVngAslnQzcCkwr8WnAuZLmUvVYDm7XZ4yIiOballxsH9IkPK1JrKv8KcApTeKXA5c3ic+jupqse/wvwAF9amxERNQqd+hHRETtklwiIqJ2SS4REVG7JJeIiKhdkktERNQuySUiImqX5BIREbVLcomIiNoluURERO2SXCIionZJLhERUbskl4iIqF2SS0RE1C7JJSIiapfkEhERtUtyiYiI2iW5RERE7ZJcIiKidkkuERFRuySXiIioXZJLRETULsklIiJql+QSERG1S3KJiIjatS25SJou6RFJdzbENpI0S9K95eeGJS5J35Q0V9Ltkt7YsM3kUv5eSZMb4m+SdEfZ5puS1Ns+IiKic9rZczkbmNgtNhW4yvY44KqyDLAXMK68pgDfgSpRACcCbwF2Bk5sSBbfKWW7tpu4kn1ERESHtC252P4VsLhbeBIwo7yfAezXED/HleuBDSRtDuwJzLK92PbjwCxgYlm3nu3f2jZwTre6mu0jIiI6pNPnXDaz/RBA+blpiY8G5jeUW1BivcUXNIn3to8VSJoiabak2YsWLVrlDxUREct7uZzQV5OYVyHeJ7bPsj3B9oRRo0b1dfOIiOhBp5PLw2VIi/LzkRJfAGzZUG4MsHAl8TFN4r3tIyIiOqTTyWUm0HXF12Tg0ob4EeWqsV2AJ8qQ1pXAHpI2LCfy9wCuLOuWStqlXCV2RLe6mu0jIiI6ZGS7KpZ0AbArsImkBVRXfZ0KXCzpaOAB4IBS/HJgb2Au8GfgKADbiyV9GbiplDvJdtdFAh+huiJtLeCK8qKXfURERIe0LbnYPqSHVbs3KWvg2B7qmQ5MbxKfDezQJP5Ys31ERETnvFxO6EdExBCS5BIREbVLcomIiNoluURERO2SXCIionZJLhERUbskl4iIqF2SS0RE1C7JJSIiapfkEhERtUtyiYiI2iW5RERE7ZJcIiKidkkuERFRuySXiIio3UqTi6TXSLpK0p1leUdJn29/0yIiYrBqpefyn8AJwPMAtm8HDm5noyIiYnBrJbmsbfvGbrFl7WhMREQMDa0kl0clvRowgKT9gYfa2qqIiBjURrZQ5ljgLOB1kh4E7gMOa2urIiJiUFtpcrE9D3iPpHWAV9he2v5mRUTEYNbK1WKbSZoGXGJ7qaTxko7uQNsiImKQauWcy9nAlcAWZfkPwCfb1aCIiBj8Wkkum9i+GHgRwPYy4IW2tioiIga1VpLL05I25qWrxXYBnujPTiX9s6Q5ku6UdIGkNSVtLekGSfdKukjS6qXsGmV5blk/tqGeE0r8Hkl7NsQnlthcSVP709aIiOi7VpLLccBM4NWSfgOcA3xsVXcoaTTwcWCC7R2AEVQ3ZX4FON32OOBxoOu8ztHA47a3BU4v5ZA0vmy3PTAROFPSCEkjgG8DewHjgUNK2YiI6JCVJhfbNwPvAt4GfBjYvtyl3x8jgbUkjQTWprpvZjfgkrJ+BrBfeT+pLFPW7y5JJX6h7Wdt3wfMBXYur7m259l+DriwlI2IiA5p5Wqx2cAUYKHtO20/358d2n4Q+BrwAFVSeQK4GVhSzucALABGl/ejgfll22Wl/MaN8W7b9BRv9tmmSJotafaiRYv687EiIqJBK8NiB1N9Od8k6UJJe5aewyqRtCFVT2JrqivQ1qEawurOXZv0sK6v8RWD9lm2J9ieMGrUqJU1PSIiWtTKsNhc258DXgOcD0wHHpD0JUkbrcI+3wPcZ3tR6QX9iGrIbYMyTAYwBlhY3i8AtgQo69cHFjfGu23TUzwiIjqkpee5SNoROA34KvBDYH/gSeDqVdjnA8AuktYuPaDdgbuAa0q9AJOBS8v7mWWZsv5q2y7xg8vVZFsD44AbgZuAceXqs9Wpel4zV6GdERGxilY6/Yukm4ElwDRgqu1ny6obJL29rzu0fYOkS4BbqGZXvpVq7rKfAhdKOrnEppVNpgHnSppL1WM5uNQzR9LFVIlpGXCs7RdKmz9KdePnCGC67Tl9bWdERKw6VZ2AXgpI25T5xYa0CRMmePbs2au07dipP625Na27/9R9BmzfERGSbrY9oXu8lWGxxyR9veuqKkmnSVq/DW2MiIghopXkMh1YChxYXk8C329noyIiYnBr5Xkur7b9gYblL0m6rV0NioiIwa+Vnsszkt7RtVBO4j/TviZFRMRg10rP5SPAjHKeRVRXbB3ZzkZFRMTg1sqTKG8DXi9pvbL8ZNtbFRERg1qPyUXSp3qIA2D7621qU0REDHK99Vxe2bFWRETEkNJjcrH9pU42JCIiho5WptzfRtJlkhZJekTSpZK26UTjIiJicGrlUuTzgYuBzammyP8v4IJ2NioiIga3VpKLbJ9re1l5/YAeno8SEREBrd3nco2kqVSPCzZwEPDTrme52F7cxvZFRMQg1EpyOaj8/HC3+Aepkk3Ov0RExHJauYly6040JCIiho5WHhY2AtgHGNtYPjdRRkRET1oZFrsM+AtwB/Bie5sTERFDQSvJZYztHdvekoiIGDJauRT5Ckl7tL0lERExZLTSc7ke+LGkVwDPU027b9vrtbVlERExaLWSXE4D3grcYTs3T0ZExEq1Mix2L3BnEktERLSqlZ7LQ8C1kq4Anu0K5lLkiIjoSSvJ5b7yWr28IiIietXKHfpfApC0ju2n69ippA2A7wE7UE0h80HgHuAiqps17wcOtP24qkdffgPYG/gzcKTtW0o9k4HPl2pPtj2jxN8EnA2sBVwOfCLDehERndPK81zeKuku4O6y/HpJZ/Zzv98Afmb7dcDrS91TgatsjwOuKssAewHjymsK8J3Sjo2AE4G3ADsDJ0rasGzznVK2a7uJ/WxvRET0QSsn9M8A9gQeA7D9O+DvVnWHktYr208r9T1newkwCZhRis0A9ivvJwHnuHI9sIGkzUubZtlebPtxYBYwsaxbz/ZvS2/lnIa6IiKiA1pJLtie3y30Qj/2uQ2wCPi+pFslfU/SOsBmth8q+3sI2LSUHw007n9BifUWX9AkvgJJUyTNljR70aJF/fhIERHRqJXkMl/S2wBLWl3SpylDZKtoJPBG4Du23wA8zUtDYM2oScyrEF8xaJ9le4LtCaNGjeq91RER0bJWkssxwLG81CPYqSyvqgXAAts3lOVLqJLNw2VIi/LzkYbyWzZsPwZYuJL4mCbxiIjokJUmF9uP2j7U9ma2N7V9mO3HVnWHtv+Xqjf02hLaHbgLmAlMLrHJwKXl/UzgCFV2AZ4ow2ZXAntI2rCcyN8DuLKsWyppl3Kl2RENdUVERAe0cp9LO3wMOE/S6sA84CiqRHexpKOBB4ADStnLqS5Dnkt1KfJRUD1eWdKXgZtKuZMaHrn8EV66FPmK8oqIiA4ZkORi+zZgQpNVuzcpa3oYhrM9HZjeJD6b6h6aiIgYAC1dLRYREdEXrTzmeAOq8xZjWf4xxx9vX7MiImIwa2VY7HKqZ7rkMccREdGSVpLLmrY/1faWRETEkNHKOZdzJf2jpM0lbdT1anvLIiJi0Gql5/Ic8FXgc7x0p7uppnGJiIhYQSvJ5VPAtrYfbXdjIiJiaGhlWGwO1c2LERERLWml5/ICcJuka1j+Mce5FDkiIppqJbn8d3lFRES0pJXHHM9YWZmIiIhGrdyhfx9NnodiO1eLRUREU60MizVOMLkm1WzFuc8lIiJ61MrzXB5reD1o+wxgtw60LSIiBqlWhsXe2LD4CqqezCvb1qKIiBj0WhkWO63h/TLgfuDAtrQmIiKGhFauFnt3JxoSERFDRyvDYmsAH2DF57mc1L5mRUTEYNbKsNilwBPAzTTcoR8REdGTVpLLGNsT296SiIgYMlqZuPJ/JP1t21sSERFDRis9l3cAR5Y79Z8FBNj2jm1tWUREDFqtJJe92t6KiIgYUlq5FPlPnWhIREQMHa2cc2kLSSMk3SrpJ2V5a0k3SLpX0kWSVi/xNcry3LJ+bEMdJ5T4PZL2bIhPLLG5kqZ2+rNFRAx3A5ZcgE8AdzcsfwU43fY44HHg6BI/Gnjc9rbA6aUcksYDBwPbAxOBM0vCGgF8m2o4bzxwSCkbEREdMiDJRdIYYB/ge2VZVJNhXlKKzAD2K+8nlWXK+t1L+UnAhbaftX0fMBfYubzm2p5n+zngwlI2IiI6ZKB6LmcAxwMvluWNgSW2l5XlBcDo8n40MB+grH+ilP9rvNs2PcVXIGmKpNmSZi9atKi/nykiIoqOJxdJ+wKP2L65MdykqFeyrq/xFYP2WbYn2J4watSoXlodERF90cqlyHV7O/A+SXtTPXxsPaqezAaSRpbeyRhgYSm/ANgSWCBpJLA+sLgh3qVxm57iERHRAR3vudg+wfYY22OpTshfbftQ4Bpg/1JsMtWcZgAzyzJl/dW2XeIHl6vJtgbGATcCNwHjytVnq5d9zOzAR4uIiGIgei49+QxwoaSTgVuBaSU+DThX0lyqHsvBALbnSLoYuIvqOTPH2n4BQNJHgSuBEcB023M6+kkiIoa5AU0utq8Fri3v51Fd6dW9zF+AA3rY/hTglCbxy4HLa2xqRET0wUDe5xIREUNUkktERNQuySUiImqX5BIREbVLcomIiNoluURERO2SXCIionZJLhERUbskl4iIqF2SS0RE1C7JJSIiapfkEhERtUtyiYiI2iW5RERE7ZJcIiKidkkuERFRuySXiIioXZJLRETULsklIiJql+QSERG1S3KJiIjaJblERETtklwiIqJ2SS4REVG7jicXSVtKukbS3ZLmSPpEiW8kaZake8vPDUtckr4paa6k2yW9saGuyaX8vZImN8TfJOmOss03JanTnzMiYjgbiJ7LMuA429sBuwDHShoPTAWusj0OuKosA+wFjCuvKcB3oEpGwInAW4CdgRO7ElIpM6Vhu4kd+FwREVF0PLnYfsj2LeX9UuBuYDQwCZhRis0A9ivvJwHnuHI9sIGkzYE9gVm2F9t+HJgFTCzr1rP9W9sGzmmoKyIiOmBAz7lIGgu8AbgB2Mz2Q1AlIGDTUmw0ML9hswUl1lt8QZN4s/1PkTRb0uxFixb19+NEREQxYMlF0rrAD4FP2n6yt6JNYl6F+IpB+yzbE2xPGDVq1MqaHBERLRqQ5CJpNarEcp7tH5Xww2VIi/LzkRJfAGzZsPkYYOFK4mOaxCMiokMG4moxAdOAu21/vWHVTKDriq/JwKUN8SPKVWO7AE+UYbMrgT0kbVhO5O8BXFnWLZW0S9nXEQ11RUREB4wcgH2+HTgcuEPSbSX2WeBU4GJJRwMPAAeUdZcDewNzgT8DRwHYXizpy8BNpdxJtheX9x8BzgbWAq4or4iI6JCOJxfbv6b5eRGA3ZuUN3BsD3VNB6Y3ic8GduhHMyMioh9yh35ERNQuySUiImqX5BIREbVLcomIiNoluURERO2SXCIionZJLhERUbskl4iIqF2SS0RE1C7JJSIiapfkEhERtUtyiYiI2iW5RERE7ZJcIiKidkkuERFRuySXiIioXZJLRETULsklIiJql+QSERG1S3KJiIjaJblERETtklwiIqJ2SS4REVG7JJeIiKjdkE0ukiZKukfSXElTB7o9ERHDyZBMLpJGAN8G9gLGA4dIGj+wrYqIGD6GZHIBdgbm2p5n+zngQmDSALcpImLYGDnQDWiT0cD8huUFwFu6F5I0BZhSFp+SdE8/9rkJ8Gg/tl8l+kqn99irATkGLzPD/RgM988Pw+8YbNUsOFSTi5rEvELAPgs4q5YdSrNtT6ijrsEqxyDHYLh/fsgx6DJUh8UWAFs2LI8BFg5QWyIihp2hmlxuAsZJ2lrS6sDBwMwBblNExLAxJIfFbC+T9FHgSmAEMN32nDbvtpbhtUEuxyDHYLh/fsgxAED2CqciIiIi+mWoDotFRMQASnKJiIjaJbn003CcZkbSdEmPSLqzIbaRpFmS7i0/NxzINrabpC0lXSPpbklzJH2ixIfNcZC0pqQbJf2uHIMvlfjWkm4ox+CiclHNkCZphKRbJf2kLA+7Y9Bdkks/DONpZs4GJnaLTQWusj0OuKosD2XLgONsbwfsAhxbfvfD6Tg8C+xm+/XATsBESbsAXwFOL8fgceDoAWxjp3wCuLtheTgeg+UkufTPsJxmxvavgMXdwpOAGeX9DGC/jjaqw2w/ZPuW8n4p1RfLaIbRcXDlqbK4WnkZ2A24pMSH9DEAkDQG2Af4XlkWw+wYNJPk0j/NppkZPUBtGWib2X4Iqi9eYNMBbk/HSBoLvAG4gWF2HMpw0G3AI8As4I/AEtvLSpHh8H/iDOB44MWyvDHD7xisIMmlf1qaZiaGLknrAj8EPmn7yYFuT6fZfsH2TlSzYOwMbNesWGdb1TmS9gUesX1zY7hJ0SF7DHoyJG+i7KBMM/OShyVtbvshSZtT/SU7pElajSqxnGf7RyU87I4DgO0lkq6lOv+0gaSR5S/3of5/4u3A+yTtDawJrEfVkxlOx6Cp9Fz6J9PMvGQmMLm8nwxcOoBtabsyrj4NuNv2157pDrIAAANZSURBVBtWDZvjIGmUpA3K+7WA91Cde7oG2L8UG9LHwPYJtsfYHkv1//9q24cyjI5BT3KHfj+Vv1jO4KVpZk4Z4Ca1naQLgF2pphZ/GDgR+G/gYuBVwAPAAba7n/QfMiS9A7gOuIOXxto/S3XeZVgcB0k7Up2sHkH1h+rFtk+StA3VxS0bAbcCh9l+duBa2hmSdgU+bXvf4XoMGiW5RERE7TIsFhERtUtyiYiI2iW5RERE7ZJcIiKidkkuERFRuySXiF6Uezl+LelOSfs1xC+VtMUq1HVDmT33nd3WvbPMLHxbuWekpzqulTShvL9f0iZNyuwq6W0Ny8dIOqIvbY3orySXiN4dQnUvx1uBfwGQ9F7gFtt9vet6d+D3tt9g+7pu6w4FvmZ7J9vP9LPNuwJ/TS62v2v7nH7WGdEnSS4RvXseWAtYA3hR0kjgk8BXe9pA0laSrpJ0e/n5Kkk7Af8O7N29dyLpQ8CBwBcknVd6Hj9pWP8tSUe20tgyieYxwD+X/bxT0hclfbqsv1bS6ZJ+VZ5F82ZJPyrPHTm5oZ7DyrNabpP0H+XxEhEtS3KJ6N35wJ7Az4AvAv8EnGP7z71s861SZkfgPOCbtm8DvgBc1L13Yvt7VNPG/EuZOmSV2b4f+C7Vs0R2atJDAnjO9t+VcpcCxwI7AEdK2ljSdsBBwNvLpJQvUPWsIlqWiSsjemH7CapndVCeKvkZ4P2S/hPYEDjN9m+7bfZW4P3l/blUPZaXk6757+4A5nQ9IkDSPKqJWN8BvAm4qZpCjbUYJhNwRn2SXCJa9wXgFKrzMDdT9WouBd69ku36OsfSMpYfVVizt8KSjgX+sSzu3UL9XXNcvdjwvmt5JNWU8TNsn9BSayOayLBYRAskjQO2sP1LYG2qL2LT/Iv/f6hmyIVqOOnXfdzdn4DxktaQtD7VhQA9sv3tMgS2U7nIYCnwyj7us9FVwP6SNgWQtJGkrfpRXwxDSS4RrTkF+Hx5fwFwJHA98LUmZT8OHCXpduBwquert8z2fKqZlW+nOmdzax/behnwD10n9Pu4LbbvovqsPy+fYRaweV/rieEtsyJHRETt0nOJiIjaJblERETtklwiIqJ2SS4REVG7JJeIiKhdkktERNQuySUiImr3/wEP0YLwiYTahQAAAABJRU5ErkJggg==%0A">
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'FTE'</span><span class="p">]</span><span class="o">.</span><span class="n">dropna</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{'whiskers': [&lt;matplotlib.lines.Line2D at 0x25258b00488&gt;,
  &lt;matplotlib.lines.Line2D at 0x25258b0fe08&gt;],
 'caps': [&lt;matplotlib.lines.Line2D at 0x25258b14b48&gt;,
  &lt;matplotlib.lines.Line2D at 0x25258b14cc8&gt;],
 'boxes': [&lt;matplotlib.lines.Line2D at 0x25258b0cc48&gt;],
 'medians': [&lt;matplotlib.lines.Line2D at 0x25258b17f48&gt;],
 'fliers': [&lt;matplotlib.lines.Line2D at 0x25258b1bb08&gt;],
 'means': []}</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Looking-at-the-datatypes">
<a class="anchor" href="#Looking-at-the-datatypes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Looking at the datatypes<a class="anchor-link" href="#Looking-at-the-datatypes"> </a>
</h2>
<ul>
<li>ML algorithms work on numbers, not strings<ul>
<li>Need a numeric representation of these strings</li>
</ul>
</li>
<li>Strings can be slow compared to numbers</li>
<li>In pandas, <code>category</code> dtype encodes categorical data numerically,<ul>
<li>Can speed up code</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Exploring-datatypes-in-pandas">
<a class="anchor" href="#Exploring-datatypes-in-pandas" aria-hidden="true"><span class="octicon octicon-link"></span></a>Exploring datatypes in pandas<a class="anchor-link" href="#Exploring-datatypes-in-pandas"> </a>
</h3>
<p>It's always good to know what datatypes you're working with, especially when the inefficient pandas type object may be involved. Towards that end, let's explore what we have.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>object     23
float64     2
dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Encode-the-labels-as-categorical-variables">
<a class="anchor" href="#Encode-the-labels-as-categorical-variables" aria-hidden="true"><span class="octicon octicon-link"></span></a>Encode the labels as categorical variables<a class="anchor-link" href="#Encode-the-labels-as-categorical-variables"> </a>
</h3>
<p>Remember, your ultimate goal is to predict the probability that a certain label is attached to a budget line item. You just saw that many columns in your data are the inefficient object type. Does this include the labels you're trying to predict? Let's find out!</p>
<p>There are 9 columns of labels in the dataset. Each of these columns is a category that has many possible values it can take.</p>
<p>You will notice that every label is encoded as an object datatype. Because category datatypes are much more efficient your task is to convert the labels to category types using the <code>.astype()</code> method.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">LABELS</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Function'</span><span class="p">,</span> <span class="s1">'Use'</span><span class="p">,</span> <span class="s1">'Sharing'</span><span class="p">,</span> <span class="s1">'Reporting'</span><span class="p">,</span> <span class="s1">'Student_Type'</span><span class="p">,</span> <span class="s1">'Position_Type'</span><span class="p">,</span>
          <span class="s1">'Object_Type'</span><span class="p">,</span> <span class="s1">'Pre_K'</span><span class="p">,</span> <span class="s1">'Operating_Status'</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">categorize_label</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'category'</span><span class="p">)</span>

<span class="c1"># Convert df[LABELS] to a category type</span>
<span class="n">df</span><span class="p">[</span><span class="n">LABELS</span><span class="p">]</span> <span class="o">=</span> <span class="n">categorize_label</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">LABELS</span><span class="p">])</span>

<span class="c1"># Print the converted dtypes</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">LABELS</span><span class="p">]</span><span class="o">.</span><span class="n">dtypes</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Function            category
Use                 category
Sharing             category
Reporting           category
Student_Type        category
Position_Type       category
Object_Type         category
Pre_K               category
Operating_Status    category
dtype: object
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Counting-unique-labels">
<a class="anchor" href="#Counting-unique-labels" aria-hidden="true"><span class="octicon octicon-link"></span></a>Counting unique labels<a class="anchor-link" href="#Counting-unique-labels"> </a>
</h3>
<p>As Peter mentioned in the video, there are over 100 unique labels. In this exercise, you will explore this fact by counting and plotting the number of unique values for each category of label.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">num_unique_labels</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">LABELS</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="o">.</span><span class="n">nunique</span><span class="p">)</span>

<span class="c1"># Plot number of unique values for each label</span>
<span class="n">num_unique_labels</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'bar'</span><span class="p">)</span>

<span class="c1"># Label the axes</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Labels'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Number of unique values'</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="How-do-we-measure-success?">
<a class="anchor" href="#How-do-we-measure-success?" aria-hidden="true"><span class="octicon octicon-link"></span></a>How do we measure success?<a class="anchor-link" href="#How-do-we-measure-success?"> </a>
</h2>
<ul>
<li>Accuracy can be misleading when classes are imbalanced<ul>
<li>Legitmate email: 99%, Spam: 1%</li>
<li>Model that never predicts spam will be 99% accurate!</li>
</ul>
</li>
<li>Metric used in this problem: log loss<ul>
<li>Loss function</li>
<li>Measure of error</li>
<li>Want to minimize the error (unlike accuracy)</li>
</ul>
</li>
<li>Log loss binary classification

$$ log loss = -\frac{1}{N} \sum^{N}_{i=1}(y_i \log(p_i)) + (1- y_i)\log(1-p_i)) $$
<ul>
<li>Actual value: $y: {1=\text{yes}, 0=\text{no}}$</li>
<li>Prediction (probability that the value is 1): $p$</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Computing-log-loss-with-NumPy">
<a class="anchor" href="#Computing-log-loss-with-NumPy" aria-hidden="true"><span class="octicon octicon-link"></span></a>Computing log loss with NumPy<a class="anchor-link" href="#Computing-log-loss-with-NumPy"> </a>
</h3>
<p>To see how the log loss metric handles the trade-off between accuracy and confidence, we will use some sample data generated with NumPy and compute the log loss using the provided function <code>compute_log_loss()</code>, which Peter showed you in the video.</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compute_log_loss</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">actual</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-14</span><span class="p">):</span>
    <span class="sd">"""Compute the logarithmic loss between predicted and</span>
<span class="sd">       actual when these are 1D arrays</span>

<span class="sd">       :param predicted: The predicted probabilties as floats between 0-1</span>
<span class="sd">       :param actual: The actual binary labels. Either 0 or 1</span>
<span class="sd">       :param eps (optional): log(0) is inf, so we need to offset our</span>
<span class="sd">                               predicted values slightly by eps from 0 or 1.</span>
<span class="sd">    """</span>
    <span class="n">predicted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">eps</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">actual</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">actual</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">predicted</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">loss</span>
</pre></div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">compute_log_loss</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">actual</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-14</span><span class="p">):</span>
    <span class="sd">"""Compute the logarithmic loss between predicted and</span>
<span class="sd">       actual when these are 1D arrays</span>

<span class="sd">       :param predicted: The predicted probabilties as floats between 0-1</span>
<span class="sd">       :param actual: The actual binary labels. Either 0 or 1</span>
<span class="sd">       :param eps (optional): log(0) is inf, so we need to offset our</span>
<span class="sd">                               predicted values slightly by eps from 0 or 1.</span>
<span class="sd">    """</span>
    <span class="n">predicted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">eps</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">actual</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">actual</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">predicted</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">loss</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">correct_confident</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">])</span>
<span class="n">correct_not_confident</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.65</span><span class="p">,</span> <span class="mf">0.65</span><span class="p">,</span> <span class="mf">0.65</span><span class="p">,</span> <span class="mf">0.65</span><span class="p">,</span> <span class="mf">0.65</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">])</span>
<span class="n">wrong_not_confident</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.65</span><span class="p">,</span> <span class="mf">0.65</span><span class="p">,</span> <span class="mf">0.65</span><span class="p">,</span> <span class="mf">0.65</span><span class="p">,</span> <span class="mf">0.65</span><span class="p">])</span>
<span class="n">wrong_confident</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">])</span>
<span class="n">actual_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">correct_confident_loss</span> <span class="o">=</span> <span class="n">compute_log_loss</span><span class="p">(</span><span class="n">correct_confident</span><span class="p">,</span> <span class="n">actual_labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Log loss, correct and confident: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">correct_confident_loss</span><span class="p">))</span> 

<span class="c1"># Compute log loss for 2nd case</span>
<span class="n">correct_not_confident_loss</span> <span class="o">=</span> <span class="n">compute_log_loss</span><span class="p">(</span><span class="n">correct_not_confident</span><span class="p">,</span> <span class="n">actual_labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Log loss, correct and not confident: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">correct_not_confident_loss</span><span class="p">))</span> 

<span class="c1"># Compute and print log loss for 3rd case</span>
<span class="n">wrong_not_confident_loss</span> <span class="o">=</span> <span class="n">compute_log_loss</span><span class="p">(</span><span class="n">wrong_not_confident</span><span class="p">,</span> <span class="n">actual_labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Log loss, wrong and not confident: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">wrong_not_confident_loss</span><span class="p">))</span> 

<span class="c1"># Compute and print log loss for 4th case</span>
<span class="n">wrong_confident_loss</span> <span class="o">=</span> <span class="n">compute_log_loss</span><span class="p">(</span><span class="n">wrong_confident</span><span class="p">,</span> <span class="n">actual_labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Log loss, wrong and confident: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">wrong_confident_loss</span><span class="p">))</span> 

<span class="c1"># Compute and print log loss for actual labels</span>
<span class="n">actual_labels_loss</span> <span class="o">=</span> <span class="n">compute_log_loss</span><span class="p">(</span><span class="n">actual_labels</span><span class="p">,</span> <span class="n">actual_labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Log loss, actual labels: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">actual_labels_loss</span><span class="p">))</span> 
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Log loss, correct and confident: 0.05129329438755058
Log loss, correct and not confident: 0.4307829160924542
Log loss, wrong and not confident: 1.049822124498678
Log loss, wrong and confident: 2.9957322735539904
Log loss, actual labels: 9.99200722162646e-15
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Time-to-build-model">
<a class="anchor" href="#Time-to-build-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Time to build model<a class="anchor-link" href="#Time-to-build-model"> </a>
</h2>
<ul>
<li>Always a good approach to start with a very simple model</li>
<li>Gives a sense of how challengeing the problem is</li>
<li>Many more things can go wrong in complex models</li>
<li>How much signal can we pull out using basic methods?</li>
<li>Train basic model on numeric data only<ul>
<li>Want to go from raw data to predictions quickly</li>
</ul>
</li>
<li>Multiclass logistic regression<ul>
<li>Train classifier on each label separately and use those to predict</li>
</ul>
</li>
<li>Format predictions and save to csv</li>
<li>Compute log loss score</li>
<li>Splitting the multi-class dataset<ul>
<li>Recall: Train-test split<ul>
<li>Will not work here</li>
<li>May end up with labels in test set that never appear in training set</li>
</ul>
</li>
<li>Solution: <code>StratifiedShyffleSplit</code><ul>
<li>Only works with a single target variable</li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Setting-up-a-train-test-split-in-scikit-learn">
<a class="anchor" href="#Setting-up-a-train-test-split-in-scikit-learn" aria-hidden="true"><span class="octicon octicon-link"></span></a>Setting up a train-test split in scikit-learn<a class="anchor-link" href="#Setting-up-a-train-test-split-in-scikit-learn"> </a>
</h3>
<p>Alright, you've been patient and awesome. It's finally time to start training models!</p>
<p>The first step is to split the data into a training set and a test set. Some labels don't occur very often, but we want to make sure that they appear in both the training and the test sets. We provide a function that will make sure at least <code>min_count</code> examples of each label appear in each split: <code>multilabel_train_test_split</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">warnings</span> <span class="kn">import</span> <span class="n">warn</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="k">def</span> <span class="nf">multilabel_sample</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">""" Takes a matrix of binary labels `y` and returns</span>
<span class="sd">        the indices for a sample of size `size` if</span>
<span class="sd">        `size` &gt; 1 or `size` * len(y) if size =&lt; 1.</span>
<span class="sd">        The sample is guaranteed to have &gt; `min_count` of</span>
<span class="sd">        each label.</span>
<span class="sd">    """</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">()</span>
    <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">'multilabel_sample only works with binary indicator matrices'</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">min_count</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">'Some classes do not have enough examples. Change min_count if necessary.'</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">size</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">size</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">min_count</span> <span class="o">&gt;</span> <span class="n">size</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">"Size less than number of columns * min_count, returning </span><span class="si">{}</span><span class="s2"> items instead of </span><span class="si">{}</span><span class="s2">."</span>
        <span class="n">warn</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">min_count</span><span class="p">,</span> <span class="n">size</span><span class="p">))</span>
        <span class="n">size</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">min_count</span>

    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="n">seed</span> <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
        <span class="n">choices</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">index</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">values</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">choices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="n">sample_idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">choices</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="c1"># first, guarantee &gt; min_count of each label</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">label_choices</span> <span class="o">=</span> <span class="n">choices</span><span class="p">[</span><span class="n">y</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">label_idxs_sampled</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">label_choices</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">min_count</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">sample_idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">label_idxs_sampled</span><span class="p">,</span> <span class="n">sample_idxs</span><span class="p">])</span>

    <span class="n">sample_idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">sample_idxs</span><span class="p">)</span>

    <span class="c1"># now that we have at least min_count of each, we can just random sample</span>
    <span class="n">sample_count</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">size</span> <span class="o">-</span> <span class="n">sample_idxs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="c1"># get sample_count indices from remaining choices</span>
    <span class="n">remaining_choices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">setdiff1d</span><span class="p">(</span><span class="n">choices</span><span class="p">,</span> <span class="n">sample_idxs</span><span class="p">)</span>
    <span class="n">remaining_sampled</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">remaining_choices</span><span class="p">,</span>
                                   <span class="n">size</span><span class="o">=</span><span class="n">sample_count</span><span class="p">,</span>
                                   <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">sample_idxs</span><span class="p">,</span> <span class="n">remaining_sampled</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">multilabel_sample_dataframe</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">""" Takes a dataframe `df` and returns a sample of size `size` where all</span>
<span class="sd">        classes in the binary matrix `labels` are represented at</span>
<span class="sd">        least `min_count` times.</span>
<span class="sd">    """</span>
    <span class="n">idxs</span> <span class="o">=</span> <span class="n">multilabel_sample</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="n">min_count</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idxs</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">multilabel_train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">""" Takes a features matrix `X` and a label matrix `Y` and</span>
<span class="sd">        returns (X_train, X_test, Y_train, Y_test) where all</span>
<span class="sd">        classes in Y are represented at least `min_count` times.</span>
<span class="sd">    """</span>
    <span class="n">index</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">index</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="n">test_set_idxs</span> <span class="o">=</span> <span class="n">multilabel_sample</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="n">min_count</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">train_set_idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">setdiff1d</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">test_set_idxs</span><span class="p">)</span>

    <span class="n">test_set_mask</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">test_set_idxs</span><span class="p">)</span>
    <span class="n">train_set_mask</span> <span class="o">=</span> <span class="o">~</span><span class="n">test_set_mask</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">train_set_mask</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_set_mask</span><span class="p">],</span> <span class="n">Y</span><span class="p">[</span><span class="n">train_set_mask</span><span class="p">],</span> <span class="n">Y</span><span class="p">[</span><span class="n">test_set_mask</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You'll start with a simple model that uses just the numeric columns of your DataFrame when calling <code>multilabel_train_test_split</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">NUMERIC_COLUMNS</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'FTE'</span><span class="p">,</span> <span class="s1">'Total'</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">numeric_data_only</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">NUMERIC_COLUMNS</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="o">-</span><span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># Get labels and convert to dummy variables: label_dummies</span>
<span class="n">label_dummies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">LABELS</span><span class="p">])</span>

<span class="c1"># Create training and test sets</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">multilabel_train_test_split</span><span class="p">(</span><span class="n">numeric_data_only</span><span class="p">,</span> <span class="n">label_dummies</span><span class="p">,</span>
                                                               <span class="n">size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>

<span class="c1"># Print the info</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"X_train info:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">info</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">X_test info:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">info</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">y_train info:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">info</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">y_test info:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">info</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>X_train info:
&lt;class 'pandas.core.frame.DataFrame'&gt;
Int64Index: 320222 entries, 134338 to 415831
Data columns (total 2 columns):
 #   Column  Non-Null Count   Dtype  
---  ------  --------------   -----  
 0   FTE     320222 non-null  float64
 1   Total   320222 non-null  float64
dtypes: float64(2)
memory usage: 7.3 MB
None

X_test info:
&lt;class 'pandas.core.frame.DataFrame'&gt;
Int64Index: 80055 entries, 206341 to 72072
Data columns (total 2 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   FTE     80055 non-null  float64
 1   Total   80055 non-null  float64
dtypes: float64(2)
memory usage: 1.8 MB
None

y_train info:
&lt;class 'pandas.core.frame.DataFrame'&gt;
Int64Index: 320222 entries, 134338 to 415831
Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12 Operating
dtypes: uint8(104)
memory usage: 34.2 MB
None

y_test info:
&lt;class 'pandas.core.frame.DataFrame'&gt;
Int64Index: 80055 entries, 206341 to 72072
Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12 Operating
dtypes: uint8(104)
memory usage: 8.6 MB
None
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Training-a-model">
<a class="anchor" href="#Training-a-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Training a model<a class="anchor-link" href="#Training-a-model"> </a>
</h3>
<p>With split data in hand, you're only a few lines away from training a model.</p>
<p>In this exercise, you will import the logistic regression and one versus rest classifiers in order to fit a multi-class logistic regression model to the <code>NUMERIC_COLUMNS</code> of your feature data.</p>
<p>Then you'll test and print the accuracy with the <code>.score()</code> method to see the results of training.</p>
<p><strong>Before you train!</strong> Remember, we're ultimately going to be using logloss to score our model, so don't worry too much about the accuracy here. Keep in mind that you're throwing away all of the text data in the dataset - that's by far most of the data! So don't get your hopes up for a killer performance just yet. We're just interested in getting things up and running at the moment.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.multiclass</span> <span class="kn">import</span> <span class="n">OneVsRestClassifier</span>

<span class="c1"># Instantiate the classifier: clf</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">OneVsRestClassifier</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">())</span>

<span class="c1"># Fit the classifier to the training data</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Print the accuracy</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Accuracy: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Accuracy: 0.0
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Ok! The good news is that your workflow didn't cause any errors. The bad news is that your model scored the lowest possible accuracy: 0.0! But hey, you just threw away ALL of the text data in the budget. Later, you won't. Before you add the text data, let's see how the model does when scored by log loss.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Making-predictions">
<a class="anchor" href="#Making-predictions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Making predictions<a class="anchor-link" href="#Making-predictions"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Use-your-model-to-predict-values-on-holdout-data">
<a class="anchor" href="#Use-your-model-to-predict-values-on-holdout-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Use your model to predict values on holdout data<a class="anchor-link" href="#Use-your-model-to-predict-values-on-holdout-data"> </a>
</h3>
<p>You're ready to make some predictions! Remember, the train-test-split you've carried out so far is for model development. The original competition provides an additional test set, for which you'll never actually see the correct labels. This is called the "holdout data."</p>
<p>The point of the holdout data is to provide a fair test for machine learning competitions. If the labels aren't known by anyone but DataCamp, DrivenData, or whoever is hosting the competition, you can be sure that no one submits a mere copy of labels to artificially pump up the performance on their model.</p>
<p>Remember that the original goal is to predict the probability of each label. In this exercise you'll do just that by using the .predict_proba() method on your trained model.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">holdout</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'./dataset/HoldoutData.csv'</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Generate predictions: predictions</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">holdout</span><span class="p">[</span><span class="n">NUMERIC_COLUMNS</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="o">-</span><span class="mi">1000</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Writing-out-your-results-to-a-csv-for-submission">
<a class="anchor" href="#Writing-out-your-results-to-a-csv-for-submission" aria-hidden="true"><span class="octicon octicon-link"></span></a>Writing out your results to a csv for submission<a class="anchor-link" href="#Writing-out-your-results-to-a-csv-for-submission"> </a>
</h3>
<p>At last, you're ready to submit some predictions for scoring. In this exercise, you'll write your predictions to a .csv using the <code>.to_csv()</code> method on a pandas DataFrame. Then you'll evaluate your performance according to the LogLoss metric discussed earlier!</p>
<p>You'll need to make sure your submission obeys the correct format.</p>
<p>To do this, you'll use your predictions values to create a new DataFrame, <code>prediction_df</code>.</p>
<p><strong>Interpreting LogLoss &amp; Beating the Benchmark</strong>:</p>
<p>When interpreting your log loss score, keep in mind that the score will change based on the number of samples tested. To get a sense of how this very basic model performs, compare your score to the DrivenData benchmark model performance: 2.0455, which merely submitted uniform probabilities for each class.</p>
<p>Remember, the lower the log loss the better. Is your model's log loss lower than 2.0455?</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">BOX_PLOTS_COLUMN_INDICES</span> <span class="o">=</span> <span class="p">[</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">37</span><span class="p">),</span>
 <span class="nb">range</span><span class="p">(</span><span class="mi">37</span><span class="p">,</span> <span class="mi">48</span><span class="p">),</span>
 <span class="nb">range</span><span class="p">(</span><span class="mi">48</span><span class="p">,</span> <span class="mi">51</span><span class="p">),</span>
 <span class="nb">range</span><span class="p">(</span><span class="mi">51</span><span class="p">,</span> <span class="mi">76</span><span class="p">),</span>
 <span class="nb">range</span><span class="p">(</span><span class="mi">76</span><span class="p">,</span> <span class="mi">79</span><span class="p">),</span>
 <span class="nb">range</span><span class="p">(</span><span class="mi">79</span><span class="p">,</span> <span class="mi">82</span><span class="p">),</span>
 <span class="nb">range</span><span class="p">(</span><span class="mi">82</span><span class="p">,</span> <span class="mi">87</span><span class="p">),</span>
 <span class="nb">range</span><span class="p">(</span><span class="mi">87</span><span class="p">,</span> <span class="mi">96</span><span class="p">),</span>
 <span class="nb">range</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="mi">104</span><span class="p">)]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">_multi_multi_log_loss</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span>
                          <span class="n">actual</span><span class="p">,</span>
                          <span class="n">class_column_indices</span><span class="o">=</span><span class="n">BOX_PLOTS_COLUMN_INDICES</span><span class="p">,</span>
                          <span class="n">eps</span><span class="o">=</span><span class="mf">1e-15</span><span class="p">):</span>
    <span class="sd">""" Multi class version of Logarithmic Loss metric as implemented on</span>
<span class="sd">    DrivenData.org</span>
<span class="sd">    """</span>
    <span class="n">class_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">class_column_indices</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    
    <span class="c1"># calculate log loss for each set of columns that belong to a class:</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">this_class_indices</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">class_column_indices</span><span class="p">):</span>
        <span class="c1"># get just the columns for this class</span>
        <span class="n">preds_k</span> <span class="o">=</span> <span class="n">predicted</span><span class="p">[:,</span> <span class="n">this_class_indices</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        
        <span class="c1"># normalize so probabilities sum to one (unless sum is zero, then we clip)</span>
        <span class="n">preds_k</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">preds_k</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">eps</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>

        <span class="n">actual_k</span> <span class="o">=</span> <span class="n">actual</span><span class="p">[:,</span> <span class="n">this_class_indices</span><span class="p">]</span>

        <span class="c1"># shrink predictions so</span>
        <span class="n">y_hats</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">preds_k</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">eps</span><span class="p">)</span>
        <span class="n">sum_logs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">actual_k</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_hats</span><span class="p">))</span>
        <span class="n">class_scores</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">actual</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">sum_logs</span>
        
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">class_scores</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">score_submission</span><span class="p">(</span><span class="n">pred_path</span><span class="o">=</span><span class="s1">'./'</span><span class="p">,</span> <span class="n">holdout_path</span><span class="o">=</span><span class="s1">'https://s3.amazonaws.com/assets.datacamp.com/production/course_2826/datasets/TestSetLabelsSample.csv'</span><span class="p">):</span>
    <span class="c1"># this happens on the backend to get the score</span>
    <span class="n">holdout_labels</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span>
        <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">holdout_path</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'category'</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="p">)</span>
    
    <span class="n">preds</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">pred_path</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="c1"># make sure that format is correct</span>
    <span class="k">assert</span> <span class="p">(</span><span class="n">preds</span><span class="o">.</span><span class="n">columns</span> <span class="o">==</span> <span class="n">holdout_labels</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
    <span class="k">assert</span> <span class="p">(</span><span class="n">preds</span><span class="o">.</span><span class="n">index</span> <span class="o">==</span> <span class="n">holdout_labels</span><span class="o">.</span><span class="n">index</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">_multi_multi_log_loss</span><span class="p">(</span><span class="n">preds</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">holdout_labels</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">prediction_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">LABELS</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
                             <span class="n">index</span><span class="o">=</span><span class="n">holdout</span><span class="o">.</span><span class="n">index</span><span class="p">,</span>
                             <span class="n">data</span><span class="o">=</span><span class="n">predictions</span><span class="p">)</span>

<span class="c1"># Save prediction_df to csv</span>
<span class="n">prediction_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">'./dataset/predictions.csv'</span><span class="p">)</span>

<span class="c1"># Submit the predictions for scoring: score</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">score_submission</span><span class="p">(</span><span class="n">pred_path</span><span class="o">=</span><span class="s1">'./dataset/predictions.csv'</span><span class="p">)</span>

<span class="c1"># Print score</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Your model, trained with numeric data only, yields logloss score: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">score</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Your model, trained with numeric data only, yields logloss score: 1.9587992012561084
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="A-very-brief-introduction-to-NLP">
<a class="anchor" href="#A-very-brief-introduction-to-NLP" aria-hidden="true"><span class="octicon octicon-link"></span></a>A very brief introduction to NLP<a class="anchor-link" href="#A-very-brief-introduction-to-NLP"> </a>
</h2>
<ul>
<li>A very brief introduction to NLP<ul>
<li>Data fpr NLP:<ul>
<li>Text, documents, speech,...</li>
</ul>
</li>
<li>Tokenization<ul>
<li>Spliting a string into segments</li>
<li>Store segments as list</li>
</ul>
</li>
<li>Example: "Natural Langauge Processing" -&gt; ["Natural", "Language", "Processing"]</li>
</ul>
</li>
<li>Bag of words representation<ul>
<li>Count the number of times a particular token appears</li>
<li>"Bag of words"<ul>
<li>Count the number of times a word was pulled out of the bag</li>
</ul>
</li>
<li>This approach discards information about word order<ul>
<li>"Red, not blue" is the same as "blue, not red"</li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Representing-text-numerically">
<a class="anchor" href="#Representing-text-numerically" aria-hidden="true"><span class="octicon octicon-link"></span></a>Representing text numerically<a class="anchor-link" href="#Representing-text-numerically"> </a>
</h2>
<ul>
<li>Representing text numerically<ul>
<li>Bag-of-words<ul>
<li>Simple way to represent text in machine learning</li>
<li>Discards information about grammar and word order</li>
<li>Computes frequency of occurance</li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Creating-a-bag-of-words-in-scikit-learn">
<a class="anchor" href="#Creating-a-bag-of-words-in-scikit-learn" aria-hidden="true"><span class="octicon octicon-link"></span></a>Creating a bag-of-words in scikit-learn<a class="anchor-link" href="#Creating-a-bag-of-words-in-scikit-learn"> </a>
</h3>
<p>In this exercise, you'll study the effects of tokenizing in different ways by comparing the bag-of-words representations resulting from different token patterns.</p>
<p>You will focus on one feature only, the <code>Position_Extra</code> column, which describes any additional information not captured by the <code>Position_Type</code> label.</p>
<p>For example, in the Shell you can check out the budget item in row 8960 of the data using <code>df.loc[8960]</code>. Looking at the output reveals that this <code>Object_Description</code> is overtime pay. For who? The Position Type is merely "other", but the Position Extra elaborates: "BUS DRIVER". Explore the column further to see more instances. It has a lot of NaN values.</p>
<p>Your task is to turn the raw text in this column into a bag-of-words representation by creating tokens that contain only alphanumeric characters.</p>
<p>For comparison purposes, the first 15 tokens of <code>vec_basic</code>, which splits <code>df.Position_Extra</code> into tokens when it encounters only whitespace characters, have been printed along with the length of the representation.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="c1"># Create the token pattern: TOKENS_ALPHANUMERIC</span>
<span class="n">TOKENS_ALPHANUMERIC</span> <span class="o">=</span> <span class="s1">'[A-Za-z0-9]+(?=</span><span class="se">\\</span><span class="s1">s+)'</span>

<span class="c1"># Fill missing values in df.Position_Extra</span>
<span class="n">df</span><span class="o">.</span><span class="n">Position_Extra</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">''</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Instantiate the CountVectorizer:vec_alphanumeric</span>
<span class="n">vec_alphanumeric</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">token_pattern</span><span class="o">=</span><span class="n">TOKENS_ALPHANUMERIC</span><span class="p">)</span>

<span class="c1"># Fit to the data</span>
<span class="n">vec_alphanumeric</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Position_Extra</span><span class="p">)</span>

<span class="c1"># Print the number of tokens and first 15 tokens</span>
<span class="n">msg</span> <span class="o">=</span> <span class="s2">"There are </span><span class="si">{}</span><span class="s2"> tokens in Position_Extra if we split on non-alpha numeric"</span>
<span class="nb">print</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vec_alphanumeric</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vec_alphanumeric</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()[:</span><span class="mi">15</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>There are 385 tokens in Position_Extra if we split on non-alpha numeric
['1st', '2nd', '3rd', '4th', '56', '5th', '9th', 'a', 'ab', 'accountability', 'adaptive', 'addit', 'additional', 'adm', 'admin']
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Combining-text-columns-for-tokenization">
<a class="anchor" href="#Combining-text-columns-for-tokenization" aria-hidden="true"><span class="octicon octicon-link"></span></a>Combining text columns for tokenization<a class="anchor-link" href="#Combining-text-columns-for-tokenization"> </a>
</h3>
<p>In order to get a bag-of-words representation for all of the text data in our DataFrame, you must first convert the text data in each row of the DataFrame into a single string.</p>
<p>In the previous exercise, this wasn't necessary because you only looked at one column of data, so each row was already just a single string. <code>CountVectorizer</code> expects each row to just be a single string, so in order to use all of the text columns, you'll need a method to turn a list of strings into a single string.</p>
<p>In this exercise, you'll complete the function definition <code>combine_text_columns()</code>. When completed, this function will convert all training text data in your DataFrame to a single string per row that can be passed to the vectorizer object and made into a bag-of-words using the <code>.fit_transform()</code> method.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">combine_text_columns</span><span class="p">(</span><span class="n">data_frame</span><span class="p">,</span> <span class="n">to_drop</span><span class="o">=</span><span class="n">NUMERIC_COLUMNS</span> <span class="o">+</span> <span class="n">LABELS</span><span class="p">):</span>
    <span class="sd">""" converts all text in each row of data_frame to single vector """</span>
    
    <span class="c1"># Drop non-text columns that are in the df</span>
    <span class="n">to_drop</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">to_drop</span><span class="p">)</span> <span class="o">&amp;</span> <span class="nb">set</span><span class="p">(</span><span class="n">data_frame</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
    <span class="n">text_data</span> <span class="o">=</span> <span class="n">data_frame</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">to_drop</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">'columns'</span><span class="p">)</span>
    
    <span class="c1"># Replace nans with blanks</span>
    <span class="n">text_data</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s2">""</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="c1"># Join all text items in a row that have a space in between</span>
    <span class="k">return</span> <span class="n">text_data</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s2">" "</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="What's-in-a-token?">
<a class="anchor" href="#What's-in-a-token?" aria-hidden="true"><span class="octicon octicon-link"></span></a>What's in a token?<a class="anchor-link" href="#What's-in-a-token?"> </a>
</h3>
<p>Now you will use <code>combine_text_columns</code> to convert all training text data in your DataFrame to a single vector that can be passed to the vectorizer object and made into a bag-of-words using the <code>.fit_transform()</code> method.</p>
<p>You'll compare the effect of tokenizing using any non-whitespace characters as a token and using only alphanumeric characters as a token.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">TOKENS_BASIC</span> <span class="o">=</span> <span class="s1">'</span><span class="se">\\</span><span class="s1">S+(?=</span><span class="se">\\</span><span class="s1">s+)'</span>

<span class="c1"># Create the alphanumeric token pattern</span>
<span class="n">TOKENS_ALPHANUMERIC</span> <span class="o">=</span> <span class="s1">'[A-Za-z0-9]+(?=</span><span class="se">\\</span><span class="s1">s+)'</span>

<span class="c1"># Instantiate basic CountVectorizer: vec_basic</span>
<span class="n">vec_basic</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">token_pattern</span><span class="o">=</span><span class="n">TOKENS_BASIC</span><span class="p">)</span>

<span class="c1"># Instantiate alphanumeric CountVecotrizer: vec_alphanumeric</span>
<span class="n">vec_alphanumeric</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">token_pattern</span><span class="o">=</span><span class="n">TOKENS_ALPHANUMERIC</span><span class="p">)</span>

<span class="c1"># Create the text vector</span>
<span class="n">text_vector</span> <span class="o">=</span> <span class="n">combine_text_columns</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1"># Fit and transform vec_basic</span>
<span class="n">vec_basic</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">text_vector</span><span class="p">)</span>

<span class="c1"># Print number of tokens of vec_basic</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"There are </span><span class="si">{}</span><span class="s2"> tokens in the dataset"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vec_basic</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())))</span>

<span class="c1"># Fit and transform vec_alphanumeric</span>
<span class="n">vec_alphanumeric</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">text_vector</span><span class="p">)</span>

<span class="c1"># Print number of tokens of vec_alphanumeric</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"There are </span><span class="si">{}</span><span class="s2"> alpha-numeric tokens in the dataset"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vec_alphanumeric</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>There are 4757 tokens in the dataset
There are 3284 alpha-numeric tokens in the dataset
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Pipelines,-feature-&amp;-text-preprocessing">
<a class="anchor" href="#Pipelines,-feature-&amp;-text-preprocessing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pipelines, feature &amp; text preprocessing<a class="anchor-link" href="#Pipelines,-feature-&amp;-text-preprocessing"> </a>
</h2>
<ul>
<li>The pipeline workflow<ul>
<li>Repeatable way to go from raw data to trained model</li>
<li>Pipeline object takes sequential list of steps<ul>
<li>Output of one step is input to next step</li>
</ul>
</li>
<li>Each step is a tuple with two elements<ul>
<li>Name: String</li>
<li>Transform: obj implementing <code>.fit()</code> and <code>.transform()</code>
</li>
</ul>
</li>
<li>Flexible: a step can itself be another pipeline!</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Instantiate-pipeline">
<a class="anchor" href="#Instantiate-pipeline" aria-hidden="true"><span class="octicon octicon-link"></span></a>Instantiate pipeline<a class="anchor-link" href="#Instantiate-pipeline"> </a>
</h3>
<p>In order to make your life easier as you start to work with all of the data in your original DataFrame, df, it's time to turn to one of scikit-learn's most useful objects: the Pipeline.</p>
<p>For the next few exercises, you'll reacquaint yourself with pipelines and train a classifier on some synthetic (sample) data of multiple datatypes before using the same techniques on the main dataset.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Preprocess</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sample_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'./dataset/sample_data.csv'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.multiclass</span> <span class="kn">import</span> <span class="n">OneVsRestClassifier</span>

<span class="c1"># Split and select numeric data only, no nans</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">sample_df</span><span class="p">[[</span><span class="s1">'numeric'</span><span class="p">]],</span> 
                                                    <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">sample_df</span><span class="p">[</span><span class="s1">'label'</span><span class="p">]),</span>
                                                   <span class="n">random_state</span><span class="o">=</span><span class="mi">22</span><span class="p">)</span>

<span class="c1"># Instantiate Pipeline object: pl</span>
<span class="n">pl</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">'clf'</span><span class="p">,</span> <span class="n">OneVsRestClassifier</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">()))</span>
<span class="p">])</span>

<span class="c1"># Fit the pipeline to the training data</span>
<span class="n">pl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Compute and print accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Accuracy on sample data - numeric, no nans: "</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Accuracy on sample data - numeric, no nans:  0.62
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Preprocessing-numeric-features">
<a class="anchor" href="#Preprocessing-numeric-features" aria-hidden="true"><span class="octicon octicon-link"></span></a>Preprocessing numeric features<a class="anchor-link" href="#Preprocessing-numeric-features"> </a>
</h3>
<p>What would have happened if you had included the with <code>'with_missing'</code> column in the last exercise? Without imputing missing values, the pipeline would not be happy (try it and see). So, in this exercise you'll improve your pipeline a bit by using the Imputer() imputation transformer from scikit-learn to fill in missing values in your sample data.</p>
<p>By default, the <a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Imputer.html">imputer transformer</a> replaces NaNs with the mean value of the column. That's a good enough imputation strategy for the sample data, so you won't need to pass anything extra to the imputer.</p>
<p>After importing the transformer, you will edit the steps list used in the previous exercise by inserting a <code>(name, transform)</code> tuple. Recall that steps are processed sequentially, so make sure the new tuple encoding your preprocessing step is put in the right place.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>

<span class="c1"># Create training and test sets using only numeric data</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">sample_df</span><span class="p">[[</span><span class="s1">'numeric'</span><span class="p">,</span> <span class="s1">'with_missing'</span><span class="p">]],</span>
                                                   <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">sample_df</span><span class="p">[</span><span class="s1">'label'</span><span class="p">]),</span>
                                                   <span class="n">random_state</span><span class="o">=</span><span class="mi">456</span><span class="p">)</span>

<span class="c1"># Instantiate Pipeline object: pl</span>
<span class="n">pl</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">'imp'</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">'clf'</span><span class="p">,</span> <span class="n">OneVsRestClassifier</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">()))</span>
<span class="p">])</span>

<span class="c1"># fit the pipeline to the training data</span>
<span class="n">pl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Compute and print accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Accuracy on sample data - all numeric, incl nans: "</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Accuracy on sample data - all numeric, incl nans:  0.636
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Text-features-and-feature-unions">
<a class="anchor" href="#Text-features-and-feature-unions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Text features and feature unions<a class="anchor-link" href="#Text-features-and-feature-unions"> </a>
</h2>
<ul>
<li>Preprocessing multiple dtypes<ul>
<li>Want to use all available features in one pipeline</li>
<li>Problem<ul>
<li>Pipeline steps for numeric and text processing can't follow each other</li>
<li>E.g., output of <code>CountVectorizer</code> can`t be input to <code>Imputer</code>
</li>
</ul>
</li>
<li>Solution<ul>
<li>
<code>FunctionTransformer()</code> &amp; <code>FeatureUnion()</code>
</li>
</ul>
</li>
</ul>
</li>
<li>FunctionTransformer<ul>
<li>Turns a Python function into an object that a scikit-learn pipeline can understand</li>
<li>Need to write two functions for pipeline preprocessing<ul>
<li>Take entire DataFrame, return numeric columns</li>
<li>Take entire DataFrame, return text columns</li>
</ul>
</li>
<li>Can then preprocess numeric and text data in separate pipelines</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Preprocessing-text-features">
<a class="anchor" href="#Preprocessing-text-features" aria-hidden="true"><span class="octicon octicon-link"></span></a>Preprocessing text features<a class="anchor-link" href="#Preprocessing-text-features"> </a>
</h3>
<p>Here, you'll perform a similar preprocessing pipeline step, only this time you'll use the <code>text</code> column from the sample data.</p>
<p>To preprocess the text, you'll turn to <code>CountVectorizer()</code> to generate a bag-of-words representation of the data. Using the <a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html">default</a> arguments, add a <code>(step, transform)</code> tuple to the steps list in your pipeline.</p>
<p>Make sure you select only the text column for splitting your training and test sets.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sample_df</span><span class="p">[</span><span class="s1">'text'</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample_df</span><span class="p">[</span><span class="s1">'text'</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s2">""</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">sample_df</span><span class="p">[</span><span class="s1">'text'</span><span class="p">],</span>
                                                    <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">sample_df</span><span class="p">[</span><span class="s1">'label'</span><span class="p">]),</span> 
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">456</span><span class="p">)</span>

<span class="c1"># Instantiate Pipeline object: pl</span>
<span class="n">pl</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s1">'vec'</span><span class="p">,</span> <span class="n">CountVectorizer</span><span class="p">()),</span>
        <span class="p">(</span><span class="s1">'clf'</span><span class="p">,</span> <span class="n">OneVsRestClassifier</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">()))</span>
    <span class="p">])</span>

<span class="c1"># Fit to the training data</span>
<span class="n">pl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Compute and print accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Accuracy on sample data - just text data: "</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Accuracy on sample data - just text data:  0.808
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Multiple-types-of-processing:-FunctionTransformer">
<a class="anchor" href="#Multiple-types-of-processing:-FunctionTransformer" aria-hidden="true"><span class="octicon octicon-link"></span></a>Multiple types of processing: FunctionTransformer<a class="anchor-link" href="#Multiple-types-of-processing:-FunctionTransformer"> </a>
</h3>
<p>The next two exercises will introduce new topics you'll need to make your pipeline truly excel.</p>
<p>Any step in the pipeline must be an object that implements the <code>fit</code> and <code>transform</code> methods. The <a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html">FunctionTransformer</a> creates an object with these methods out of any Python function that you pass to it. We'll use it to help select subsets of data in a way that plays nicely with pipelines.</p>
<p>You are working with numeric data that needs imputation, and text data that needs to be converted into a bag-of-words. You'll create functions that separate the text from the numeric variables and see how the <code>.fit()</code> and <code>.transform()</code> methods work.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">FunctionTransformer</span>

<span class="c1"># Obtain the text data: get_text_data</span>
<span class="n">get_text_data</span> <span class="o">=</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">'text'</span><span class="p">],</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Obtain the numberic data: get_numeric_data</span>
<span class="n">get_numeric_data</span> <span class="o">=</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[[</span><span class="s1">'numeric'</span><span class="p">,</span> <span class="s1">'with_missing'</span><span class="p">]],</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Fit and transform the text data: just_text_data</span>
<span class="n">just_text_data</span> <span class="o">=</span> <span class="n">get_text_data</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">sample_df</span><span class="p">)</span>

<span class="c1"># Fit and transform the numeric data: just_numeric_data</span>
<span class="n">just_numeric_data</span> <span class="o">=</span> <span class="n">get_numeric_data</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">sample_df</span><span class="p">)</span>

<span class="c1"># Print head to check results</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Text Data'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">just_text_data</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Numeric Data'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">just_numeric_data</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Text Data
0           
1        foo
2    foo bar
3           
4    foo bar
Name: text, dtype: object

Numeric Data
     numeric  with_missing
0 -10.856306      4.433240
1   9.973454      4.310229
2   2.829785      2.469828
3 -15.062947      2.852981
4  -5.786003      1.826475
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Multiple-types-of-processing:-FeatureUnion">
<a class="anchor" href="#Multiple-types-of-processing:-FeatureUnion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Multiple types of processing: FeatureUnion<a class="anchor-link" href="#Multiple-types-of-processing:-FeatureUnion"> </a>
</h3>
<p>Now that you can separate text and numeric data in your pipeline, you're ready to perform separate steps on each by nesting pipelines and using <code>FeatureUnion()</code>.</p>
<p>These tools will allow you to streamline all preprocessing steps for your model, even when multiple datatypes are involved. Here, for example, you don't want to impute our text data, and you don't want to create a bag-of-words with our numeric data. Instead, you want to deal with these separately and then join the results together using <code>FeatureUnion()</code>.</p>
<p>In the end, you'll still have only two high-level steps in your pipeline: preprocessing and model instantiation. The difference is that the first preprocessing step actually consists of a pipeline for numeric data and a pipeline for text data. The results of those pipelines are joined using <code>FeatureUnion()</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">FeatureUnion</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">sample_df</span><span class="p">[[</span><span class="s1">'numeric'</span><span class="p">,</span> <span class="s1">'with_missing'</span><span class="p">,</span> <span class="s1">'text'</span><span class="p">]],</span>
                                                   <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">sample_df</span><span class="p">[</span><span class="s1">'label'</span><span class="p">]),</span>
                                                   <span class="n">random_state</span><span class="o">=</span><span class="mi">22</span><span class="p">)</span>

<span class="c1"># Create a FeatureUnion with nested pipeline: process_and_join_features</span>
<span class="n">process_and_join_features</span> <span class="o">=</span> <span class="n">FeatureUnion</span><span class="p">(</span>
    <span class="n">transformer_list</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s1">'numeric_features'</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">([</span>
            <span class="p">(</span><span class="s1">'selector'</span><span class="p">,</span> <span class="n">get_numeric_data</span><span class="p">),</span>
            <span class="p">(</span><span class="s1">'imputer'</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">())</span>
        <span class="p">])),</span>
        <span class="p">(</span><span class="s1">'text_features'</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">([</span>
            <span class="p">(</span><span class="s1">'selector'</span><span class="p">,</span> <span class="n">get_text_data</span><span class="p">),</span>
            <span class="p">(</span><span class="s1">'vectorizer'</span><span class="p">,</span> <span class="n">CountVectorizer</span><span class="p">())</span>
        <span class="p">]))</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Instantiate nested pipeline: pl</span>
<span class="n">pl</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">'union'</span><span class="p">,</span> <span class="n">process_and_join_features</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">'clf'</span><span class="p">,</span> <span class="n">OneVsRestClassifier</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">()))</span>
<span class="p">])</span>

<span class="c1"># Fit pl to the training data</span>
<span class="n">pl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Compute and print accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Accuracy on sample data - all data: "</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Accuracy on sample data - all data:  0.928
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Choosing-a-classification-model">
<a class="anchor" href="#Choosing-a-classification-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Choosing a classification model<a class="anchor-link" href="#Choosing-a-classification-model"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Using-FunctionTransformer-on-the-main-dataset">
<a class="anchor" href="#Using-FunctionTransformer-on-the-main-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Using FunctionTransformer on the main dataset<a class="anchor-link" href="#Using-FunctionTransformer-on-the-main-dataset"> </a>
</h3>
<p>In this exercise you're going to use <code>FunctionTransformer</code> on the primary budget data, before instantiating a multiple-datatype pipeline in the next exercise.</p>
<p>Recall from Chapter 2 that you used a custom function <code>combine_text_columns</code> to select and properly format text data for tokenization; it is loaded into the workspace and ready to be put to work in a function transformer!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dummy_labels</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">LABELS</span><span class="p">])</span>

<span class="c1"># Get the columns that are features in the original df</span>
<span class="n">NON_LABELS</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">c</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">LABELS</span><span class="p">]</span>

<span class="c1"># Split into training and test sets</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">multilabel_train_test_split</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">NON_LABELS</span><span class="p">],</span>
                                                               <span class="n">dummy_labels</span><span class="p">,</span>
                                                              <span class="n">size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                                                              <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>

<span class="c1"># Preprocess the text data: get_text_data</span>
<span class="n">get_text_data</span> <span class="o">=</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">combine_text_columns</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Preprocess the numeric data: get_numeric_data</span>
<span class="n">get_numeric_data</span> <span class="o">=</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="n">NUMERIC_COLUMNS</span><span class="p">],</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Add-a-model-to-the-pipeline">
<a class="anchor" href="#Add-a-model-to-the-pipeline" aria-hidden="true"><span class="octicon octicon-link"></span></a>Add a model to the pipeline<a class="anchor-link" href="#Add-a-model-to-the-pipeline"> </a>
</h3>
<p>You're about to take everything you've learned so far and implement it in a Pipeline that works with the real, <a href="https://www.drivendata.org/">DrivenData</a> budget line item data you've been exploring.</p>
<p>Surprise! The structure of the pipeline is exactly the same as earlier in this chapter:</p>
<ul>
<li>the preprocessing step uses FeatureUnion to join the results of nested pipelines that each rely on FunctionTransformer to select multiple datatypes</li>
<li>the model step stores the model object</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pl</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">'union'</span><span class="p">,</span> <span class="n">FeatureUnion</span><span class="p">(</span>
        <span class="n">transformer_list</span><span class="o">=</span><span class="p">[</span>
            <span class="p">(</span><span class="s1">'numeric_features'</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">([</span>
                <span class="p">(</span><span class="s1">'selector'</span><span class="p">,</span> <span class="n">get_numeric_data</span><span class="p">),</span>
                <span class="p">(</span><span class="s1">'imputer'</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">())</span>
            <span class="p">])),</span>
            <span class="p">(</span><span class="s1">'text_features'</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">([</span>
                <span class="p">(</span><span class="s1">'selector'</span><span class="p">,</span> <span class="n">get_text_data</span><span class="p">),</span>
                <span class="p">(</span><span class="s1">'vectorizer'</span><span class="p">,</span> <span class="n">CountVectorizer</span><span class="p">())</span>
            <span class="p">]))</span>
        <span class="p">]</span>
    <span class="p">)),</span>
    <span class="p">(</span><span class="s1">'clf'</span><span class="p">,</span> <span class="n">OneVsRestClassifier</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">),</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
<span class="p">])</span>

<span class="c1"># Fit to the training data</span>
<span class="n">pl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Compute and print accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Accuracy on budget dataset: "</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Accuracy on budget dataset:  0.0
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Try-a-different-class-of-model">
<a class="anchor" href="#Try-a-different-class-of-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Try a different class of model<a class="anchor-link" href="#Try-a-different-class-of-model"> </a>
</h3>
<p>Now you're cruising. One of the great strengths of pipelines is how easy they make the process of testing different models.</p>
<p>Until now, you've been using the model step <code>('clf', OneVsRestClassifier(LogisticRegression()))</code> in your pipeline.</p>
<p>But what if you want to try a different model? Do you need to build an entirely new pipeline? New nests? New FeatureUnions? Nope! You just have a simple one-line change, as you'll see in this exercise.</p>
<p>In particular, you'll swap out the logistic-regression model and replace it with a <a href="https://en.wikipedia.org/wiki/Random_forest">random forest</a> classifier, which uses the statistics of an ensemble of decision trees to generate predictions.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="c1"># Edit model step in pipeline</span>
<span class="n">pl</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">'union'</span><span class="p">,</span> <span class="n">FeatureUnion</span><span class="p">(</span>
        <span class="n">transformer_list</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="s1">'numeric_features'</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">([</span>
                <span class="p">(</span><span class="s1">'selector'</span><span class="p">,</span> <span class="n">get_numeric_data</span><span class="p">),</span>
                <span class="p">(</span><span class="s1">'imputer'</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">())</span>
            <span class="p">])),</span>
            <span class="p">(</span><span class="s1">'text_features'</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">([</span>
                <span class="p">(</span><span class="s1">'selector'</span><span class="p">,</span> <span class="n">get_text_data</span><span class="p">),</span>
                <span class="p">(</span><span class="s1">'vectorizer'</span><span class="p">,</span> <span class="n">CountVectorizer</span><span class="p">())</span>
            <span class="p">]))</span>
        <span class="p">]</span>
    <span class="p">)),</span>
    <span class="p">(</span><span class="s1">'clf'</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
<span class="p">])</span>

<span class="c1"># Fit to the training data</span>
<span class="n">pl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Compute and print accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Accuracy on budget dataset: "</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Accuracy on budget dataset:  0.9132096683530073
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Can-you-adjust-the-model-or-parameters-to-improve-accuracy?">
<a class="anchor" href="#Can-you-adjust-the-model-or-parameters-to-improve-accuracy?" aria-hidden="true"><span class="octicon octicon-link"></span></a>Can you adjust the model or parameters to improve accuracy?<a class="anchor-link" href="#Can-you-adjust-the-model-or-parameters-to-improve-accuracy?"> </a>
</h3>
<p>You just saw a substantial improvement in accuracy by swapping out the model. Pipelines are amazing!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="c1"># Edit model step in pipeline</span>
<span class="n">pl</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">'union'</span><span class="p">,</span> <span class="n">FeatureUnion</span><span class="p">(</span>
        <span class="n">transformer_list</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="s1">'numeric_features'</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">([</span>
                <span class="p">(</span><span class="s1">'selector'</span><span class="p">,</span> <span class="n">get_numeric_data</span><span class="p">),</span>
                <span class="p">(</span><span class="s1">'imputer'</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">())</span>
            <span class="p">])),</span>
            <span class="p">(</span><span class="s1">'text_features'</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">([</span>
                <span class="p">(</span><span class="s1">'selector'</span><span class="p">,</span> <span class="n">get_text_data</span><span class="p">),</span>
                <span class="p">(</span><span class="s1">'vectorizer'</span><span class="p">,</span> <span class="n">CountVectorizer</span><span class="p">())</span>
            <span class="p">]))</span>
        <span class="p">]</span>
    <span class="p">)),</span>
    <span class="p">(</span><span class="s1">'clf'</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
<span class="p">])</span>

<span class="c1"># Fit to the training data</span>
<span class="n">pl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Compute and print accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Accuracy on budget dataset: "</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Accuracy on budget dataset:  0.9125601149209919
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Learning-from-the-expert:-processing">
<a class="anchor" href="#Learning-from-the-expert:-processing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Learning from the expert: processing<a class="anchor-link" href="#Learning-from-the-expert:-processing"> </a>
</h2>
<ul>
<li>Text preprocessing<ul>
<li>NLP tricks for text data<ul>
<li>Tokenize on punctuation to avoid hyphens, underscores, etc.</li>
<li>Includes unigrams and bi-grams in the model to capture important information involving multiple tokens - e.g. "middle school"</li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Deciding-what's-a-word">
<a class="anchor" href="#Deciding-what's-a-word" aria-hidden="true"><span class="octicon octicon-link"></span></a>Deciding what's a word<a class="anchor-link" href="#Deciding-what's-a-word"> </a>
</h3>
<p>Before you build up to the winning pipeline, it will be useful to look a little deeper into how the text features will be processed.</p>
<p>In this exercise, you will use <code>CountVectorizer</code> on the training data <code>X_train</code> to see the effect of tokenization on punctuation.</p>
<p>Remember, since CountVectorizer expects a vector, you'll need to use the preloaded function, combine_text_columns before fitting to the training data.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">text_vector</span> <span class="o">=</span> <span class="n">combine_text_columns</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># Create the token pattern: TOKENS_ALPHANUMERIC</span>
<span class="n">TOKENS_ALPHANUMERIC</span> <span class="o">=</span> <span class="s1">'[A-Za-z0-9]+(?=</span><span class="se">\\</span><span class="s1">s+)'</span>

<span class="c1"># Instantiate the CountVectorizer: text_features</span>
<span class="n">text_features</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">token_pattern</span><span class="o">=</span><span class="n">TOKENS_ALPHANUMERIC</span><span class="p">)</span>

<span class="c1"># Fit text_features to the text vector</span>
<span class="n">text_features</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">text_vector</span><span class="p">)</span>

<span class="c1"># Print the first 10 tokens</span>
<span class="nb">print</span><span class="p">(</span><span class="n">text_features</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()[:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>['00a', '12', '1st', '2nd', '3rd', '4th', '5', '56', '5th', '6']
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="N-gram-range-in-scikit-learn">
<a class="anchor" href="#N-gram-range-in-scikit-learn" aria-hidden="true"><span class="octicon octicon-link"></span></a>N-gram range in scikit-learn<a class="anchor-link" href="#N-gram-range-in-scikit-learn"> </a>
</h3>
<p>In this exercise you'll insert a <code>CountVectorizer</code> instance into your pipeline for the main dataset, and compute multiple n-gram features to be used in the model.</p>
<p>In order to look for ngram relationships at multiple scales, you will use the <code>ngram_range</code> parameter as Peter discussed in the video.</p>
<p><strong>Special functions</strong>: You'll notice a couple of new steps provided in the pipeline in this and many of the remaining exercises. Specifically, the <code>dim_red</code> step following the <code>vectorizer</code> step , and the <code>scale</code> step preceeding the <code>clf</code> (classification) step.</p>
<p>These have been added in order to account for the fact that you're using a reduced-size sample of the full dataset in this course. To make sure the models perform as the expert competition winner intended, we have to apply a <a href="https://en.wikipedia.org/wiki/Dimensionality_reduction">dimensionality reduction</a> technique, which is what the <code>dim_red</code> step does, and we have to <a href="https://en.wikipedia.org/wiki/Feature_scaling">scale the features</a> to lie between -1 and 1, which is what the scale step does.</p>
<p>The <code>dim_red</code> step uses a scikit-learn function called <code>SelectKBest()</code>, applying something called the <a href="https://en.wikipedia.org/wiki/Chi-squared_test">chi-squared test</a> to select the K "best" features. The <code>scale</code> step uses a scikit-learn function called <code>MaxAbsScaler()</code> in order to squash the relevant features into the interval -1 to 1.</p>
<p>You won't need to do anything extra with these functions here, just complete the vectorizing pipeline steps below. However, notice how easy it was to add more processing steps to our pipeline!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">chi2</span><span class="p">,</span> <span class="n">SelectKBest</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MaxAbsScaler</span>

<span class="c1"># Select 300 best features</span>
<span class="n">chi_k</span> <span class="o">=</span> <span class="mi">300</span>

<span class="c1"># Perform preprocessing</span>
<span class="n">get_text_data</span> <span class="o">=</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">combine_text_columns</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">get_numeric_data</span> <span class="o">=</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="n">NUMERIC_COLUMNS</span><span class="p">],</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Create the token pattern: TOKENS_ALPHANUMERIC</span>
<span class="n">TOKENS_ALPHANUMERIC</span> <span class="o">=</span> <span class="s1">'[A-Za-z0-9]+(?=</span><span class="se">\\</span><span class="s1">s+)'</span>

<span class="c1"># Instantiate pipeline: pl</span>
<span class="n">pl</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s1">'union'</span><span class="p">,</span> <span class="n">FeatureUnion</span><span class="p">(</span>
            <span class="n">transformer_list</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">(</span><span class="s1">'numeric_features'</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">([</span>
                    <span class="p">(</span><span class="s1">'selector'</span><span class="p">,</span> <span class="n">get_numeric_data</span><span class="p">),</span>
                    <span class="p">(</span><span class="s1">'imputer'</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">())</span>
                <span class="p">])),</span>
                <span class="p">(</span><span class="s1">'text_features'</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">([</span>
                    <span class="p">(</span><span class="s1">'selector'</span><span class="p">,</span> <span class="n">get_text_data</span><span class="p">),</span>
                    <span class="p">(</span><span class="s1">'vectorizer'</span><span class="p">,</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">token_pattern</span><span class="o">=</span><span class="n">TOKENS_ALPHANUMERIC</span><span class="p">,</span>
                                                   <span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))),</span>
                    <span class="p">(</span><span class="s1">'dim_red'</span><span class="p">,</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">chi2</span><span class="p">,</span> <span class="n">chi_k</span><span class="p">))</span>
                <span class="p">]))</span>
             <span class="p">]</span>
        <span class="p">)),</span>
        <span class="p">(</span><span class="s1">'scale'</span><span class="p">,</span> <span class="n">MaxAbsScaler</span><span class="p">()),</span>
        <span class="p">(</span><span class="s1">'clf'</span><span class="p">,</span> <span class="n">OneVsRestClassifier</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)))</span>
    <span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Compute and print accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Accuracy on budget dataset: "</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Accuracy on budget dataset:  0.5466491786896509
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Learning-from-the-expert:-a-stats-trick">
<a class="anchor" href="#Learning-from-the-expert:-a-stats-trick" aria-hidden="true"><span class="octicon octicon-link"></span></a>Learning from the expert: a stats trick<a class="anchor-link" href="#Learning-from-the-expert:-a-stats-trick"> </a>
</h2>
<ul>
<li>Interaction terms<ul>
<li>Example<ul>
<li>English teacher for 2nd grade</li>
<li>2nd grade - budget for English teacher</li>
</ul>
</li>
<li>Interaction terms mathematically describe when tokens appear together</li>
<li>the math:
$$ \beta_1 x_1 + \beta_2 x_2 + \beta_3 (x_1 \times x_2) $$</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Implement-interaction-modeling-in-scikit-learn">
<a class="anchor" href="#Implement-interaction-modeling-in-scikit-learn" aria-hidden="true"><span class="octicon octicon-link"></span></a>Implement interaction modeling in scikit-learn<a class="anchor-link" href="#Implement-interaction-modeling-in-scikit-learn"> </a>
</h3>
<p>It's time to add interaction features to your model. The <code>PolynomialFeatures</code> object in scikit-learn does just that, but here you're going to use a custom interaction object, <code>SparseInteractions</code>. Interaction terms are a statistical tool that lets your model express what happens if two features appear together in the same row.</p>
<p><code>SparseInteractions</code> does the same thing as <code>PolynomialFeatures</code>, but it uses sparse matrices to do so. You can get the code for <code>SparseInteractions</code> at <a href="https://github.com/drivendataorg/box-plots-sklearn/blob/master/src/features/SparseInteractions.py">this GitHub Gist</a>.</p>
<p><code>PolynomialFeatures</code> and <code>SparseInteractions</code> both take the argument <code>degree</code>, which tells them what polynomial degree of interactions to compute.</p>
<p>You're going to consider interaction terms of <code>degree=2</code> in your pipeline. You will insert these steps after the preprocessing steps you've built out so far, but before the classifier steps.</p>
<p>Pipelines with interaction terms take a while to train (since you're making n features into n-squared features!), so as long as you set it up right, we'll do the heavy lifting and tell you what your score is!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">combinations</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">sparse</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span>


<span class="k">class</span> <span class="nc">SparseInteractions</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">feature_name_separator</span><span class="o">=</span><span class="s2">"_"</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">=</span> <span class="n">degree</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_name_separator</span> <span class="o">=</span> <span class="n">feature_name_separator</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">sparse</span><span class="o">.</span><span class="n">isspmatrix_csc</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">csc_matrix</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="s2">"columns"</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">orig_col_names</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">orig_col_names</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])])</span>

        <span class="n">spi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_sparse_interactions</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spi</span>

    <span class="k">def</span> <span class="nf">get_feature_names</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span>

    <span class="k">def</span> <span class="nf">_create_sparse_interactions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">out_mat</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">orig_col_names</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">sub_degree</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">col_ixs</span> <span class="ow">in</span> <span class="n">combinations</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">sub_degree</span><span class="p">):</span>
                <span class="c1"># add name for new column</span>
                <span class="n">name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_name_separator</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">orig_col_names</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">col_ixs</span><span class="p">)])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

                <span class="c1"># get column multiplications value</span>
                <span class="n">out</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">col_ixs</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">col_ixs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
                    <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">j</span><span class="p">])</span>

                <span class="n">out_mat</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">sparse</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">X</span><span class="p">]</span> <span class="o">+</span> <span class="n">out_mat</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pl</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s1">'union'</span><span class="p">,</span> <span class="n">FeatureUnion</span><span class="p">(</span>
            <span class="n">transformer_list</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">(</span><span class="s1">'numeric_features'</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">([</span>
                    <span class="p">(</span><span class="s1">'selector'</span><span class="p">,</span> <span class="n">get_numeric_data</span><span class="p">),</span>
                    <span class="p">(</span><span class="s1">'imputer'</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">())</span>
                <span class="p">])),</span>
                <span class="p">(</span><span class="s1">'text_features'</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">([</span>
                    <span class="p">(</span><span class="s1">'selector'</span><span class="p">,</span> <span class="n">get_text_data</span><span class="p">),</span>
                    <span class="p">(</span><span class="s1">'vectorizer'</span><span class="p">,</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">token_pattern</span><span class="o">=</span><span class="n">TOKENS_ALPHANUMERIC</span><span class="p">,</span>
                                                   <span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))),</span>  
                    <span class="p">(</span><span class="s1">'dim_red'</span><span class="p">,</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">chi2</span><span class="p">,</span> <span class="n">chi_k</span><span class="p">))</span>
                <span class="p">]))</span>
             <span class="p">]</span>
        <span class="p">)),</span>
        <span class="p">(</span><span class="s1">'int'</span><span class="p">,</span> <span class="n">SparseInteractions</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">'scale'</span><span class="p">,</span> <span class="n">MaxAbsScaler</span><span class="p">()),</span>
        <span class="p">(</span><span class="s1">'clf'</span><span class="p">,</span> <span class="n">OneVsRestClassifier</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)))</span>
    <span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Compute and print accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Accuracy on sparse interaction: "</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Accuracy on sparse interaction:  0.7826369371057398
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Learning-from-the-expert-the-winning-model">
<a class="anchor" href="#Learning-from-the-expert-the-winning-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Learning from the expert the winning model<a class="anchor-link" href="#Learning-from-the-expert-the-winning-model"> </a>
</h2>
<ul>
<li>The hashing trick<ul>
<li>Adding new features may cause enormous increase in array size</li>
<li>Hashing is a way of increasing memory efficiency<ul>
<li>Hash function limits possible outputs, fixing array size</li>
</ul>
</li>
</ul>
</li>
<li>When to use the hashing trick<ul>
<li>Want to make array of features as small as possible<ul>
<li>Dimensionality reduction</li>
<li>Particularly useful on large datasets</li>
<li>E.g., lots of text data!</li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Why-is-hashing-a-useful-trick?">
<a class="anchor" href="#Why-is-hashing-a-useful-trick?" aria-hidden="true"><span class="octicon octicon-link"></span></a>Why is hashing a useful trick?<a class="anchor-link" href="#Why-is-hashing-a-useful-trick?"> </a>
</h3>
<p>In the video, Peter explained that a <a href="https://en.wikipedia.org/wiki/Feature_hashing#Feature_vectorization_using_the_hashing_trick">hash</a> function takes an input, in your case a token, and outputs a hash value. For example, the input may be a string and the hash value may be an integer.</p>
<p>By explicitly stating how many possible outputs the hashing function may have, we limit the size of the objects that need to be processed. With these limits known, computation can be made more efficient and we can get results faster, even on large datasets.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Implementing-the-hashing-trick-in-scikit-learn">
<a class="anchor" href="#Implementing-the-hashing-trick-in-scikit-learn" aria-hidden="true"><span class="octicon octicon-link"></span></a>Implementing the hashing trick in scikit-learn<a class="anchor-link" href="#Implementing-the-hashing-trick-in-scikit-learn"> </a>
</h3>
<p>In this exercise you will check out the scikit-learn implementation of <code>HashingVectorizer</code> before adding it to your pipeline later.</p>
<p>As you saw in the video, <code>HashingVectorizer</code> acts just like <code>CountVectorizer</code> in that it can accept <code>token_pattern</code> and <code>ngram_range</code> parameters. The important difference is that it creates hash values from the text, so that we get all the computational advantages of hashing!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">HashingVectorizer</span>

<span class="c1"># Get text data: text_data</span>
<span class="n">text_data</span> <span class="o">=</span> <span class="n">combine_text_columns</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># Create the token pattern: TOKENS_ALPHANUMERIC</span>
<span class="n">TOKENS_ALPHANUMERIC</span> <span class="o">=</span> <span class="s1">'[A-Za-z0-9]+(?=</span><span class="se">\\</span><span class="s1">s+)'</span> 

<span class="c1"># Instantiate the HashingVectorizer: hashing_vec</span>
<span class="n">hashing_vec</span> <span class="o">=</span> <span class="n">HashingVectorizer</span><span class="p">(</span><span class="n">token_pattern</span><span class="o">=</span><span class="n">TOKENS_ALPHANUMERIC</span><span class="p">)</span>

<span class="c1"># Fit and transform the Hashing Vectorizer</span>
<span class="n">hashed_text</span> <span class="o">=</span> <span class="n">hashing_vec</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">text_data</span><span class="p">)</span>

<span class="c1"># Create DataFrame and print the head</span>
<span class="n">hashed_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">hashed_text</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">hashed_df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>          0
0  0.377964
1  0.755929
2  0.377964
3  0.377964
4  0.235702
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-winning-model">
<a class="anchor" href="#Build-the-winning-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Build the winning model<a class="anchor-link" href="#Build-the-winning-model"> </a>
</h3>
<p>You have arrived! This is where all of your hard work pays off. It's time to build the model that won DrivenData's competition.</p>
<p>You've constructed a robust, powerful pipeline capable of processing training and testing data. Now that you understand the data and know all of the tools you need, you can essentially solve the whole problem in a relatively small number of lines of code. Wow!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pl</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s1">'union'</span><span class="p">,</span> <span class="n">FeatureUnion</span><span class="p">(</span>
            <span class="n">transformer_list</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">(</span><span class="s1">'numeric_features'</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">([</span>
                    <span class="p">(</span><span class="s1">'selector'</span><span class="p">,</span> <span class="n">get_numeric_data</span><span class="p">),</span>
                    <span class="p">(</span><span class="s1">'imputer'</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">())</span>
                <span class="p">])),</span>
                <span class="p">(</span><span class="s1">'text_features'</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">([</span>
                    <span class="p">(</span><span class="s1">'selector'</span><span class="p">,</span> <span class="n">get_text_data</span><span class="p">),</span>
                    <span class="p">(</span><span class="s1">'vectorizer'</span><span class="p">,</span> <span class="n">HashingVectorizer</span><span class="p">(</span><span class="n">token_pattern</span><span class="o">=</span><span class="n">TOKENS_ALPHANUMERIC</span><span class="p">,</span>
                                                     <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">binary</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                     <span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))),</span>
                    <span class="p">(</span><span class="s1">'dim_red'</span><span class="p">,</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">chi2</span><span class="p">,</span> <span class="n">chi_k</span><span class="p">))</span>
                <span class="p">]))</span>
             <span class="p">]</span>
        <span class="p">)),</span>
        <span class="p">(</span><span class="s1">'int'</span><span class="p">,</span> <span class="n">SparseInteractions</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">'scale'</span><span class="p">,</span> <span class="n">MaxAbsScaler</span><span class="p">()),</span>
        <span class="p">(</span><span class="s1">'clf'</span><span class="p">,</span> <span class="n">OneVsRestClassifier</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">()))</span>
    <span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="goodboychan/goodboychan.github.io"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/python/datacamp/machine_learning/2020/06/05/01-School-Budgeting-with-Machine-Learning-in-Python.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/goodboychan" target="_blank" title="goodboychan"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/chanseokk" target="_blank" title="chanseokk"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" target="_blank" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
