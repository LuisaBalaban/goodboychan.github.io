<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Fine-tuning your model | Chan`s Jupyter</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Fine-tuning your model" />
<meta name="author" content="Chanseok Kang" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A Summary of lecture “Supervised Learning with scikit-learn”, via datacamp" />
<meta property="og:description" content="A Summary of lecture “Supervised Learning with scikit-learn”, via datacamp" />
<link rel="canonical" href="https://goodboychan.github.io/python/datacamp/machine_learning/2020/05/30/01-Fine-tuning-your-model.html" />
<meta property="og:url" content="https://goodboychan.github.io/python/datacamp/machine_learning/2020/05/30/01-Fine-tuning-your-model.html" />
<meta property="og:site_name" content="Chan`s Jupyter" />
<meta property="og:image" content="https://goodboychan.github.io/images/roc-curve.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-05-30T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://goodboychan.github.io/python/datacamp/machine_learning/2020/05/30/01-Fine-tuning-your-model.html","headline":"Fine-tuning your model","dateModified":"2020-05-30T00:00:00-05:00","datePublished":"2020-05-30T00:00:00-05:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://goodboychan.github.io/python/datacamp/machine_learning/2020/05/30/01-Fine-tuning-your-model.html"},"image":"https://goodboychan.github.io/images/roc-curve.png","author":{"@type":"Person","name":"Chanseok Kang"},"description":"A Summary of lecture “Supervised Learning with scikit-learn”, via datacamp","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://goodboychan.github.io/feed.xml" title="Chan`s Jupyter" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-33905785-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-33905785-1');
</script>


<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>

<script data-ad-client="ca-pub-6747875619665490" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Chan`s Jupyter</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/book/">Book</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Fine-tuning your model</h1><p class="page-description">A Summary of lecture "Supervised Learning with scikit-learn", via datacamp</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-05-30T00:00:00-05:00" itemprop="datePublished">
        May 30, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Chanseok Kang</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      13 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#Python">Python</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#Datacamp">Datacamp</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#Machine_Learning">Machine_Learning</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/goodboychan/goodboychan.github.io/tree/main/_notebooks/2020-05-30-01-Fine-tuning-your-model.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/goodboychan/goodboychan.github.io/main?filepath=_notebooks%2F2020-05-30-01-Fine-tuning-your-model.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/goodboychan/goodboychan.github.io/blob/main/_notebooks/2020-05-30-01-Fine-tuning-your-model.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Fgoodboychan%2Fgoodboychan.github.io%2Fblob%2Fmain%2F_notebooks%2F2020-05-30-01-Fine-tuning-your-model.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#How-good-is-your-model?">How good is your model? </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Metrics-for-classification">Metrics for classification </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Preprocess">Preprocess </a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Logistic-regression-and-the-ROC-curve">Logistic regression and the ROC curve </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Building-a-logistic-regression-model">Building a logistic regression model </a></li>
<li class="toc-entry toc-h3"><a href="#Plotting-an-ROC-curve">Plotting an ROC curve </a></li>
<li class="toc-entry toc-h3"><a href="#Precision-recall-Curve">Precision-recall Curve </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Area-under-the-ROC-curve-(AUC)">Area under the ROC curve (AUC) </a>
<ul>
<li class="toc-entry toc-h3"><a href="#AUC-computation">AUC computation </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Hyperparameter-tuning">Hyperparameter tuning </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Hyperparameter-tuning-with-GridSearchCV">Hyperparameter tuning with GridSearchCV </a></li>
<li class="toc-entry toc-h3"><a href="#Hyperparameter-tuning-with-RandomizedSearchCV">Hyperparameter tuning with RandomizedSearchCV </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Hold-out-set-for-final-evaluation">Hold-out set for final evaluation </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Hold-out-set-in-practice-I:-Classification">Hold-out set in practice I: Classification </a></li>
<li class="toc-entry toc-h3"><a href="#Hold-out-set-in-practice-II:-Regression">Hold-out set in practice II: Regression </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Preprocess">Preprocess </a></li>
</ul>
</li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-05-30-01-Fine-tuning-your-model.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="How-good-is-your-model?">
<a class="anchor" href="#How-good-is-your-model?" aria-hidden="true"><span class="octicon octicon-link"></span></a>How good is your model?<a class="anchor-link" href="#How-good-is-your-model?"> </a>
</h2>
<ul>
<li>Classification metrics<ul>
<li>Measuring model performance with accuracy:<ul>
<li>Fraction of correctly classified samples</li>
<li>Not always a useful metrics</li>
</ul>
</li>
</ul>
</li>
<li>Class imbalance example: Emails<ul>
<li>Spam classification<ul>
<li>99% of emails are real; 1% of emails are spam</li>
</ul>
</li>
<li>Could build a classifier that predicts ALL emails as real<ul>
<li>99% accurate!</li>
<li>But horrible at actually classifying spam</li>
<li>Fails at its original purpose</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Diagnosing classification predictions</p>
<ul>
<li>
<p>Confusion matrix
<img src="/images/copied_from_nb/image/confusion_matrix.png" alt="cm"></p>
</li>
<li>
<p>Accuracy:
$$ \dfrac{tp + tn}{tp + tn + fp + fn} $$</p>
</li>
<li>
<p>Precision (Positive Predictive Value):
$$ \dfrac{tp}{tp + fp}$$</p>
</li>
<li>
<p>Recall (Sensitivity, hit rate, True Positive Rate):
$$ \dfrac{tp}{tp + fn}$$</p>
</li>
<li>
<p>F1 score: Harmonic mean of precision and recall
$$ 2 \cdot \dfrac{\text{precision} \cdot \text{recall}}{\text{precision} + \text{recall}} $$</p>
</li>
<li>
<p>High precision : Not many real emails predicted as spam</p>
</li>
<li>High recall : Predicted most spam emails correctly</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Metrics-for-classification">
<a class="anchor" href="#Metrics-for-classification" aria-hidden="true"><span class="octicon octicon-link"></span></a>Metrics for classification<a class="anchor-link" href="#Metrics-for-classification"> </a>
</h3>
<p>Accuracy is not always an informative metric. In this exercise, you will dive more deeply into evaluating the performance of binary classifiers by computing a confusion matrix and generating a classification report.</p>
<p>You may have noticed in the video that the classification report consisted of three rows, and an additional support column. The support gives the number of samples of the true response that lie in that class - so in the video example, the support was the number of Republicans or Democrats in the test set on which the classification report was computed. The precision, recall, and f1-score columns, then, gave the respective metrics for that particular class.</p>
<p>Here, you'll work with the <a href="https://www.kaggle.com/uciml/pima-indians-diabetes-database">PIMA Indians</a> dataset obtained from the UCI Machine Learning Repository. The goal is to predict whether or not a given female patient will contract diabetes based on features such as BMI, age, and number of pregnancies. Therefore, it is a binary classification problem. A target value of 0 indicates that the patient does not have diabetes, while a value of 1 indicates that the patient does have diabetes. As in Chapters 1 and 2, the dataset has been preprocessed to deal with missing values.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Preprocess">
<a class="anchor" href="#Preprocess" aria-hidden="true"><span class="octicon octicon-link"></span></a>Preprocess<a class="anchor-link" href="#Preprocess"> </a>
</h4>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'./dataset/diabetes.csv'</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pregnancies</th>
      <th>glucose</th>
      <th>diastolic</th>
      <th>triceps</th>
      <th>insulin</th>
      <th>bmi</th>
      <th>dpf</th>
      <th>age</th>
      <th>diabetes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>6</td>
      <td>148</td>
      <td>72</td>
      <td>35</td>
      <td>0</td>
      <td>33.6</td>
      <td>0.627</td>
      <td>50</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>85</td>
      <td>66</td>
      <td>29</td>
      <td>0</td>
      <td>26.6</td>
      <td>0.351</td>
      <td>31</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8</td>
      <td>183</td>
      <td>64</td>
      <td>0</td>
      <td>0</td>
      <td>23.3</td>
      <td>0.672</td>
      <td>32</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>89</td>
      <td>66</td>
      <td>23</td>
      <td>94</td>
      <td>28.1</td>
      <td>0.167</td>
      <td>21</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>137</td>
      <td>40</td>
      <td>35</td>
      <td>168</td>
      <td>43.1</td>
      <td>2.288</td>
      <td>33</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>

<span class="c1"># Create training and test set</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Instantiate a k-NN classifier: knn</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>

<span class="c1"># Fit the classifier to the training data</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Predict the labels of the test data: y_pred</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Generate the confusion matrix and classification report</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[[176  30]
 [ 56  46]]
              precision    recall  f1-score   support

           0       0.76      0.85      0.80       206
           1       0.61      0.45      0.52       102

    accuracy                           0.72       308
   macro avg       0.68      0.65      0.66       308
weighted avg       0.71      0.72      0.71       308

</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Logistic-regression-and-the-ROC-curve">
<a class="anchor" href="#Logistic-regression-and-the-ROC-curve" aria-hidden="true"><span class="octicon octicon-link"></span></a>Logistic regression and the ROC curve<a class="anchor-link" href="#Logistic-regression-and-the-ROC-curve"> </a>
</h2>
<ul>
<li>Logistic regression for binary classification<ul>
<li>Logistic regression outputs probabilities</li>
<li>If the probability is greater than 0.5:<ul>
<li>The data is labeled '1'</li>
</ul>
</li>
<li>If the probability is less than 0.5:<ul>
<li>The data is labeled '0'</li>
</ul>
</li>
</ul>
</li>
<li>Probability thresholds<ul>
<li>By default, logistic regression threshold = 0.5</li>
<li>Not specific to logistic regression<ul>
<li>k-NN classifiers also have thresholds</li>
</ul>
</li>
</ul>
</li>
<li>ROC curves (Receiver Operating Characteristic curve)
<img src="/images/copied_from_nb/./image/roc.png" alt="roc">
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Building-a-logistic-regression-model">
<a class="anchor" href="#Building-a-logistic-regression-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Building a logistic regression model<a class="anchor-link" href="#Building-a-logistic-regression-model"> </a>
</h3>
<p>Time to build your first logistic regression model! As Hugo showed in the video, scikit-learn makes it very easy to try different models, since the Train-Test-Split/Instantiate/Fit/Predict paradigm applies to all classifiers and regressors - which are known in scikit-learn as 'estimators'. You'll see this now for yourself as you train a logistic regression model on exactly the same data as in the previous exercise. Will it outperform k-NN? There's only one way to find out!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="c1"># Create training and test sets</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Create the classifier: logreg</span>
<span class="n">logreg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>

<span class="c1"># Fit the classifier to the training data</span>
<span class="n">logreg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Predict the labels of the test set: y_pred</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">logreg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Compute and print the confusion matrix and classification report</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[[168  38]
 [ 36  66]]
              precision    recall  f1-score   support

           0       0.82      0.82      0.82       206
           1       0.63      0.65      0.64       102

    accuracy                           0.76       308
   macro avg       0.73      0.73      0.73       308
weighted avg       0.76      0.76      0.76       308

</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Plotting-an-ROC-curve">
<a class="anchor" href="#Plotting-an-ROC-curve" aria-hidden="true"><span class="octicon octicon-link"></span></a>Plotting an ROC curve<a class="anchor-link" href="#Plotting-an-ROC-curve"> </a>
</h3>
<p>Great job in the previous exercise - you now have a new addition to your toolbox of classifiers!</p>
<p>Classification reports and confusion matrices are great methods to quantitatively evaluate model performance, while ROC curves provide a way to visually evaluate models. As Hugo demonstrated in the video, most classifiers in scikit-learn have a <code>.predict_proba()</code> method which returns the probability of a given sample being in a particular class. Having built a logistic regression model, you'll now evaluate its performance by plotting an ROC curve. In doing so, you'll make use of the <code>.predict_proba()</code> method and become familiar with its functionality.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span>

<span class="c1"># Compute predicted probabilities: y_pred_prob</span>
<span class="n">y_pred_prob</span> <span class="o">=</span> <span class="n">logreg</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>

<span class="c1"># Generate ROC curve values: fpr, tpr, thresholds</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_prob</span><span class="p">)</span>

<span class="c1"># Plot ROC curve</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">'k--'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'False Positive Rate'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'True Positive Rate'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'ROC Curve'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxU9fX/8dcxccOqVUErsu8JixajiKiIKIvFirYoyhelBihQ3NCquCBS9QcIouybCCKLSkGx5VtqtVa/VEQERIgikR1RFlnEhSWc3x8zsdOYZUJyM5mZ9/PxmIdzZ+7MPTfEnPtZ7vmYuyMiIsnrmFgHICIisaVEICKS5JQIRESSnBKBiEiSUyIQEUlySgQiIklOiUBEJMkpEUhCMbMNZva9me03sy/NbKqZ/SzPPheb2Vtm9o2Z7TWz180sPc8+p5jZM2a2Kfxd2eHtigUc18zsDjNbZWbfmtkWM3vFzBoHeb4ipUGJQBLRNe7+M+A84JdA/9w3zKw58HfgNaAyUBP4CFhkZrXC+xwHvAk0BNoBpwAXA7uACws45rPAncAdwOlAPeBV4FfFDd7MUov7GZGSMN1ZLInEzDYA3d39H+HtoUBDd/9VePtd4GN375Pnc/8L7HD3W8ysO/AEUNvd90dxzLrAp0Bzd19SwD5vAy+6++TwdrdwnJeEtx3oC9wFpAILgf3ufm/Ed7wG/MvdnzazysAo4DJgPzDC3UdG8SMS+Qm1CCRhmVkVoD2QHd6uQOjK/pV8dn8ZuCr8/Ergb9EkgbDWwJaCkkAxdASaAenATOBGMzMAMzsNaAPMNrNjgNcJtWTOCR//LjNrW8LjS5JSIpBE9KqZfQNsBrYDj4ZfP53Q7/y2fD6zDcjt/z+jgH0KUtz9C/L/3P1rd/8eeBdw4NLwe78F3nP3L4ALgEruPsjdD7r7OmAS0LkUYpAkpEQgiaiju58MXA404D9/4HcDR4Cz8/nM2cDO8PNdBexTkOLuX5DNuU881Gc7G7gp/NLNwIzw8+pAZTPbk/sAHgTOKoUYJAkpEUjCcvd/AVOBYeHtb4H3gE757H4DoQFigH8Abc3spCgP9SZQxcwyCtnnW6BCxPYv8gs5z/Ys4LdmVp1Ql9Gfw69vBta7+88jHie7+9VRxivyX5QIJNE9A1xlZueFtx8Abg1P9TzZzE4zs8eB5sBj4X2mE/pj+2cza2Bmx5jZGWb2oJn95I+tu68FxgKzzOxyMzvOzE4ws85m9kB4txXA9WZWwczqAJlFBe7uy4EdwGRgobvvCb+1BNhnZveb2YlmlmJmjczsgqP5AYkoEUhCc/cdwAvAI+Ht/wPaAtcT6tffSGiK6SXhP+i4+wFCA8afAm8A+wj98a0IvF/Aoe4ARgNjgD3A58B1hAZ1AUYAB4GvgGn8p5unKLPCscyMOKcc4BpC02PXE+rSmgycGuV3ivwXTR8VEUlyahGIiCQ5JQIRkSSnRCAikuSUCEREklzcFbeqWLGi16hRI9ZhiIjElQ8//HCnu1fK7724SwQ1atRg6dKlsQ5DRCSumNnGgt5T15CISJJTIhARSXJKBCIiSU6JQEQkySkRiIgkucASgZlNMbPtZraqgPfNzEaGFwVfaWZNg4pFREQKFmSLYCqhhb8L0h6oG370BMYFGIuIiBQgsPsI3P0dM6tRyC7XAi+EV2JabGY/N7Oz3b00lvwTESk3Zr6/iddWbD3qzx85ksPBg4doWutMHr2mYSlGFhLLMYJziFiaD9gSfu0nzKynmS01s6U7duwok+BERErLayu2krVt31F9ds+ePXzwwVJWr15NUMsGxPLOYsvntXzP0t0nAhMBMjIytICCiAAlv9IuK1nb9pF+9im89PvmUX9mz549/PGPf+TlyZOpU6cOkydPpmXLRoHEF8tEsAWoGrFdBfgiRrGISBzKvdJOP/uUWIdSqPSzT+Ha8/Lt8MhXTk4OF198MWvWrOG+++5j4MCBnHjiiYHFF8tEMB/oa2azCS3MvVfjAyLlS3m/4j6aK+3ybNeuXZx++umkpKTwxBNPULVqVTIyMgI/bpDTR2cB7wH1zWyLmWWaWS8z6xXeZQGwDsgGJgF9gopFRI5OSfq2y0Jxr7TLK3fnxRdfpF69ekyePBmA6667rkySAAQ7a+imIt534A9BHV9Eiie/q/9Eu+IujzZv3kyvXr1YsGABF110ES1atCjzGHRnsYgA+V/9J8oVd3k1a9YsGjZsyNtvv80zzzzD//3f/5Genl7mccTdegQi8lOl0Zevq/+yd9ppp9GsWTMmTpxIzZo1YxaHEoFIAiiN2TO6+g/e4cOHGTFiBAcPHuShhx6iXbt2tG3bFrP8ZtOXHSUCkThS0JW/rubLv48++ojMzEw+/PBDbrjhBtwdM4t5EgCNEYjElYJm8ehqvvw6cOAAjzzyCBkZGWzevJlXXnmF2bNnl4sEkEstApGABDEHX1f+8Wft2rUMGTKEm2++maeffpozzjgj1iH9hFoEIgEJYg6+rvzjw/79+5kxYwYAjRo14tNPP2XatGnlMgmAWgQigdLVe/J544036NmzJxs3bqRp06akpaVRq1atWIdVKLUIRERKwe7du8nMzKRNmzYcd9xx/Otf/yItLS3WYUVFLQKRUhQ5LhAPxdCkdOTk5NCiRQs+++wz+vfvz4ABAzjhhBNiHVbUlAhESlHkfH715ye+nTt3/lgk7sknn6RatWo0bRp/q+4qEYgU4Ghm/WhWT3Jwd6ZPn85dd93F4MGD6dmzJx07dox1WEdNYwQiBTiaWT9qBSS+jRs30r59e2699VbS0tK47LLLYh1SialFIIIqb0p0XnzxRXr37o27M2rUKPr06cMxx8T/9XT8n4FIKVDlTYlGpUqVaNGiBatXr6Zv374JkQRALQJJYvnN8NHVv0Q6dOgQw4cP59ChQzzyyCO0bduWNm3alKvyEKUhMdKZyFGIbAXo6l/yWr58Oc2aNaN///5kZWURWkuLhEsCoBaBJDm1AiSvH374gUGDBjF06FAqVqzIn//8Z66//vpYhxUoJQKJayUp7KYbviQ/2dnZDBs2jFtuuYXhw4dz2mmnxTqkwKlrSOJaSQq7qTtIcu3fv5/p06cDoSJxa9asYcqUKUmRBEAtAkkA6t6Rkli4cCE9e/Zk8+bNZGRkkJaWFtNlI2NBLQIRSUq7du3i1ltvpV27dlSoUIF33303borElTYlAolbM9/fxPvrv451GBKHcovEzZgxg4ceeojly5fTokWLWIcVM+oakriVO0isfn6J1o4dOzjjjDNISUlhyJAhVK9enfPOOy/WYcWcWgQSl3JbA81qns7NzarFOhwp59yd559/nnr16jFp0iQArr32WiWBMCUCiUtqDUi0NmzYQNu2bbntttto3LgxrVq1inVI5Y66hiRu5C0JodaAFGX69On07t0bM2Ps2LH8/ve/T5j6QKVJPxGJGyoJIcV11llncdlll7F69Wp69+6tJFAAtQgkcCW5+zeSCsNJUQ4dOsTQoUPJyclhwIABtGnThjZt2sQ6rHJP6VECV5K7fyOpFSCFWbZsGRdccAEPP/wwa9as+bFInBRNLQIJTG5LQFfyEqTvv/+exx57jGHDhlGpUiXmzZsX18tGxkKgLQIza2dma8ws28weyOf9amb2TzNbbmYrzezqIOORshWZBHQlL0FZt24dTz/9NN26dSMrK0tJ4CgE1iIwsxRgDHAVsAX4wMzmu3tWxG4PAy+7+zgzSwcWADWCikmClXcsQC0BCcq+ffuYO3cu3bp1o2HDhqxdu5bq1avHOqy4FWSL4EIg293XuftBYDZwbZ59HMitA3wq8EWA8UjA8o4FqCUgQViwYAGNGjUiMzOTTz75BEBJoISCHCM4B9gcsb0FaJZnn4HA383sduAk4Mr8vsjMegI9AapV07zx8kwtAAnKzp07ufvuu3nxxRdJT09n0aJFSVskrrQF2SLIbz23vMP4NwFT3b0KcDUw3cx+EpO7T3T3DHfPqFSpUgChikh5llskbvbs2QwYMIBly5Zx0UUXxTqshBFki2ALUDViuwo/7frJBNoBuPt7ZnYCUBHYHmBcUoryWwBepLR89dVXVKpUiZSUFIYNG0b16tVp0qRJrMNKOEG2CD4A6ppZTTM7DugMzM+zzyagNYCZpQEnADsCjElKme72lSC4O8899xz169dn4sSJAFxzzTVKAgEJrEXg7ofNrC+wEEgBprj7ajMbBCx19/nAPcAkM7ubULdRN9ddIHEjsgKoxgWktKxbt44ePXrw1ltv0bJlS668Mt+hQylFgd5Q5u4LCE0JjXxtQMTzLCB5V4OIc6oAKqVt2rRp9OnTh5SUFMaPH0+PHj1UH6gM6M5iKRZVAJUgVa5cmSuuuIJx48ZRpUqVWIeTNJQIpFgi7xbWmICU1MGDBxk8eDBHjhxh4MCBXHXVVVx11VWxDivpKBFIseleASkNH3zwAbfddhurVq2ia9euuDtm+c06l6Cp801EytR3333Hvffey0UXXcTu3buZP38+L7zwgpJADKlFIAXKbx0B3SsgJbV+/XpGjRpFjx49GDJkCKeeemqsQ0p6ahFIgfJbR0DjAnI09u7dy/PPPw9Aw4YNyc7OZvz48UoC5YRaBFIojQdISf31r3/l97//Pdu2baN58+Y0aNCAqlWrFv1BKTNqEYhIIHbs2EGXLl3o0KEDp512Gu+99x4NGjSIdViSD7UIRKTU5eTkcMkll7B+/Xoee+wxHnjgAY477rhYhyUFiCoRhGsFVXP37IDjkRhTETkpiS+//JIzzzyTlJQUhg8fTo0aNWjUqFGsw5IiFNk1ZGa/Aj4G3ghvn2dm84IOTGJDReTkaBw5coQJEyZQr149JkyYAECHDh2UBOJENC2CQYQWlPkngLuvMLM6gUYlZSq/VoAGiCVa2dnZ9OjRg7fffpsrrriCtm3bxjokKaZoBosPufuePK+pQmgCUStAjtbzzz9P48aNWbZsGZMmTeIf//gHtWrVinVYUkzRtAg+MbMbgGPMrCZwJ7A42LCkrKiUtJREtWrVaNu2LWPGjOGcc3QBEa+iaRH0Bc4HjgBzgR8IJQNJAColLcVx4MABBg4cyIABoWryrVu35tVXX1USiHPRJIK27n6/u/8y/HgAaB90YFJ2VEpaovH+++9z/vnn89hjj7Fp0ya0hlTiiCYRPJzPaw+VdiAiUj59++239OvXj+bNm7N3717+8pe/MHXqVBWJSyAFjhGYWVtCC8ufY2ZPR7x1CqFuIoljuTOFdK+AFGXjxo2MHTuWXr16MXjwYE45Rb8viaawweLtwCpCYwKrI17/BnggyKAkeJFJQOMDkteePXuYM2cO3bt3Jz09nezsbK0YlsAKTATuvhxYbmYz3P2HMoxJyojuF5D8vPbaa/Tu3Zvt27dzySWX0KBBAyWBBBfNGME5ZjbbzFaa2We5j8AjE5EytX37djp37kzHjh2pVKkSixcvVpG4JBHNfQRTgceBYYRmC/0OjRHEjfwWlwHVEZL/lpOTQ4sWLdi0aROPP/449913H8cee2ysw5IyEk0iqODuC81smLt/DjxsZu8GHZiUjoIGhDU2IABffPEFv/jFL0hJSeHZZ5+lRo0apKenxzosKWPRJIIDFpon9rmZ9QK2AmcGG5YUV1FX/hoLkEi5ReLuv/9+Bg8eTJ8+fbj66qtjHZbESDRjBHcDPwPuAFoAPYDbggxKii+/ZSVBV/7yU5999hmtWrWiT58+NGvWjPbtdX9osiuyReDu74effgN0BTAzTSEoh3TlL0V57rnn6Nu3LyeccAJTpkyhW7duujFMCm8RmNkFZtbRzCqGtxua2Quo6JxIXKpRowbt27cnKyuL3/3ud0oCAhR+Z/H/A34DfERogHgeoWJzQ4BeZROe5CpoDCCXZgFJfg4cOMCf/vQnAB5//HFat25N69atYxyVlDeFdQ1dC5zr7t+b2enAF+HtNWUTmkQqqhyExgIkr3//+99kZmby6aefctttt+HuagFIvgpLBD+4+/cA7v61mX2qJFA28rv61+wfidb+/ft56KGHGDVqFFWrVuVvf/ubVg2TQhU2RlDLzOaGH/OAGhHbc6P5cjNrZ2ZrzCzbzPKtT2RmN5hZlpmtNrOZR3MSiSa/GUC64pdobdq0iQkTJvCHP/yBVatWKQlIkQprEfwmz/bo4nyxmaUAY4CrgC3AB2Y2392zIvapC/QHWrj7bjPT/QlhuvqX4ti9ezevvPIKPXv2JD09nXXr1lG5cuVYhyVxorCic2+W8LsvBLLdfR2Amc0mNO6QFbFPD2CMu+8OH3N7CY8pknTmzZtHnz592LFjBy1btqR+/fpKAlIs0dxQdrTOATZHbG8JvxapHlDPzBaZ2WIza5ffF5lZTzNbamZLd+zYEVC4IvHlyy+/pFOnTlx//fX84he/YMmSJdSvXz/WYUkciqbExNHKb3pC3rXtUoG6wOVAFeBdM2vk7nv+60PuE4GJABkZGVofT5JeTk4Ol156KZs3b+bJJ5/k3nvvVZE4OWpRJwIzO97dDxTju7cAVSO2qxCagpp3n8XufghYb2ZrCCWGD4pxnLilyqBSXFu2bKFy5cqkpKQwcuRIatasqVLRUmJFdg2Z2YVm9jGwNrx9rpmNiuK7PwDqmllNMzsO6AzMz7PPq0Cr8PdWJNRVtK4Y8cc11QeSaB05coRRo0bRoEEDxo0bB0D79u2VBKRURNMiGAl0IPRHG3f/yMxaFfUhdz9sZn2BhUAKMMXdV5vZIGCpu88Pv9fGzLKAHOCP7r7rKM8lLml2kBTl008/pXv37ixatIi2bdvSoUOHWIckCSaaRHCMu2/Mc0diTjRf7u4LgAV5XhsQ8dyBfuGHiOQxefJk+vbtS4UKFZg2bRpdu3bV3cFS6qJJBJvN7ELAw/cG3A5oqUqRMlC7dm2uueYaRo8ezVlnnRXrcCRBRZMIehPqHqoGfAX8I/yaiJSyH374gUGDBgHw5JNP0qpVK1q1KrInVqREokkEh929c+CRiCS5RYsWkZmZyZo1a+jevbuKxEmZiSYRfBCe1vkSMNfdvwk4prhXVMnoXJomKgDffPMNDz74IGPGjKF69eosXLiQNm3axDosSSJFTh9199rA48D5wMdm9qqZqYVQiIKmhealaaICoXsDJk+ezO23387HH3+sJCBlLqobytz938C/zWwg8AwwA5gdYFxxT9NCpTC7du3i5Zdfpnfv3qSlpbFu3TrOPvvsWIclSSqaG8p+ZmZdzOx1YAmwA7g48MhEEpC7M2fOHNLT07njjjtYsya0xIeSgMRSNEXnVgEXAUPdvY673xOxoL2IRGnbtm385je/oVOnTlStWpWlS5eqSJyUC9F0DdVy9yOBRyKSwHKLxG3dupWhQ4dy9913k5oaZM1HkegVtnj9cHe/B/izmf2k4qe7Xx9oZCIJYPPmzZxzzjmkpKQwZswYatasSb169WIdlsh/KeyS5KXwf4u1MpmIhFoAY8aMoX///gwdOpQ//OEPWjJSyq3CVihbEn6a5u7/lQzCxeRKuoJZwsm9f0D3ByS3Tz75hMzMTN577z3at2/PNddcE+uQRAoVzWDxbfm8llnagSSCyCSg+wOS08SJEznvvPP47LPPmD59On/961+pVq1arMMSKVRhYwQ3ElpDoKaZzY1462RgT/6fEt0/kNzq1q3Lddddx8iRIznzzDNjHY5IVAobI1gC7CK0stiYiNe/AZYHGZRIvPj+++8ZOHAgZsbgwYNVJE7iUmFjBOuB9YSqjYpIHu+88w7du3dn7dq19OrVS0XiJG4VOEZgZv8K/3e3mX0d8dhtZl+XXYgi5cu+ffvo06cPLVu2JCcnhzfffJNx48YpCUjcKqxrKLd9W7EsAhGJF1988QVTp06lX79+DBo0iJNOOinWIYmUSIEtgoi7iasCKe6eAzQHfg/oN1+Sys6dOxk7diwADRo0YP369QwfPlxJQBJCNNNHXyW0TGVt4AUgDZgZaFQi5YS789JLL5Gens5dd93FZ5+FVmnVspGSSKJJBEfc/RBwPfCMu98OaJK8JLwvvviCjh070rlzZ6pXr86HH36o8hCSkKJaqtLMOgFdgY7h144NLiSR2MvJyeGyyy5j69atDBs2jDvvvFNF4iRhRfObfRvQh1AZ6nVmVhOYFWxYIrGxceNGqlSpQkpKCmPHjqVWrVrUqVMn1mGJBCqapSpXAXcAS82sAbDZ3Z8IPLI4M/P9Tby/XrNq41VOTg5PP/00aWlpjBs3DoA2bdooCUhSKLJFYGaXAtOBrYABvzCzru6+KOjg4knuYvWqMRR/Vq1aRWZmJkuWLKFDhw507Nix6A+JJJBouoZGAFe7exaAmaURSgwZQQYWj5rVPJ2bm6nAWDwZP348d9xxB6eeeiozZ86kc+fOujFMkk40s4aOy00CAO7+CXBccCGJBM89tNZSWloanTp1Iisri5tuuklJQJJSNC2CZWY2gVArAKALKjoH/Gf9AUBrEMSJ7777jgEDBpCSksKQIUNo2bIlLVu2jHVYIjEVTYugF/A5cB9wP7CO0N3FSS93/QFAaxDEgbfffpsmTZowfPhw9u/f/2OrQCTZFdoiMLPGQG1gnrsPLZuQ4kPuLKFmNU/X+gPl3N69e7nvvvuYOHEitWvX5q233lKpaJEIhVUffZBQeYkuwBtmlt9KZUlLs4Tix7Zt23jxxRe59957WblypZKASB6FdQ11AZq4eyfgAqB3cb/czNqZ2RozyzazBwrZ77dm5mYWVzORNEuo/NqxYwejRo0CQkXiNmzYwFNPPUWFChViHJlI+VNYIjjg7t8CuPuOIvb9CTNLIbSyWXsgHbjJzNLz2e9kQjesvV+c74+Vme9v4sYJ7/04NiDli7szc+ZM0tLSuOeee34sElepUqUYRyZSfhX2x72Wmc0NP+YBtSO25xbyuVwXAtnuvs7dDwKzgWvz2e9PwFDgh2JHHwNaoL782rx5M9dccw1dunShTp06LF++XEXiRKJQ2GDxb/Jsjy7md58DbI7Y3gI0i9zBzH4JVHX3v5jZvQV9kZn1BHoCVKsW+64YLVBf/hw+fJjLL7+cL7/8khEjRnD77beTkpIS67BE4kJhaxa/WcLvzu/OnB/n65nZMYTuWu5W1Be5+0RgIkBGRobm/MmPNmzYQNWqVUlNTWXChAnUqlWLWrVqxToskbhSrH7/YtpCaHWzXFWALyK2TwYaAW+b2QbgImB+eR4wVmG58uPw4cMMGzaMtLS0H1cOu/LKK5UERI5CkAXWPwDqhstWbwU6Azfnvunue4lYD9nM3gbudfelAcZUIpoyWj6sXLmSzMxMli5dyrXXXstvfpO3F1NEiiPqFoGZHV+cL3b3w0BfYCHwCfCyu682s0Fm9uvihVl+aMpobI0dO5bzzz+fjRs38tJLLzFv3jwqV64c67BE4lo0ZagvBJ4DTgWqmdm5QPfwkpWFcvcFwII8rw0oYN/LowlYkpO7Y2Y0atSIzp07M2LECCpWrFj0B0WkSNF0DY0EOhC6yxh3/8jMdGumlIlvv/2Whx9+mNTUVJ566ikuu+wyLrvssliHJZJQoukaOsbdN+Z5LSeIYEQivfnmmzRu3JhnnnmGAwcOqEicSECiSQSbw91DbmYpZnYX8FnAcUkS27NnD927d+fKK68kNTWVd955h5EjR2qtAJGARJMIegP9gGrAV4SmeRa77pBItL766itmz57N/fffz0cffcSll14a65BEElqRYwTuvp3Q1E+RwOT+8b/zzjupX78+GzZs0GCwSBmJZtbQJCLuCM7l7j0DiUiSirszY8YM7rzzTvbv38/VV19N3bp1lQREylA0XUP/AN4MPxYBZwIHggxKksOmTZv41a9+RdeuXalfvz4rVqygbt26sQ5LJOlE0zX0UuS2mU0H3ggsIkkKuUXitm/fzsiRI+nTp4+KxInEyNGUmKgJVC/tQMqz3EXqtUB9ya1bt47q1auTmprKpEmTqF27NjVq1Ih1WCJJrciuITPbbWZfhx97CLUGHgw+tPJDaxCU3OHDhxkyZAjp6emMGTMGgNatWysJiJQDRS1eb8C5hIrGARzxJL2rR2sQHL0VK1aQmZnJsmXLuO666+jUqVOsQxKRCIW2CMJ/9Oe5e074kZRJQI7e6NGjueCCC9i6dStz5sxh7ty5nH322bEOS0QiRDNraImZNQ08EkkoudcMTZo0oUuXLmRlZalctEg5VWDXkJmlhktJXwL0MLPPgW8JrTzm7q7kID+xf/9+HnroIY499liGDRumInEicaCwMYIlQFOgYxnFInHu73//Oz179mTTpk3cfvvtP5aOFpHyrbBEYADu/nkZxSJxavfu3fTr14+pU6dSv3593nnnHS655JJYhyUiUSosEVQys34FvenuTwcQT7mTu05xs5qnxzqUcmv79u3MmTOH/v37M2DAAE444YRYhyQixVBYIkgBfka4ZZCstE5x/r788ktmzZrF3Xff/WORuDPOOCPWYYnIUSgsEWxz90FlFkk5knsnMUDWtn1apziCu/PCCy9w9913891339GhQwfq1q2rJCASxwqbPpq0LYHcO4kB3U0cYcOGDbRr145u3bqRnp6uInEiCaKwFkHrMouiHNKdxP/t8OHDtGrVip07dzJmzBh69erFMcdEcxuKiJR3BSYCd/+6LAOR8ik7O5uaNWuSmprKlClTqFWrFtWrJ1XNQZGEp0u6CDPf38SNE977sVsomR06dIgnn3yShg0b/lgkrlWrVkoCIgnoaMpQJyxVGQ1ZtmwZmZmZrFixgk6dOnHjjTfGOiQRCZASQR7JPjYwcuRI+vXrR6VKlZg7dy7XXXddrEMSkYCpa0iA/xSJ++Uvf8ktt9xCVlaWkoBIklCLIMl988039O/fn+OPP57hw4dz6aWXcumll8Y6LBEpQ2oRJLG//e1vNGrUiLFjx+LuaLkJkeSkRJCEdu3axa233kr79u056aSTWLRoEU8//bQqhYokKSWCJLRr1y7mzZvHI488wvLly2nePHkHx0Uk4ERgZu3MbI2ZZZvZA/m838/MssxspZm9aWaapHRNzYcAAA7WSURBVB6Qbdu2MWzYMNydevXqsXHjRgYNGsTxxx8f69BEJMYCSwRmlgKMAdoD6cBNZpaeZ7flQIa7NwHmAEODiidZuTtTpkwhLS2NRx55hOzsbABOO+20GEcmIuVFkC2CC4Fsd1/n7geB2cC1kTu4+z/d/bvw5mKgSoDxJJ3169fTpk0bMjMzOffcc/noo49UJE5EfiLI6aPnAJsjtrcAzQrZPxP43/zeMLOeQE+AatVUDjoahw8f5oorrmDXrl2MGzeOnj17qkiciOQryESQ3xSUfOcnmtn/ABlAy/zed/eJwESAjIwMzXEsxNq1a6lVqxapqak8//zz1K5dm6pVq8Y6LBEpx4K8RNwCRP4FqgJ8kXcnM7sSeAj4tbsfCDCeQuUuSRmvDh06xOOPP06jRo0YPXo0AJdffrmSgIgUKcgWwQdAXTOrCWwFOgM3R+5gZr8EJgDt3H17gLEUKZ6XpFy6dCmZmZmsXLmSzp07c9NNN8U6JBGJI4G1CNz9MNAXWAh8Arzs7qvNbJCZ/Tq821OE1kV+xcxWmNn8oOKJRjwuSfnss8/SrFkzdu7cyWuvvcasWbM488wzYx2WiMSRQGsNufsCYEGe1wZEPL8yyOMnMnfHzMjIyCAzM5OhQ4fy85//PNZhiUgcSvqic7kL1eeuQ1De7du3j/vvv58TTjiBESNG0KJFC1q0aBHrsEQkjiX9fMJ4WoxmwYIFNGzYkIkTJ5KamqoicSJSKpK+RQDlfzGanTt3ctdddzFjxgwaNmzInDlzaNassFsyRESil/Qtgniwe/duXn/9dR599FGWLVumJCAipUotgnJq69atzJgxgz/+8Y/UrVuXjRs3ajBYRAKhFkE54+5MmjSJ9PR0Bg4cyOeffw6gJCAigUnqRFDe7ib+/PPPad26NT179qRp06asXLmSOnXqxDosEUlwSd01VJ7uJj58+DCtW7fm66+/ZsKECXTv3l1F4kSkTCR1IoDY3028Zs0aateuTWpqKtOmTaN27dpUqaJq3CJSdnTJGSMHDx7kscceo3HjxowZMwaAli1bKgmISJlL+hZBLCxZsoTMzExWrVrFzTffTJcuXWIdkogkMbUIytgzzzxD8+bNf7w3YMaMGVSsWDHWYYlIElMiKCO55SAuvPBCevTowerVq+nQoUOMoxIRUddQ4Pbu3ct9993HiSeeyDPPPMPFF1/MxRdfHOuwRER+pBZBgF5//XXS09OZPHkyxx9/vIrEiUi5lHQtgtyy00Bgpad37NjBnXfeyaxZs2jcuDGvvvoqF1xwQakfR0SkNCRdiyC37DQQWOnpvXv3smDBAh577DGWLl2qJCAi5VrStQggmLLTmzdv5sUXX+SBBx6gTp06bNy4kVNPPbVUjyEiEoSkaxGUtiNHjjB+/HgaNmzI448//mOROCUBEYkXSgQlsHbtWq644gp69+7NhRdeyMcff6wicSISd5Kya6g0HD58mKuuuoo9e/bw3HPP8bvf/Q4zi3VYIiLFpkRQTJ988gl169YlNTWV6dOnU7t2bSpXrhzrsEREjpq6hqJ04MABHn30UZo0acLo0aMBuPTSS5UERCTuqUUQhcWLF5OZmUlWVhZdu3ala9eusQ5JRKTUqEVQhOHDh3PxxRfzzTffsGDBAl544QXOOOOMWIclIlJqlAgKcOTIEQCaN29Or169WLVqFe3bt49xVCIipU9dQ3ns2bOHe+65hwoVKjBq1CgViRORhKcWQYRXX32V9PR0pk2bxsknn6wicSKSFJQIgO3bt3PDDTdw3XXXcdZZZ7FkyRKefPJJ3RcgIklBiQDYt28fb7zxBk888QRLliyhadOmsQ5JRKTMJO0YwaZNm5g+fToPPvggderUYdOmTZx88smxDktEpMwFmgjMrB3wLJACTHb3wXnePx54ATgf2AXc6O4bgogldx2CrG37+Lnvp2HDNhw5coQbb7yROnXqKAmISNIKrGvIzFKAMUB7IB24yczS8+yWCex29zrACGBIUPG8tmIrq7bu4eBX61jx2iSaN2/O6tWrVSRORJJekGMEFwLZ7r7O3Q8Cs4Fr8+xzLTAt/HwO0NoCGqF1d77d8inbZz/IqLs6s3DhQmrUqBHEoURE4kqQXUPnAJsjtrcAzQrax90Pm9le4AxgZ+ROZtYT6AlQrVq1owqm4TmnclqzRgx8Iouzzz77qL5DRCQRBZkI8ruyzzsxP5p9cPeJwESAjIyMo5rc/+g1DYGGR/NREZGEFmTX0BagasR2FeCLgvYxs1TgVODrAGMSEZE8gkwEHwB1zaymmR0HdAbm59lnPnBr+Plvgbdct/OKiJSpwLqGwn3+fYGFhKaPTnH31WY2CFjq7vOB54DpZpZNqCXQOah4REQkf4HeR+DuC4AFeV4bEPH8B6BTkDGIiEjhVGJCRCTJKRGIiCQ5JQIRkSSnRCAikuQs3mZrmtkOYONRfrwiee5aTgI65+Sgc04OJTnn6u5eKb834i4RlISZLXX3jFjHUZZ0zslB55wcgjpndQ2JiCQ5JQIRkSSXbIlgYqwDiAGdc3LQOSeHQM45qcYIRETkp5KtRSAiInkoEYiIJLmETARm1s7M1phZtpk9kM/7x5vZS+H33zezGmUfZemK4pz7mVmWma00szfNrHos4ixNRZ1zxH6/NTM3s7ifahjNOZvZDeF/69VmNrOsYyxtUfxuVzOzf5rZ8vDv99WxiLO0mNkUM9tuZqsKeN/MbGT457HSzJqW+KDunlAPQiWvPwdqAccBHwHpefbpA4wPP+8MvBTruMvgnFsBFcLPeyfDOYf3Oxl4B1gMZMQ67jL4d64LLAdOC2+fGeu4y+CcJwK9w8/TgQ2xjruE53wZ0BRYVcD7VwP/S2iFx4uA90t6zERsEVwIZLv7Onc/CMwGrs2zz7XAtPDzOUBrM8tv2cx4UeQ5u/s/3f278OZiQivGxbNo/p0B/gQMBX4oy+ACEs059wDGuPtuAHffXsYxlrZoztmBU8LPT+WnKyHGFXd/h8JXarwWeMFDFgM/N7MSLcSeiIngHGBzxPaW8Gv57uPuh4G9wBllEl0wojnnSJmErijiWZHnbGa/BKq6+1/KMrAARfPvXA+oZ2aLzGyxmbUrs+iCEc05DwT+x8y2EFr/5PayCS1mivv/e5ECXZgmRvK7ss87RzaafeJJ1OdjZv8DZAAtA40oeIWes5kdA4wAupVVQGUgmn/nVELdQ5cTavW9a2aN3H1PwLEFJZpzvgmY6u7Dzaw5oVUPG7n7keDDi4lS//uViC2CLUDViO0q/LSp+OM+ZpZKqDlZWFOsvIvmnDGzK4GHgF+7+4Eyii0oRZ3zyUAj4G0z20CoL3V+nA8YR/u7/Zq7H3L39cAaQokhXkVzzpnAywDu/h5wAqHibIkqqv/fiyMRE8EHQF0zq2lmxxEaDJ6fZ5/5wK3h578F3vLwKEycKvKcw90kEwglgXjvN4Yiztnd97p7RXev4e41CI2L/Nrdl8Ym3FIRze/2q4QmBmBmFQl1Fa0r0yhLVzTnvAloDWBmaYQSwY4yjbJszQduCc8eugjY6+7bSvKFCdc15O6HzawvsJDQjIMp7r7azAYBS919PvAcoeZjNqGWQOfYRVxyUZ7zU8DPgFfC4+Kb3P3XMQu6hKI854QS5TkvBNqYWRaQA/zR3XfFLuqSifKc7wEmmdndhLpIusXzhZ2ZzSLUtVcxPO7xKHAsgLuPJzQOcjWQDXwH/K7Ex4zjn5eIiJSCROwaEhGRYlAiEBFJckoEIiJJTolARCTJKRGIiCQ5JQIpd8wsx8xWRDxqFLJvjYKqNBbzmG+HK1x+FC7PUP8ovqOXmd0Sft7NzCpHvDfZzNJLOc4PzOy8KD5zl5lVKOmxJXEpEUh59L27nxfx2FBGx+3i7ucSKkj4VHE/7O7j3f2F8GY3oHLEe93dPatUovxPnGOJLs67ACUCKZASgcSF8JX/u2a2LPy4OJ99GprZknArYqWZ1Q2//j8Rr08ws5QiDvcOUCf82dbhOvcfh+vEHx9+fbD9Z32HYeHXBprZvWb2W0L1nGaEj3li+Eo+w8x6m9nQiJi7mdmoo4zzPSKKjZnZODNbaqF1CB4Lv3YHoYT0TzP7Z/i1Nmb2Xvjn+IqZ/ayI40iCUyKQ8ujEiG6heeHXtgNXuXtT4EZgZD6f6wU86+7nEfpDvCVccuBGoEX49RygSxHHvwb42MxOAKYCN7p7Y0J34vc2s9OB64CG7t4EeDzyw+4+B1hK6Mr9PHf/PuLtOcD1Eds3Ai8dZZztCJWUyPWQu2cATYCWZtbE3UcSqkPTyt1bhctOPAxcGf5ZLgX6FXEcSXAJV2JCEsL34T+GkY4FRof7xHMI1dDJ6z3gITOrAsx197Vm1ho4H/ggXFrjREJJJT8zzOx7YAOhUsb1gfXu/ln4/WnAH4DRhNY3mGxmfwWiLnPt7jvMbF24Rsza8DEWhb+3OHGeRKjkQuTqVDeYWU9C/1+fTWiRlpV5PntR+PVF4eMcR+jnJklMiUDixd3AV8C5hFqyP1loxt1nmtn7wK+AhWbWnVDJ3mnu3j+KY3SJLEpnZvmuURGuf3MhoUJnnYG+wBXFOJeXgBuAT4F57u4W+qscdZyEVuoaDIwBrjezmsC9wAXuvtvMphIqvpaXAW+4+03FiFcSnLqGJF6cCmwL15jvSuhq+L+YWS1gXbg7ZD6hLpI3gd+a2ZnhfU636Ndr/hSoYWZ1wttdgX+F+9RPdfcFhAZi85u58w2hUtj5mQt0JFRH/6Xwa8WK090PEeriuSjcrXQK8C2w18zOAtoXEMtioEXuOZlZBTPLr3UlSUSJQOLFWOBWM1tMqFvo23z2uRFYZWYrgAaElvPLIvQH8+9mthJ4g1C3SZHc/QdClR1fMbOPgSPAeEJ/VP8S/r5/EWqt5DUVGJ87WJzne3cDWUB1d18Sfq3YcYbHHoYD97r7R4TWKl4NTCHU3ZRrIvC/ZvZPd99BaEbTrPBxFhP6WUkSU/VREZEkpxaBiEiSUyIQEUlySgQiIklOiUBEJMkpEYiIJDklAhGRJKdEICKS5P4/eQGFOqPDQKQAAAAASUVORK5CYII=%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Precision-recall-Curve">
<a class="anchor" href="#Precision-recall-Curve" aria-hidden="true"><span class="octicon octicon-link"></span></a>Precision-recall Curve<a class="anchor-link" href="#Precision-recall-Curve"> </a>
</h3>
<p>When looking at your ROC curve, you may have noticed that the y-axis (True positive rate) is also known as recall. Indeed, in addition to the ROC curve, there are other ways to visually evaluate model performance. One such way is the precision-recall curve, which is generated by plotting the precision and recall for different thresholds. As a reminder, precision and recall are defined as:
$$ \text{Precision} = \dfrac{TP}{TP + FP} \\
   \text{Recall} = \dfrac{TP}{TP + FN}$$
   Study the precision-recall curve. Note that here, the class is positive (1) if the individual has diabetes.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_curve</span>

<span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_prob</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">recall</span><span class="p">,</span> <span class="n">precision</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Recall'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Precision'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Precision / Recall plot'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Text(0.5, 1.0, 'Precision / Recall plot')</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Area-under-the-ROC-curve-(AUC)">
<a class="anchor" href="#Area-under-the-ROC-curve-(AUC)" aria-hidden="true"><span class="octicon octicon-link"></span></a>Area under the ROC curve (AUC)<a class="anchor-link" href="#Area-under-the-ROC-curve-(AUC)"> </a>
</h2>
<ul>
<li>Larger area under the ROC curve = better model</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="AUC-computation">
<a class="anchor" href="#AUC-computation" aria-hidden="true"><span class="octicon octicon-link"></span></a>AUC computation<a class="anchor-link" href="#AUC-computation"> </a>
</h3>
<p>Say you have a binary classifier that in fact is just randomly making guesses. It would be correct approximately 50% of the time, and the resulting ROC curve would be a diagonal line in which the True Positive Rate and False Positive Rate are always equal. The Area under this ROC curve would be 0.5. This is one way in which the AUC, which Hugo discussed in the video, is an informative metric to evaluate a model. If the AUC is greater than 0.5, the model is better than random guessing. Always a good sign!</p>
<p>In this exercise, you'll calculate AUC scores using the <code>roc_auc_score()</code> function from <code>sklearn.metrics</code> as well as by performing cross-validation on the diabetes dataset.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="c1"># Compute predicted probabilites: y_pred_prob</span>
<span class="n">y_pred_prob</span> <span class="o">=</span> <span class="n">logreg</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>

<span class="c1"># Compute and print AUC score</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"AUC: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_prob</span><span class="p">)))</span>

<span class="c1"># Compute cross-validated AUC scores: cv_auc</span>
<span class="n">cv_auc</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">logreg</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">'roc_auc'</span><span class="p">)</span>

<span class="c1"># Print list of AUC scores</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"AUC scores computed using 5-fold cross-validation: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cv_auc</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>AUC: 0.8243384732533791
AUC scores computed using 5-fold cross-validation: [0.81240741 0.80777778 0.82574074 0.87283019 0.84471698]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Hyperparameter-tuning">
<a class="anchor" href="#Hyperparameter-tuning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hyperparameter tuning<a class="anchor-link" href="#Hyperparameter-tuning"> </a>
</h2>
<ul>
<li>Linear regression: Choosing parameters</li>
<li>Ridge/Lasso regression: Choosing alpha</li>
<li>k-Nearest Neighbors: Choosing n_neighbors</li>
<li>Hyperparameters: Parameters like alpha and k</li>
<li>Hyperparameters cannot be learned by fitting the model</li>
<li>Choosing the correct hyperparameter<ul>
<li>Try a bunch of different hyperparameter values</li>
<li>Fit all of them separately</li>
<li>See how well each performs</li>
<li>Choose the best performing one</li>
<li>It is essential to use cross-validation</li>
</ul>
</li>
<li>Grid search cross-validation</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Hyperparameter-tuning-with-GridSearchCV">
<a class="anchor" href="#Hyperparameter-tuning-with-GridSearchCV" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hyperparameter tuning with GridSearchCV<a class="anchor-link" href="#Hyperparameter-tuning-with-GridSearchCV"> </a>
</h3>
<p>Like the alpha parameter of lasso and ridge regularization that you saw earlier, logistic regression also has a regularization parameter: $C$. $C$ controls the inverse of the regularization strength, and this is what you will tune in this exercise. A large $C$ can lead to an overfit model, while a small $C$ can lead to an underfit model.</p>
<p>The hyperparameter space for $C$ has been setup for you. Your job is to use GridSearchCV and logistic regression to find the optimal $C$ in this hyperparameter space.</p>
<p>You may be wondering why you aren't asked to split the data into training and test sets. Good observation! Here, we want you to focus on the process of setting up the hyperparameter grid and performing grid-search cross-validation. In practice, you will indeed want to hold out a portion of your data for evaluation purposes, and you will learn all about this in the next video!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="c1"># Setup the hyperparameter grid</span>
<span class="n">c_space</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'C'</span><span class="p">:</span><span class="n">c_space</span><span class="p">}</span>

<span class="c1"># Instantiate a logistic regression classifier: logreg</span>
<span class="n">logreg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>

<span class="c1"># Instantiate the GridSearchCV object: logreg_cv</span>
<span class="n">logreg_cv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">logreg</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Fit it to the data</span>
<span class="n">logreg_cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Print the tuned parameters and score</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Tuned Logistic Regression Parameters: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">logreg_cv</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Best score is </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">logreg_cv</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tuned Logistic Regression Parameters: {'C': 0.006105402296585327}
Best score is 0.7734742381801205
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Hyperparameter-tuning-with-RandomizedSearchCV">
<a class="anchor" href="#Hyperparameter-tuning-with-RandomizedSearchCV" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hyperparameter tuning with RandomizedSearchCV<a class="anchor-link" href="#Hyperparameter-tuning-with-RandomizedSearchCV"> </a>
</h3>
<p>GridSearchCV can be computationally expensive, especially if you are searching over a large hyperparameter space and dealing with multiple hyperparameters. A solution to this is to use <code>RandomizedSearchCV</code>, in which not all hyperparameter values are tried out. Instead, a fixed number of hyperparameter settings is sampled from specified probability distributions. You'll practice using <code>RandomizedSearchCV</code> in this exercise and see how this works.</p>
<p>Here, you'll also be introduced to a new model: the Decision Tree. Don't worry about the specifics of how this model works. Just like k-NN, linear regression, and logistic regression, decision trees in scikit-learn have <code>.fit()</code> and <code>.predict()</code> methods that you can use in exactly the same way as before. Decision trees have many parameters that can be tuned, such as <code>max_features</code>, <code>max_depth</code>, and <code>min_samples_leaf</code>: This makes it an ideal use case for <code>RandomizedSearchCV</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">randint</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RandomizedSearchCV</span>

<span class="c1"># Setup the parameters and distributions to sample from: param_dist</span>
<span class="n">param_dist</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"max_depth"</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="s2">"max_features"</span><span class="p">:</span> <span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span>
    <span class="s2">"min_samples_leaf"</span><span class="p">:</span> <span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span>
    <span class="s2">"criterion"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"gini"</span><span class="p">,</span> <span class="s2">"entropy"</span><span class="p">],</span>
<span class="p">}</span>

<span class="c1"># Instantiate a Decision Tree classifier: tree</span>
<span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>

<span class="c1"># Instantiate the RandomizedSearchCV object: tree_cv</span>
<span class="n">tree_cv</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">param_dist</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Fit it to the data</span>
<span class="n">tree_cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Print the tuned parameters and score</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Tuned Decision Tree Parameters: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tree_cv</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Best score is </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tree_cv</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tuned Decision Tree Parameters: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 7, 'min_samples_leaf': 4}
Best score is 0.7448603683897801
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Hold-out-set-for-final-evaluation">
<a class="anchor" href="#Hold-out-set-for-final-evaluation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hold-out set for final evaluation<a class="anchor-link" href="#Hold-out-set-for-final-evaluation"> </a>
</h2>
<ul>
<li>How well can the model perform on never before seen data?</li>
<li>Using ALL data for cross-validation is not ideal</li>
<li>Split data into training and hold-out set at the beginning</li>
<li>Perform grid search cross-validation on training set</li>
<li>Choose best hyperparameters and evaluate on hold-out set</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Hold-out-set-in-practice-I:-Classification">
<a class="anchor" href="#Hold-out-set-in-practice-I:-Classification" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hold-out set in practice I: Classification<a class="anchor-link" href="#Hold-out-set-in-practice-I:-Classification"> </a>
</h3>
<p>You will now practice evaluating a model with tuned hyperparameters on a hold-out set. The feature array and target variable array from the diabetes dataset have been pre-loaded as <code>X</code> and <code>y</code>.</p>
<p>In addition to $C$, logistic regression has a <code>'penalty'</code> hyperparameter which specifies whether to use <code>'l1'</code> or <code>'l2'</code> regularization. Your job in this exercise is to create a hold-out set, tune the <code>'C'</code> and <code>'penalty'</code> hyperparameters of a logistic regression classifier using <code>GridSearchCV</code> on the training set.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="c1"># Create the hyperparameter grid</span>
<span class="n">c_space</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'C'</span><span class="p">:</span> <span class="n">c_space</span><span class="p">,</span> <span class="s1">'penalty'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'l1'</span><span class="p">,</span> <span class="s1">'l2'</span><span class="p">]}</span>

<span class="c1"># Instantiate the logistic regression classifier: logreg</span>
<span class="n">logreg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">'liblinear'</span><span class="p">)</span>

<span class="c1"># Create train and test sets</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Instantiate the GridSearchCV object: logreg_cv</span>
<span class="n">logreg_cv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">logreg</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Fit it to the training data</span>
<span class="n">logreg_cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Print the optimal parameters and best score</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Tuned Logistic Regression Parameter: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">logreg_cv</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Tuned Logistic Regression Accuracy: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">logreg_cv</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tuned Logistic Regression Parameter: {'C': 3.727593720314938, 'penalty': 'l2'}
Tuned Logistic Regression Accuracy: 0.7608695652173914
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Hold-out-set-in-practice-II:-Regression">
<a class="anchor" href="#Hold-out-set-in-practice-II:-Regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hold-out set in practice II: Regression<a class="anchor-link" href="#Hold-out-set-in-practice-II:-Regression"> </a>
</h3>
<p>Remember lasso and ridge regression from the previous chapter? Lasso used the $L1$ penalty to regularize, while ridge used the $L2$ penalty. There is another type of regularized regression known as the elastic net. In elastic net regularization, the penalty term is a linear combination of the $L1$ and $L2$ penalties:

$$ a * L1 + b * L2 $$
</p>
<p>In scikit-learn, this term is represented by the <code>'l1_ratio'</code> parameter: An <code>'l1_ratio'</code> of 1 corresponds to an $L1$ penalty, and anything lower is a combination of $L1$ and $L2$.</p>
<p>In this exercise, you will <code>GridSearchCV</code> to tune the <code>'l1_ratio'</code> of an elastic net model trained on the Gapminder data. As in the previous exercise, use a hold-out set to evaluate your model's performance.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Preprocess">
<a class="anchor" href="#Preprocess" aria-hidden="true"><span class="octicon octicon-link"></span></a>Preprocess<a class="anchor-link" href="#Preprocess"> </a>
</h4>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'./dataset/gm_2008_region.csv'</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">'Region'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="s1">'columns'</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>population</th>
      <th>fertility</th>
      <th>HIV</th>
      <th>CO2</th>
      <th>BMI_male</th>
      <th>GDP</th>
      <th>BMI_female</th>
      <th>life</th>
      <th>child_mortality</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>34811059.0</td>
      <td>2.73</td>
      <td>0.1</td>
      <td>3.328945</td>
      <td>24.59620</td>
      <td>12314.0</td>
      <td>129.9049</td>
      <td>75.3</td>
      <td>29.5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>19842251.0</td>
      <td>6.43</td>
      <td>2.0</td>
      <td>1.474353</td>
      <td>22.25083</td>
      <td>7103.0</td>
      <td>130.1247</td>
      <td>58.3</td>
      <td>192.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>40381860.0</td>
      <td>2.24</td>
      <td>0.5</td>
      <td>4.785170</td>
      <td>27.50170</td>
      <td>14646.0</td>
      <td>118.8915</td>
      <td>75.5</td>
      <td>15.4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2975029.0</td>
      <td>1.40</td>
      <td>0.1</td>
      <td>1.804106</td>
      <td>25.35542</td>
      <td>7383.0</td>
      <td>132.8108</td>
      <td>72.5</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>21370348.0</td>
      <td>1.96</td>
      <td>0.1</td>
      <td>18.016313</td>
      <td>27.56373</td>
      <td>41312.0</td>
      <td>117.3755</td>
      <td>81.5</td>
      <td>5.2</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">'life'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">'columns'</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'life'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">ElasticNet</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span><span class="p">,</span> <span class="n">train_test_split</span>

<span class="c1"># Create train and test sets</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Create the hyperparameter grid</span>
<span class="n">l1_space</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'l1_ratio'</span><span class="p">:</span> <span class="n">l1_space</span><span class="p">}</span>

<span class="c1"># Instantiate the ElasticNet regressor: elastic_net</span>
<span class="n">elastic_net</span> <span class="o">=</span> <span class="n">ElasticNet</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

<span class="c1"># Setup the GridSearchCV object: gm_cv</span>
<span class="n">gm_cv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">elastic_net</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Fit it to the training data</span>
<span class="n">gm_cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Predict on the test set and compute metrics</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">gm_cv</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">r2</span> <span class="o">=</span> <span class="n">gm_cv</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Tuned ElasticNet l1 ratio: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gm_cv</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Tuned ElasticNet R squared: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Tuned ElasticNet MSE: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mse</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\kcsgo\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 282.48621758506584, tolerance: 5.58941590909091
  positive)
C:\Users\kcsgo\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 309.8466391486277, tolerance: 5.893071666666667
  positive)
C:\Users\kcsgo\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 255.50344008061325, tolerance: 5.890250303030303
  positive)
C:\Users\kcsgo\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 287.6728412633782, tolerance: 5.814186865671641
  positive)
C:\Users\kcsgo\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 311.1827114768199, tolerance: 5.801944179104479
  positive)
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tuned ElasticNet l1 ratio: {'l1_ratio': 0.20689655172413793}
Tuned ElasticNet R squared: 0.8668305372460283
Tuned ElasticNet MSE: 10.057914133398445
</pre>
</div>
</div>

</div>
</div>

</div>
    

</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="goodboychan/goodboychan.github.io"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/python/datacamp/machine_learning/2020/05/30/01-Fine-tuning-your-model.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/goodboychan" target="_blank" title="goodboychan"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/chanseokk" target="_blank" title="chanseokk"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" target="_blank" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
