<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Artificial Neural Networks in PyTorch</h1><p class="page-description">In this second chapter, we delve deeper into Artificial Neural Networks, learning how to train them with real datasets. This is the Summary of lecture "Introduction to Deep Learning with PyTorch", via datacamp.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-07-28T00:00:00-05:00" itemprop="datePublished">
        Jul 28, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Chanseok Kang</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      7 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#Python">Python</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#Datacamp">Datacamp</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#PyTorch">PyTorch</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#Deep_Learning">Deep_Learning</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/goodboychan/goodboychan.github.io/tree/main/_notebooks/2020-07-28-05-Artificial-Neural-Networks-in-PyTorch.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/goodboychan/goodboychan.github.io/main?filepath=_notebooks%2F2020-07-28-05-Artificial-Neural-Networks-in-PyTorch.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/goodboychan/goodboychan.github.io/blob/main/_notebooks/2020-07-28-05-Artificial-Neural-Networks-in-PyTorch.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Fgoodboychan%2Fgoodboychan.github.io%2Fblob%2Fmain%2F_notebooks%2F2020-07-28-05-Artificial-Neural-Networks-in-PyTorch.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Activation-functions">Activation functions </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Neural-networks">Neural networks </a></li>
<li class="toc-entry toc-h3"><a href="#ReLU-activation">ReLU activation </a></li>
<li class="toc-entry toc-h3"><a href="#ReLU-activation-again">ReLU activation again </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Loss-functions">Loss functions </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Calculating-loss-function-in-PyTorch">Calculating loss function in PyTorch </a></li>
<li class="toc-entry toc-h3"><a href="#Loss-function-of-random-scores">Loss function of random scores </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Preparing-a-dataset-in-PyTorch">Preparing a dataset in PyTorch </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Preparing-MNIST-dataset">Preparing MNIST dataset </a></li>
<li class="toc-entry toc-h3"><a href="#Inspecting-the-dataloaders">Inspecting the dataloaders </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Training-neural-networks">Training neural networks </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Building-a-neural-network---again">Building a neural network - again </a></li>
<li class="toc-entry toc-h3"><a href="#Training-a-neural-network">Training a neural network </a></li>
<li class="toc-entry toc-h3"><a href="#Using-the-network-to-make-predictions">Using the network to make predictions </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-07-28-05-Artificial-Neural-Networks-in-PyTorch.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Activation-functions">
<a class="anchor" href="#Activation-functions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Activation functions<a class="anchor-link" href="#Activation-functions"> </a>
</h2>
<p><img src="/images/copied_from_nb/image/activation.png" alt="activation"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Neural-networks">
<a class="anchor" href="#Neural-networks" aria-hidden="true"><span class="octicon octicon-link"></span></a>Neural networks<a class="anchor-link" href="#Neural-networks"> </a>
</h3>
<p>Let us see the differences between neural networks which apply <code>ReLU</code> and those which do not apply <code>ReLU</code>.</p>
<p>We are going to convince ourselves that networks with multiple layers which do not contain non-linearity can be expressed as neural networks with one layer.</p>
<p>The network and the shape of layers and weights is shown below.
<img src="/images/copied_from_nb/image/net-ex.jpg" alt="net-ex"></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">input_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.0401</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9005</span><span class="p">,</span>  <span class="mf">0.0397</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0876</span><span class="p">]])</span>

<span class="n">weight_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.1094</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8285</span><span class="p">,</span>  <span class="mf">0.0416</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1222</span><span class="p">],</span>
                        <span class="p">[</span> <span class="mf">0.3327</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0461</span><span class="p">,</span>  <span class="mf">1.4473</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8070</span><span class="p">],</span>
                        <span class="p">[</span> <span class="mf">0.0681</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7058</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.8017</span><span class="p">,</span>  <span class="mf">0.5857</span><span class="p">],</span>
                        <span class="p">[</span> <span class="mf">0.8764</span><span class="p">,</span>  <span class="mf">0.9618</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4505</span><span class="p">,</span>  <span class="mf">0.2888</span><span class="p">]])</span>

<span class="n">weight_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.6856</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7650</span><span class="p">,</span>  <span class="mf">1.6375</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5759</span><span class="p">],</span>
                        <span class="p">[</span><span class="o">-</span><span class="mf">0.1092</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1620</span><span class="p">,</span>  <span class="mf">0.1951</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1169</span><span class="p">],</span>
                        <span class="p">[</span><span class="o">-</span><span class="mf">0.5120</span><span class="p">,</span>  <span class="mf">1.1997</span><span class="p">,</span>  <span class="mf">0.8483</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2476</span><span class="p">],</span>
                        <span class="p">[</span><span class="o">-</span><span class="mf">0.3369</span><span class="p">,</span>  <span class="mf">0.5617</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6658</span><span class="p">,</span>  <span class="mf">0.2221</span><span class="p">]])</span>

<span class="n">weight_3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.8824</span><span class="p">,</span>  <span class="mf">0.1268</span><span class="p">,</span>  <span class="mf">1.1951</span><span class="p">,</span>  <span class="mf">1.3061</span><span class="p">],</span>
                        <span class="p">[</span><span class="o">-</span><span class="mf">0.8753</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3277</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1454</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0167</span><span class="p">],</span>
                        <span class="p">[</span> <span class="mf">0.3582</span><span class="p">,</span>  <span class="mf">0.3254</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.8509</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4205</span><span class="p">],</span>
                        <span class="p">[</span> <span class="mf">0.3786</span><span class="p">,</span>  <span class="mf">0.5999</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5665</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3975</span><span class="p">]])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hidden_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">weight_1</span><span class="p">)</span>
<span class="n">hidden_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">hidden_1</span><span class="p">,</span> <span class="n">weight_2</span><span class="p">)</span>

<span class="c1"># Calculate the output</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">hidden_2</span><span class="p">,</span> <span class="n">weight_3</span><span class="p">))</span>

<span class="c1"># Calculate wieght_composed_1 and weight</span>
<span class="n">weight_composed_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">weight_1</span><span class="p">,</span> <span class="n">weight_2</span><span class="p">)</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">weight_composed_1</span><span class="p">,</span> <span class="n">weight_3</span><span class="p">)</span>

<span class="c1"># Multiply input_layer with weight</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">weight</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([[0.2653, 0.1311, 3.8219, 3.0032]])
tensor([[0.2653, 0.1311, 3.8219, 3.0032]])
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="ReLU-activation">
<a class="anchor" href="#ReLU-activation" aria-hidden="true"><span class="octicon octicon-link"></span></a>ReLU activation<a class="anchor-link" href="#ReLU-activation"> </a>
</h3>
<p>Now we are going to build a neural network which has non-linearity and by doing so, we are going to convince ourselves that networks with multiple layers and non-linearity functions cannot be expressed as a neural network with one layer.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

<span class="c1"># Apply non-linearity on hidden_1 and hidden_2</span>
<span class="n">hidden_1_activated</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">weight_1</span><span class="p">))</span>
<span class="n">hidden_2_activated</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">hidden_1_activated</span><span class="p">,</span> <span class="n">weight_2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">hidden_2_activated</span><span class="p">,</span> <span class="n">weight_3</span><span class="p">))</span>

<span class="c1"># Apply non-linearity in the product of first two weights</span>
<span class="n">weight_composed_1_activated</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">weight_1</span><span class="p">,</span> <span class="n">weight_2</span><span class="p">))</span>

<span class="c1"># Multiply `weight_composed_1_activated` with `weight_3`</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">weight_composed_1_activated</span><span class="p">,</span> <span class="n">weight_3</span><span class="p">)</span>

<span class="c1"># Multiply input_layer with weight</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">weight</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([[-0.2770, -0.0345, -0.1410, -0.0664]])
tensor([[-0.2117, -0.4782,  4.0438,  3.0417]])
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="ReLU-activation-again">
<a class="anchor" href="#ReLU-activation-again" aria-hidden="true"><span class="octicon octicon-link"></span></a>ReLU activation again<a class="anchor-link" href="#ReLU-activation-again"> </a>
</h3>
<p>Neural networks don't need to have the same number of units in each layer. Here, you are going to experiment with the <code>ReLU</code> activation function again, but this time we are going to have a different number of units in the layers of the neural network. The input layer will still have 4 features, but then the first hidden layer will have 6 units and the output layer will have 2 units.
<img src="/images/copied_from_nb/image/net-ex2.jpg" alt="net-ex2"></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">weight_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">weight_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># Multiply input_layer with weight_1</span>
<span class="n">hidden_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">weight_1</span><span class="p">)</span>

<span class="c1"># Apply ReLU activation function over hidden_1 and multiply with weight_2</span>
<span class="n">hidden_1_activated</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">hidden_1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">hidden_1_activated</span><span class="p">,</span> <span class="n">weight_2</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([[0., 0.]])
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Loss-functions">
<a class="anchor" href="#Loss-functions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Loss functions<a class="anchor-link" href="#Loss-functions"> </a>
</h2>
<ul>
<li>Process<ul>
<li>Initialize neural networks with random weights</li>
<li>Do a forward pass</li>
<li>Calculate loss function (1 number)</li>
<li>Calcualte the gradients</li>
<li>Change the weights based on gradients</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Calculating-loss-function-in-PyTorch">
<a class="anchor" href="#Calculating-loss-function-in-PyTorch" aria-hidden="true"><span class="octicon octicon-link"></span></a>Calculating loss function in PyTorch<a class="anchor-link" href="#Calculating-loss-function-in-PyTorch"> </a>
</h3>
<p>You are going to code the previous exercise, and make sure that we computed the loss correctly. Predicted scores are -1.2 for class 0 (cat), 0.12 for class 1 (car) and 4.8 for class 2 (frog). The ground truth is class 2 (frog). Compute the loss function in PyTorch.</p>
<table>
<thead>
<tr>
<th>Class</th>
<th>Predicted Score</th>
</tr>
</thead>
<tbody>
<tr>
<td>Cat</td>
<td>-1.2</td>
</tr>
<tr>
<td>Car</td>
<td>0.12</td>
</tr>
<tr>
<td>Frog</td>
<td>4.8</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">,</span> <span class="mf">4.8</span><span class="p">]])</span>
<span class="n">ground_truth</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">])</span>

<span class="c1"># Instantiate cross entropy loss</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># Compute and print the loss</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor(0.0117)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>the loss function PyTorch calculated gives the same number as the loss function you calculated. Being proficient in understanding and calculating loss functions is a very important skill in deep learning.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Loss-function-of-random-scores">
<a class="anchor" href="#Loss-function-of-random-scores" aria-hidden="true"><span class="octicon octicon-link"></span></a>Loss function of random scores<a class="anchor-link" href="#Loss-function-of-random-scores"> </a>
</h3>
<p>If the neural network predicts random scores, what would be its loss function? Let's find it out in PyTorch. The neural network is going to have 1000 classes, each having a random score. For ground truth, it will have class 111. Calculate the loss function.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">ground_truth</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">111</span><span class="p">])</span>

<span class="c1"># Instantiate cross-entropy loss</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># Calculate and print the loss</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor(7.0403)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Preparing-a-dataset-in-PyTorch">
<a class="anchor" href="#Preparing-a-dataset-in-PyTorch" aria-hidden="true"><span class="octicon octicon-link"></span></a>Preparing a dataset in PyTorch<a class="anchor-link" href="#Preparing-a-dataset-in-PyTorch"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Preparing-MNIST-dataset">
<a class="anchor" href="#Preparing-MNIST-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Preparing MNIST dataset<a class="anchor-link" href="#Preparing-MNIST-dataset"> </a>
</h3>
<p>You are going to prepare dataloaders for MNIST training and testing set. As we explained in the lecture, MNIST has some differences to CIFAR-10, with the main difference being that MNIST images are grayscale (1 channel based) instead of RGB (3 channels).</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>

<span class="c1"># Transform the data to torch tensors and normalize it</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">))</span>
<span class="p">])</span>

<span class="c1"># Preparing training set and test set</span>
<span class="n">trainset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">'mnist'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
<span class="n">testset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">'mnist'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

<span class="c1"># Prepare training loader and test loader</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">trainset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">testset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist/MNIST/raw/train-images-idx3-ubyte.gz
Extracting mnist/MNIST/raw/train-images-idx3-ubyte.gz to mnist/MNIST/raw
Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist/MNIST/raw/train-labels-idx1-ubyte.gz
Extracting mnist/MNIST/raw/train-labels-idx1-ubyte.gz to mnist/MNIST/raw
Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw/t10k-images-idx3-ubyte.gz
Extracting mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw
Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz


Extracting mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw
Processing...
Done!
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/opt/conda/conda-bld/pytorch_1591914855613/work/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Inspecting-the-dataloaders">
<a class="anchor" href="#Inspecting-the-dataloaders" aria-hidden="true"><span class="octicon octicon-link"></span></a>Inspecting the dataloaders<a class="anchor-link" href="#Inspecting-the-dataloaders"> </a>
</h3>
<p>Now you are going to explore a bit the dataloaders you created in the previous exercise. In particular, you will compute the shape of the dataset in addition to the minibatch size.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong><code>train_data</code>, <code>test_data</code> attributes in dataset is replaced with <code>data</code>
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trainset_shape</span> <span class="o">=</span> <span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span>
<span class="n">testset_shape</span> <span class="o">=</span> <span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span>

<span class="c1"># Print the computed shapes</span>
<span class="nb">print</span><span class="p">(</span><span class="n">trainset_shape</span><span class="p">,</span> <span class="n">testset_shape</span><span class="p">)</span>

<span class="c1"># Compute the size of the minibatch for training set and test set</span>
<span class="n">trainset_batchsize</span> <span class="o">=</span> <span class="n">train_loader</span><span class="o">.</span><span class="n">batch_size</span>
<span class="n">testset_batchsize</span> <span class="o">=</span> <span class="n">test_loader</span><span class="o">.</span><span class="n">batch_size</span>

<span class="c1"># Print sizes of the minibatch</span>
<span class="nb">print</span><span class="p">(</span><span class="n">trainset_batchsize</span><span class="p">,</span> <span class="n">testset_batchsize</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([60000, 28, 28]) torch.Size([10000, 28, 28])
32 32
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Training-neural-networks">
<a class="anchor" href="#Training-neural-networks" aria-hidden="true"><span class="octicon octicon-link"></span></a>Training neural networks<a class="anchor-link" href="#Training-neural-networks"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Building-a-neural-network---again">
<a class="anchor" href="#Building-a-neural-network---again" aria-hidden="true"><span class="octicon octicon-link"></span></a>Building a neural network - again<a class="anchor-link" href="#Building-a-neural-network---again"> </a>
</h3>
<p>You haven't created a neural network since the end of the first chapter, so this is a good time to build one (practice makes perfect). Build a class for a neural network which will be used to train on the MNIST dataset. The dataset contains images of shape (28, 28, 1), so you should deduct the size of the input layer. For hidden layer use 200 units, while for output layer use 10 units (1 for each class). For activation function, use <code>relu</code> in a functional way.</p>
<p>For context, the same net will be trained and used to make predictions in the next two exercises.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="c1"># Define the class Net</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Define all the parameters of the net</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Do the forward pass</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Training-a-neural-network">
<a class="anchor" href="#Training-a-neural-network" aria-hidden="true"><span class="octicon octicon-link"></span></a>Training a neural network<a class="anchor-link" href="#Training-a-neural-network"> </a>
</h3>
<p>Given the fully connected neural network (called <code>model</code>) which you built in the previous exercise and a train loader called <code>train_loader</code> containing the MNIST dataset (which we created for you), you're to train the net in order to predict the classes of digits. You will use the Adam optimizer to optimize the network, and considering that this is a classification problem you are going to use cross entropy as loss function.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>

<span class="c1"># Instantiate the Adam optimizer and Cross-Entropy loss function</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">3e-4</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">data_target</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data_target</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">data_target</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    
    <span class="c1"># Compute a forward pass</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    
    <span class="c1"># Compute the loss gradients and change the weights</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Using-the-network-to-make-predictions">
<a class="anchor" href="#Using-the-network-to-make-predictions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Using the network to make predictions<a class="anchor-link" href="#Using-the-network-to-make-predictions"> </a>
</h3>
<p>Now that you have trained the network, use it to make predictions for the data in the testing set. The network is called <code>model</code> (same as in the previous exercise), and the loader is called <code>test_loader</code>. We have already initialized variables <code>total</code> and <code>correct</code> to 0.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">correct</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>

<span class="c1"># Set the model in eval mode</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_loader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
    <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
    
    <span class="c1"># Put each image into a vector</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">)</span>
    
    <span class="c1"># Do the forward pass and get the predictions</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">outputs</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'The test set accuracy of the network is: </span><span class="si">%d</span><span class="s1"> </span><span class="si">%%</span><span class="s1">'</span> <span class="o">%</span> <span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">))</span> 
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>The test set accuracy of the network is: 95 %
</pre>
</div>
</div>

</div>
</div>

</div>
    

</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="goodboychan/goodboychan.github.io"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/python/datacamp/pytorch/deep_learning/2020/07/28/05-Artificial-Neural-Networks-in-PyTorch.html" hidden></a>
</article>