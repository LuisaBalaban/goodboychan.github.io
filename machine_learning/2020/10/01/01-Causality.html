<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Causality</h1><p class="page-description">In this post, it will be explained about what the causality is, such as casual graphical model and temporal causality. This post is the summary of "Mathematical principles in Machine Learning" offered from UNIST.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-10-01T00:00:00-05:00" itemprop="datePublished">
        Oct 1, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      3 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#Machine_Learning">Machine_Learning</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h1"><a href="#causality">Causality</a>
<ul>
<li class="toc-entry toc-h2"><a href="#introduction-to-causality">Introduction to Causality</a></li>
<li class="toc-entry toc-h2"><a href="#three-layers-of-causal-hierarchy">Three layers of Causal Hierarchy</a></li>
<li class="toc-entry toc-h2"><a href="#summary">Summary</a></li>
</ul>
</li>
</ul><h1 id="causality">
<a class="anchor" href="#causality" aria-hidden="true"><span class="octicon octicon-link"></span></a>Causality</h1>

<h2 id="introduction-to-causality">
<a class="anchor" href="#introduction-to-causality" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction to Causality</h2>

<p><a href="https://en.wikipedia.org/wiki/Causality">Causality</a>, also referred to as causation, is what connect one process (cause) with another process (effect).</p>

<p><img src="/assets/image/cause_effect.png" alt="cause_effect" title="Fig 1. The relationship between cause and effect"></p>

<p>There are common confusion between <strong>association</strong> and <strong>causation</strong>. It is easy to understand the difference by example. Famous example is the relationship between Chocolate and Nobel prize winner. There was study result that the place where the chocolate consumption is high, won more nobel prize. In this case, chocolate consumption affects the the nobel prize winner? Actually, it is not. The truth is that two quantities (chocolate consumption and nobel prize winner) have steadily increased over time due to respective local conditions, which is not related any further. As a result, these two unrelated time trends induce an association. So in this case, we can tell that there is an association between the chocolate consumption in time and the nobel prize winner trend in time.</p>

<p>We can draw the relationship between the state $X$ and state $Y$.</p>

<p><img src="/assets/image/cause_association.png" alt="cause_association" title="Fig 2. X and Y are associated"></p>

<p>The mention of association between $X$ and $Y$ can be explained in 4 causal models.</p>

<ul>
  <li>$X$ causes $Y$</li>
  <li>And $Y$ causes $X$</li>
  <li>There is common cause which occurs state $X$ and state $Y$. (Usually, it is called <strong>confounding</strong>)</li>
  <li>There are many confounding factors which occurs state $X$ and state $Y$.</li>
</ul>

<p>Practically speaking, the word “$T$ causes $Y$” means that changing $T$ leads to a change in $Y$ <strong>keeping everything else constant</strong>, and vice versa. In this case, causal effect is the magnitude by which $Y$ is changed by a unit change in $T$.</p>

<h2 id="three-layers-of-causal-hierarchy">
<a class="anchor" href="#three-layers-of-causal-hierarchy" aria-hidden="true"><span class="octicon octicon-link"></span></a>Three layers of Causal Hierarchy</h2>

<p>More concisely, we can define the level of causation in 3 layers.</p>

<p><img src="/assets/image/3_layer_causation.png" alt="3 layers causation" title="Fig 3. The Three layers of causal hierarchy"></p>

<p>First level is <strong>Association</strong>. Here, we just only consider statistical relationship. We can directly infered from the observed data from conditional expectations. As you notice from the word, causal information is not required, questions in this hierarchy are placed at the lowest level of the hierarchy. So when we mention about association, it comes with conditional probability ($P(Y \vert X)$). In short, association cares observation such as “what is” and “How would seeing $X$ change our belief in $Y$?”</p>

<ul>
  <li>Specification: $p(X), p(Y \vert X)$</li>
  <li>Joint Distribution: $p(X, Y)$</li>
  <li>Inferences: $p(X), p(Y), p(Y \vert X) p(X \vert Y)$</li>
</ul>

<p>Second level is <strong>Intervention</strong>. Unlike association, intervention includes not only seeing what is, but changing what we see as sort of interventional inference. Usually, it includes action (expressed with $do(x)$). So when we see the comment of “perfect intervention”, it means that it is controlled experiment that an event is specifically set in some conditions. Mathmatically, it can express like this,</p>

<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>y</mi><mi mathvariant="normal">∣</mi><mi>d</mi><mi>o</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(y \vert do(x), z)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord">∣</span><span class="mord mathnormal">d</span><span class="mord mathnormal">o</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span></span></span></span></span>

<p>It is the probability of event $Y = y$ given that we intervene and set the value of $X$ to $x$ and subsequently observe event $Z = z$.</p>

<ul>
  <li>Specification: $p(X), p(Y \vert X)$</li>
  <li>Joint distribution: $p(X, Y)$</li>
  <li>Inferences: $p(Y \vert do(X = x))$</li>
</ul>

<p>The final level is <strong>Counterfactuals</strong>. And it includes interventional and associational questions. If we have a model that can answer counterfactual queries, we can also answer questions about interventions and observations. The mathematical symbol is like this,</p>

<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mi>x</mi></msub><mi mathvariant="normal">∣</mi><msup><mi>x</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo separator="true">,</mo><msup><mi>y</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(y_x \vert x', y')</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0519em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>

<p>It is the probability that event $Y = y$ would be observed hand $X$ been $x$, given that we actually observed $X$ to be $x’$ nad $Y$ to be $y’$.</p>

<ul>
  <li>Specification: $p(X), p(Y \vert X)$</li>
  <li>Joint distribution: $p(X, Y)$</li>
  <li>Inferences: $p(Y_x = y \vert X = x’, Y = y’) = p(Y = y \vert X = x’, Y = y’, do(X = x))$</li>
</ul>

<h2 id="summary">
<a class="anchor" href="#summary" aria-hidden="true"><span class="octicon octicon-link"></span></a>Summary</h2>

<p>In this post, we covered what causality is and why it is important. And we briefly looked the three layers of causal hierarchy, Association, Intervention, and Counterfactuals.</p>

  </div><a class="u-url" href="/machine_learning/2020/10/01/01-Causality.html" hidden></a>
</article>